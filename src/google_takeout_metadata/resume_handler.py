# Fichier : src/google_takeout_metadata/resume_handler.py

import logging
from pathlib import Path
from typing import List, Tuple

logger = logging.getLogger(__name__)


def should_resume(output_dir: Path) -> bool:
    """DÃ©tecter si des fichiers de log -efile existent pour une reprise.
    
    Args:
        output_dir: RÃ©pertoire Ã  vÃ©rifier pour les logs -efile
        
    Returns:
        True si des logs -efile existent et qu'une reprise est possible
    """
    log_files = [
        "error_files.txt",
        "unchanged_files.txt", 
        "failed_condition_files.txt",
        "updated_files.txt"
    ]
    
    return any((output_dir / log_file).exists() for log_file in log_files)


def parse_efile_logs(output_dir: Path) -> Tuple[List[Path], List[Path], List[Path], List[Path]]:
    """Parser les logs -efile pour extraire les listes de fichiers.
    
    Args:
        output_dir: RÃ©pertoire contenant les logs -efile
        
    Returns:
        Tuple de (error_files, updated_files, unchanged_files, failed_condition_files)
    """
    error_files = _read_file_list(output_dir / "error_files.txt")
    updated_files = _read_file_list(output_dir / "updated_files.txt") 
    unchanged_files = _read_file_list(output_dir / "unchanged_files.txt")
    failed_condition_files = _read_file_list(output_dir / "failed_condition_files.txt")
    
    logger.info(f"ğŸ“Š Analyse des logs -efile: {len(error_files)} erreurs, "
                f"{len(updated_files)} mis Ã  jour, {len(unchanged_files)} inchangÃ©s, "
                f"{len(failed_condition_files)} conditions Ã©chouÃ©es")
    
    return error_files, updated_files, unchanged_files, failed_condition_files


def build_resume_batch(error_files: List[Path], unchanged_files: List[Path] = None, resume_mode: str = "errors") -> List[Path]:
    """Construire un lot de reprise Ã  partir des logs -efile.
    
    Args:
        error_files: Liste des fichiers en erreur
        unchanged_files: Liste des fichiers inchangÃ©s (optionnel)
        resume_mode: Mode de reprise ("errors" ou "all")
        
    Returns:
        Liste des fichiers Ã  retraiter
    """
    files_to_resume = error_files.copy()  # Toujours reprendre les erreurs
    
    if resume_mode == "all" and unchanged_files:
        files_to_resume.extend(unchanged_files)  # Reprendre aussi les inchangÃ©s si policy modifiÃ©e
        logger.info(f"ğŸ”„ Mode reprise complÃ¨te: {len(files_to_resume)} fichiers Ã  retraiter")
    else:
        logger.info(f"ğŸ”„ Mode reprise erreurs: {len(files_to_resume)} fichiers Ã  retraiter")
    
    return files_to_resume


def _read_file_list(log_file: Path) -> List[Path]:
    """Lire une liste de fichiers depuis un log -efile.
    
    Args:
        log_file: Fichier de log Ã  lire
        
    Returns:
        Liste des chemins de fichiers trouvÃ©s dans le log
    """
    if not log_file.exists():
        return []
    
    files = []
    try:
        with open(log_file, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#'):  # Ignorer les commentaires
                    files.append(Path(line))
    except Exception as e:
        logger.warning(f"âš ï¸ Erreur lors de la lecture de {log_file}: {e}")
    
    return files


def cleanup_efile_logs(output_dir: Path) -> None:
    """Nettoyer les anciens logs -efile aprÃ¨s un traitement rÃ©ussi.
    
    Args:
        output_dir: RÃ©pertoire contenant les logs Ã  nettoyer
    """
    log_files = [
        "error_files.txt",
        "unchanged_files.txt", 
        "failed_condition_files.txt",
        "updated_files.txt"
    ]
    
    cleaned = 0
    for log_file in log_files:
        log_path = output_dir / log_file
        if log_path.exists():
            try:
                log_path.unlink()
                cleaned += 1
            except Exception as e:
                logger.warning(f"âš ï¸ Impossible de nettoyer {log_file}: {e}")
    
    if cleaned > 0:
        logger.info(f"ğŸ§¹ {cleaned} fichiers de log -efile nettoyÃ©s")
