# Directory Structure
```
astuces.md
AUDIT_TESTS_AXES.md
doc_exiftool_full.txt
error_files.txt
pyproject.toml
pytest.ini
README.md
requirements.txt
SIDECAR_SAFETY_IMPLEMENTATION.md
src/google_takeout_metadata/__init__.py
src/google_takeout_metadata/__main__.py
src/google_takeout_metadata/cli.py
src/google_takeout_metadata/exif_writer.py
src/google_takeout_metadata/file_organizer.py
src/google_takeout_metadata/processor_batch.py
src/google_takeout_metadata/processor.py
src/google_takeout_metadata/resume_handler.py
src/google_takeout_metadata/sidecar_safety.py
src/google_takeout_metadata/sidecar.py
src/google_takeout_metadata/statistics.py
TERMINOLOGY_UPDATE.md
test_assets/README.md
tests/CORRECT_test_robust_approach.py
tests/SIDECAR_CLEANUP_FIXES.md
tests/test_batch_organization.py
tests/test_cli.py
tests/test_deduplication_robuste.py
tests/test_end_to_end.py
tests/test_exif_writer.py
tests/test_file_organization.py
tests/test_improvements.py
tests/test_integration.py
tests/test_local_folder.py
tests/test_p1_specific.py
tests/test_processor_batch.py
tests/test_processor.py
tests/test_resume_handler.py
tests/test_robust_approach.py
tests/test_sidecar_integration.py
tests/test_sidecar.py
tests/test_stats_validation.py
tests/test_wm_cg_fix.py
updated_files.txt
```

# Files

## File: astuces.md
````markdown
Pour obtenir :

> `PersonInImage: Jeremy, Cindy, Anthony Vincent, Bernard, Jean`

…à partir de la base :

* image : `Jeremy, Cindy`
* sidecar : `people = [ "Anthony Vincent", "Bernard", "Jean", "Cindy" ]`

Je n'ai identifié que **deux façons reellement correctes**:

---

# Option A — “supprimer puis ajouter” (infaillible et surtout gère aussi les doublons pré-existants)

```bash
exiftool \
  -overwrite_original -wm cg \
  -XMP-iptcExt:PersonInImage-="Anthony Vincent" -XMP-iptcExt:PersonInImage+="Anthony Vincent" -execute \
  -XMP-iptcExt:PersonInImage-=Bernard        -XMP-iptcExt:PersonInImage+=Bernard        -execute \
  -XMP-iptcExt:PersonInImage-=Jean           -XMP-iptcExt:PersonInImage+=Jean           -execute \
  -XMP-iptcExt:PersonInImage-=Cindy          -XMP-iptcExt:PersonInImage+=Cindy          \
  -common_args img.jpg
```

* `-wm cg` : append-only (n’écrase pas l’existant).
* Pour chaque nom du sidecar : on **retire** l’éventuel item, puis on **ajoute** l’item une seule fois ⇒ **zéro doublon garanti**, même si l’image en avait déjà (ou si on repasses plusieurs fois).

---

# Option B — “ajouter si absent” (évite d’enlever/rajouter, sensible à la casse si on ne normalises pas)

```bash
exiftool -overwrite_original \
  -if 'not $XMP-iptcExt:PersonInImage=~/\bAnthony Vincent\b/i' -XMP-iptcExt:PersonInImage+="Anthony Vincent" -execute \
  -if 'not $XMP-iptcExt:PersonInImage=~/\bBernard\b/i'         -XMP-iptcExt:PersonInImage+=Bernard         -execute \
  -if 'not $XMP-iptcExt:PersonInImage=~/\bJean\b/i'            -XMP-iptcExt:PersonInImage+=Jean            -execute \
  -if 'not $XMP-iptcExt:PersonInImage=~/\bCindy\b/i'           -XMP-iptcExt:PersonInImage+=Cindy           \
  -common_args img.jpg
```

* La regex `/…/i` est **insensible à la casse** → évite `Cindy` + `cindy`.
* On **n’ajoute** que si le nom **n’existe pas déjà**.

---

## Résultat

Dans **les deux** cas ci-dessus, après exécution sur l'exemple ci-dessus, on obtient bien :

```
PersonInImage: Anthony, Cindy, Anthony Vincent, Bernard, Jean
```

## Extra

* Si on veux forcer une **casse cohérente** (ex. “Title Case”) avant d’écrire, effectuer côté script (extraction du sidecar) puis appliquer l’une des deux méthodes.
* **Ordre** : `PersonInImage` est une “bag” XMP (ordre pas strictement garanti). En pratique, exiftool tend à **ajouter** à la fin ; l’important est l’**ensemble** des noms, pas leur ordre.
* On peux remplacer les quatre blocs par ceux issus du **parsing du sidecar** (PowerShell/Python) pour automatiser sur tout un dossier.

## Pourquoi “supprimer puis ajouter” (option A) est infaillible

La doc recommande explicitement, pour les balises liste, le motif :
`-TAG-=val -TAG+=val`
afin d’ajouter sans dupliquer (même si la valeur existait déjà). 

Cette approche normalise la présence de chaque nom : on enlève l’éventuelle occurrence, puis on écrit exactement une fois.
Elle gère tous les scénarios : doublons pré-existants, ré-exécutions multiples, cas mixtes, etc.
Elle n’a pas besoin que l’item soit dans le même lot d’arguments : On peut traiter un nom à la fois, un fichier à la fois, un sidecar à la fois.

## Pourquoi “ajouter si absent” (option B) est précise et sobre

L’usage de `-if + regex` :
`-if 'not $PersonInImage=~/\bNom\b/i' -PersonInImage+=Nom`
- permet de ne pas toucher aux fichiers déjà propres (aucune écriture si la valeur existe), et de rester idempotent. La doc formalise l’usage puissant de `-if` pour conditionner l’écriture. 
- On maîtrises la sensibilité à la casse (/i) et le mot entier (\b…\b).
- On évite des écritures inutiles (pratique si on veut limiter les I/O).

## Pourquoi je n'ai pas utilisé `-api NoDups=1`
### Ce que fait vraiment `-api NoDups=1`:
- L’option retire les doublons uniquement parmi les valeurs “en file d’attente d’écriture” (celles que l'on fournis dans la même invocation exiftool). Elle ne dédoublonne pas ce qui est déjà présent dans le fichier si on se contentes d’ajouter (+=) de nouvelles valeurs. 

- La doc indique d’ailleurs que `NoDups` (API) a été ajouté pour rendre la fonction helper `NoDups` largement redondante lors de copies ou d’accumulations, mais sans la capacité d’éviter la réécriture quand il n’y a pas de doublons existants. Exemple typique : combiner des listes depuis plusieurs sources dans la même commande avec `-tagsFromFile ... -+subject ... -api nodups`. 
--> `NoDups` supprimera les doublons dans un lot de +=, mais ne retirera pas un doublon déjà présent dans le fichier, puisqu’il ne déduplique pas par rapport à l’état pré-existant.

Par contre `NoDups` est très pratique quand on accumules des listes dans une seule commande, par exemple :
- on copie des items depuis plusieurs sources vers un même tag liste via `-tagsFromFile + -+DSTTAG`, et on veut une déduplication automatique du lot au moment de l’écriture. La doc donne l’exemple :
`exiftool -tagsfromfile a.jpg -subject -tagsfromfile b.jpg -+subject -api nodups c.jpg`

- on construit un gros argfile avec plein de += pour un même fichier et on veut s’épargner un tri/dédoublonnage préalable dans ce lot.

**Mais** : cette dédup intra-lot ne remplace pas l’assurance “zéro doublon final” vis-à-vis de l’état déjà inscrit dans le fichier. Pour ça, il faut soit le motif `-TAG-=val -TAG+=val` (option A), soit la condition -if (option B).

## Fonctionnalitées complémentaires
L'usage de `-wm cg` (create groups only) en mode append-only est pertinent ; la doc confirme que `-wm cg` limite l’écriture à la création et évite d’éditer l’existant (utile en batch). Combiner avec A ou B selon l’effet recherché. 

Pour le batch, `-@ argfile`, `-execute` et `-common_args` sont les bons outils

---
Très bonne question — sur un **Takeout de \~50 Go**, la *stratégie d’exécution* compte plus que la micro-optimisation des options. Voilà ce qui marche vraiment bien, avec les raisons et la doc à l’appui.

---

## Analyse/ astuces de méthodes + performances sur gros dossiers

* **Évite un exiftool par fichier** → garde un **processus ouvert** et enchaîne les commandes avec `-execute` + `-common_args`, ou utilise un **fichier d’arguments** `-@` (mêmes effets). &#x20;
* **Préfère `-overwrite_original`** (plus rapide) à `-overwrite_original_in_place` (plus lent) sauf si tu DOIS préserver certains attributs système du fichier.&#x20;
* **Journalise** les “mis à jour / inchangés / en erreur” avec `-efile` pour les passes suivantes.&#x20;
* **Parallélise par sous-dossiers** (2–4 processus max sur SSD/NVMe ; 1–2 sur HDD) au lieu d’un seul process sur toute l’arbo, pour tirer parti des cœurs sans saturer l’I/O.

---

## 1) Réduire drastiquement l’overhead de lancement

Chaque lancement d’exiftool a un coût. Deux approches natives permettent de **chaîner des commandes** dans un **seul** process :

### A) `-@ args.txt` + `-execute` + `-common_args`

* Tu mets des blocs « commande » séparés par `-execute`, et tu factorises les options communes avec `-common_args`. C’est exactement le pattern recommandé dans la doc (exemple avancé).&#x20;
* `-execute` exécute immédiatement les arguments accumulés **jusqu’à présent** (en y ajoutant les `-common_args`).&#x20;

> Bénéfice : 1 seul process, des milliers d’images traitées d’affilée, **quasi sans overhead** de relance.

### B) Mode **persistant** : `-stay_open`

* Lance exiftool une fois avec `-stay_open True -@ ARGFILE`, alimente `ARGFILE` (ou `-@ -` en pipe) avec des blocs terminés par `-execute`, puis fermes proprement avec `-stay_open\nFalse`.&#x20;
* (La doc détaille même la synchronisation via un numéro `-executeNUM` renvoyé dans `{readyNUM}`.)&#x20;

> Bénéfice : identique à A), mais **parfait** pour des intégrations scriptées/long-lived.

---

## 2) Écrire plus vite : choisir la bonne option d’overwrite

* `-overwrite_original` remplace le fichier via un fichier temporaire **en une opération** ; c’est le choix **plus rapide** pour des gros volumes.&#x20;
* `-overwrite_original_in_place` ajoute une étape pour préserver certains attributs (création, tags Finder, etc.), **mais plus lente** : à réserver quand c’est nécessaire.&#x20;

---

## 3) Éviter les écritures inutiles (vrai gain sur 50 Go)

* Si tu utilises la méthode **B “ajouter si absent”** (`-if 'not $PersonInImage=~/\bNom\b/i' -PersonInImage+=Nom`), exiftool **ne réécrit pas** les fichiers qui possèdent déjà la valeur → **gros gain I/O** sur des relances. (Tu peux chaîner chaque nom avec `-execute` et factoriser l’image via `-common_args`.)&#x20;
* Alternative robuste : **A “supprimer puis ajouter”** (`-TAG-=Nom -TAG+=Nom`) garantit zéro doublon final mais **force une écriture** même si la valeur était déjà propre. À privilégier pour “nettoyage” initial, puis passer à B pour les relances. *(Technique recommandée par la doc pour les listes ; cf. exemples de +/– sur listes.)*&#x20;

---

## 4) batcher intelligemment

* **Journalise les statuts** avec `-efileNUM file.txt` : tu peux demander d’écrire dans des fichiers distincts les listes de *updated*, *unchanged*, *errors*, etc., en combinant les flags (2,4,8,16…). Très pratique pour **reprendre** uniquement les “inchangés” ou “en erreur” lors d’une passe suivante.&#x20;

---

## 5) Exemple “gros dossier” performant

### Variante argfile (recommandée, simple à rejouer)

`args.txt` (généré par ton script à partir des sidecars) :

```
# Options communes (appliquées à tous les blocs)
-common_args
-overwrite_original
-q
# (ajoute -api NoDups=1 si tu empiles plusieurs += pour un même fichier dans le même bloc)
# --- image 1 ---
-if not $XMP-iptcExt:PersonInImage=~/\bAnthony Vincent\b/i
-XMP-iptcExt:PersonInImage+=Anthony Vincent
-execute
-if not $XMP-iptcExt:PersonInImage=~/\bBernard\b/i
-XMP-iptcExt:PersonInImage+=Bernard
-execute
-if not $XMP-iptcExt:PersonInImage=~/\bJean\b/i
-XMP-iptcExt:PersonInImage+=Jean
-execute
# on passe le chemin cible une seule fois si tu factorises par image :
# (voir modèle “3 commandes dans 1” de la doc)
# --- image N ---
…
```

Lancement :

```bash
exiftool -@ args.txt
```

> Pattern “3 commandes dans 1” avec `-execute` et `-common_args` = **référence** dans la doc.&#x20;

### Variante `-stay_open` (si tu préfères un démon exiftool)

```bash
exiftool -stay_open True -@ - <<'EOF'
-overwrite_original
-q
# bloc image 1
-if not $XMP-iptcExt:PersonInImage=~/\bAnthony Vincent\b/i
-XMP-iptcExt:PersonInImage+=Anthony Vincent
-execute
…
-stay_open
False
EOF
```

> Le protocole d’échange `-stay_open … -@ … -execute … -stay_open False` est documenté, avec même les astuces de synchro `{readyNUM}`.&#x20;

---

## 6) Petits plus

* **Silence la sortie** pour réduire l’I/O console avec `-q` (double `-q` pour encore moins).
* Si tu as des **vidéos** (MP4/MOV), l’écriture peut être plus lourde. Ta suite a déjà des options vidéo (QuickTimeUTC, etc.) — garde-les, mais évite de toucher aux vidéos si le sidecar n’apporte rien de neuf. (Tes tests montrent l’inclusion conditionnelle des champs QuickTime).&#x20;
* Si tu veux **préserver horodatages** FS, c’est `-preserve`/`-P` (non listé dans l’extrait cité), mais ça **n’accélère pas**.
* **Ne pas utiliser `-overwrite_original_in_place`** pour la perf : la doc précise l’étape supplémentaire → plus lent.&#x20;

---

## 7) Parallélisation pragmatique

ExifTool est essentiellement **mono-processus**. Pour accélérer sur 50 Go :

* **Découpe** par albums/sous-dossiers et lance **2–4 exécutions en parallèle** sur SSD/NVMe (évite 100 % CPU *et* 100 % disque).

---

### Conclusion

Pour un Takeout massif, la **grosse différence** vient de :

1. **Réduire les relances** (un seul exiftool via `-@`/`-execute`/`-common_args` ou `-stay_open`).  &#x20;
2. **Limiter les écritures** (conditions `-if` ou lot bien ciblé).
3. **Choisir `-overwrite_original`** pour la vitesse.&#x20;
4. **Journaliser** avec `-efile` pour relancer efficacement.&#x20;

---

## 8) Implémentation dans le projet

**Notre choix final** : Nous avons implémenté l'**Option A "supprimer puis ajouter"** pour garantir zéro doublon.

### Approche adoptée

```python
# Mode append-only avec déduplication (nouveau comportement)
if meta.people:
    normalized_people = [normalize_person_name(person) for person in meta.people]
    for person in normalized_people:
        args.extend([
            f"-XMP-iptcExt:PersonInImage-={person}",
            f"-XMP-iptcExt:PersonInImage+={person}"
        ])
```

### Avantages de cette implémentation

✅ **Déduplication robuste** : Élimine les doublons pré-existants dans les fichiers
✅ **Normalisation intelligente** : "anthony vincent" → "Anthony Vincent", gestion des "McDonald", "O'Connor", etc.
✅ **Performance optimisée** : Journalisation `-efile` pour reprises intelligentes
✅ **Stratégie `-wm` différenciée** : Pas de `-wm cg` avec `-TAG-=` (incompatible), réactivé pour les autres champs
✅ **Support Unicode complet** : `-codedcharacterset=utf8` pour accents et emoji

### Commande générée type

```bash
exiftool \
  -overwrite_original \
  -charset filename=UTF8 -charset iptc=UTF8 -charset exif=UTF8 \
  -codedcharacterset=utf8 \
  -XMP-iptcExt:PersonInImage-="Anthony Vincent" -XMP-iptcExt:PersonInImage+="Anthony Vincent" \
  -XMP-iptcExt:PersonInImage-=Bernard        -XMP-iptcExt:PersonInImage+=Bernard        \
  -XMP-dc:Subject-="Anthony Vincent"         -XMP-dc:Subject+="Anthony Vincent"         \
  -XMP-dc:Subject-=Bernard                   -XMP-dc:Subject+=Bernard                   \
  -wm cg \
  -CreateDate="2024:01:15 10:30:00" \
  -GPSLatitude=48.8566 \
  img.jpg
```

### Journalisation pour reprises

```bash
# En mode batch : ajout des options -efile pour journalisation
exiftool \
  -charset filename=UTF8 \
  -@ args.txt \
  -common_args \
  -overwrite_original \
  -charset iptc=UTF8 -charset exif=UTF8 \
  -codedcharacterset=utf8 \
  -q -q \
  -efile1 error_files.txt \
  -efile2 unchanged_files.txt \
  -efile4 failed_condition_files.txt \
  -efile8 updated_files.txt
```

Cette approche garantit **zéro doublon final** tout en conservant d'excellentes performances grâce aux reprises intelligentes via les logs `-efile`.
````

## File: AUDIT_TESTS_AXES.md
````markdown
# AUDIT DES TESTS - COUVERTURE DES AXES SÉMANTIQUES

## Récapitulatif des Axes

### Axe 1 — Sémantique d'écriture (3 modes)
1. **Append-only** : `-wm cg` + `-if not $TAG` pour scalaires (Description, GPS, dates)
2. **Robuste (nettoyage)** : `-TAG-=val` puis `-TAG+=val` pour listes (PersonInImage, Keywords) → zéro doublon
3. **Conditionnel (perf)** : `-if 'not $TAG=~/\bval\b/i'` puis `-TAG+=val` → optimisation pour relances

### Axe 2 — Stratégie d'exécution
1. **Unitaire** : un appel exiftool par fichier
2. **Batch** : un seul process exiftool avec `-@` args.txt + blocs

---

## AUDIT PAR MODULE DE TESTS

### ✅ test_exif_writer.py (14/14 tests)
**Couverture :**
- ✅ **Robuste** : `test_build_remove_then_add_args_for_people` valide `-TAG-=` puis `-TAG+=`
- ✅ **Append-only** : `test_build_description_args_conditional` valide `-wm cg` + `-if not $TAG`
- ✅ **Conditionnel** : `test_build_conditional_add_args_for_people` valide regex + conditions
- ✅ **Unitaire** : tous les tests utilisent `write_metadata` (appel unitaire)
- ✅ **Helper** : `add_remove_then_add` testé pour garantir l'ordre

**Commentaires :** ✅ Cohérents avec la nouvelle sémantique

### ✅ test_hybrid_approach.py (2/2 tests)
**Couverture :**
- ✅ **Robuste** : valide que `-TAG-=` + `-TAG+=` élimine les doublons
- ✅ **Idempotence** : plusieurs passages donnent le même résultat
- ✅ **Unitaire** : utilise `write_metadata`

**Commentaires :** ✅ Parfaitement alignés sur l'approche robuste

### ✅ test_integration.py (7/7 tests)
**Couverture :**
- ✅ **Append-only** : `test_append_only_mode` valide la préservation des données existantes
- ✅ **Overwrite** : `test_explicit_overwrite_behavior` valide l'accumulation en mode écrasement
- ✅ **GPS** : `test_write_and_read_gps` valide les références GPS N/S/E/W
- ✅ **Encodage** : `test_write_and_read_albums` valide UTF-8 avec accents
- ✅ **Unitaire** : tous utilisent `process_sidecar_file` (unitaire)

**Commentaires :** ✅ Bien mis à jour, logique métier cohérente

### ✅ test_processor_batch.py (15/15 tests)
**Couverture :**
- ✅ **Batch** : tous les tests utilisent `process_batch` avec `-@` args.txt
- ✅ **Robuste** : les tests valident l'approche remove-then-add par défaut
- ✅ **Échecs** : `test_process_directory_batch_clean_sidecars` corrigé pour la bonne logique métier
- ⚠️ **Nettoyage** : logique corrigée (sidecar conservé si échec exiftool)

**Commentaires :** ✅ Corrigés pour respecter la logique métier

### ✅ test_improvements.py (17/17 tests)
**Couverture :**
- ✅ **Batch + nettoyage** : tests corrigés pour la vraie logique métier
- ✅ **Échecs vs succès** : distinction claire entre vraie erreur et "condition failed"
- ❌ **Ancien test** : `test_batch_sidecar_cleanup_with_condition_failure` supprimé (logique incorrecte)
- ✅ **Nouveaux tests** : ajout de tests avec vraie logique métier

**Commentaires :** ✅ Complètement refactorisés avec logique correcte

### ✅ test_end_to_end.py (1/1 test)
**Couverture :**
- ✅ **Robuste** : valide l'approche complete end-to-end avec déduplication
- ✅ **Normalisation** : valide `normalize_keyword` et `normalize_person_name`
- ✅ **Unitaire** : utilise `process_sidecar_file`

**Commentaires :** ✅ Cohérent

### 🔍 TESTS À SURVEILLER

#### test_cli.py (17/17 tests)
**État :** ✅ Passent mais non audités en détail
**Action :** Vérifier que les options CLI correspondent aux axes sémantiques

#### test_deduplication_robuste.py (7/7 tests)  
**État :** ✅ Passent et semblent cohérents avec l'approche robuste
**Action :** Confirmer que ces tests valident bien le comportement `-TAG-=` + `-TAG+=`

#### test_processor.py (7/7 tests)
**État :** ✅ Passent - tests unitaires du processor principal
**Action :** Vérifier cohérence avec les modes append_only vs overwrite

#### test_resume_handler.py (12/12 tests)
**État :** ✅ Passent - gestion des reprises de traitement
**Action :** Vérifier que la logique de reprise est cohérente avec les échecs/succès

#### test_sidecar.py (22/22 tests)
**État :** ✅ Passent - parsing JSON des sidecars
**Action :** Tests orthogonaux aux axes, probablement OK

---

## RÉSUMÉ DE L'AUDIT

### ✅ CORRECTIONS EFFECTUÉES
1. **Tests batch nettoyage** : Logique métier corrigée (pas de suppression sidecar si échec exiftool)
2. **Tests integration** : Cohérence avec les axes append-only/robuste/overwrite  
3. **Tests improvements** : Refactorisation complète avec vraie logique métier
4. **Commentaires** : Mise à jour pour refléter les vrais comportements

### 🎯 COUVERTURE DES AXES
- ✅ **Axe 1 - Sémantique** : 3 modes (append-only, robuste, conditionnel) couverts
- ✅ **Axe 2 - Exécution** : 2 stratégies (unitaire, batch) couvertes  
- ✅ **Helper** : `add_remove_then_add` garantit l'ordre et évite les coquilles
- ✅ **Edge cases** : échecs exiftool, encodage UTF-8, GPS, normalisation

### 📊 STATUT FINAL
**129/129 tests passent** avec logique métier cohérente et couverture complète des axes sémantiques.

### 🔍 ACTIONS DE SUIVI
1. Audit rapide des 5 modules non détaillés (CLI, deduplication_robuste, processor, resume_handler, sidecar)
2. Vérification que les options CLI correspondent aux axes
3. Documentation des choix de design dans les commentaires de code
````

## File: doc_exiftool_full.txt
````
exiftool Application Documentation
NAME
SYNOPSIS
Reading
Writing
Copying
Other
DESCRIPTION
OPTIONS
Option Overview
Option Details
Tag operations
Input-output text formatting
Processing control
Other options
Special features
Utilities
Advanced options
Advanced formatting feature
Helper functions
WINDOWS UNICODE FILE NAMES
WRITING READ-ONLY FILES
READING EXAMPLES
WRITING EXAMPLES
COPYING EXAMPLES
RENAMING EXAMPLES
GEOTAGGING EXAMPLES
PIPING EXAMPLES
INTERRUPTING EXIFTOOL
EXIT STATUS
AUTHOR
SEE ALSO
NAME
exiftool - Read and write meta information in files

SYNOPSIS
Reading
exiftool [OPTIONS] [-TAG...] [--TAG...] FILE...

Writing
exiftool [OPTIONS] -TAG[+-^<]=[VALUE]... FILE...

Copying
exiftool [OPTIONS] -tagsFromFile SRCFILE [-[DSTTAG<]SRCTAG...] FILE...

Other
exiftool [ -ver | -list[w|f|r|wf|g[NUM]|d|x|geo] ]

For specific examples, see the EXAMPLES sections below.

This documentation is displayed if exiftool is run without an input FILE when one is expected.

DESCRIPTION
A command-line interface to Image::ExifTool, used for reading and writing meta information in a variety of file types. FILE is one or more source file names, directory names, or - for the standard input. Metadata is read from source files and printed in readable form to the console (or written to output text files with -w).

To write or delete metadata, tag values are assigned using -TAG=[VALUE], and/or the -geotag, -csv= or -json= options. To copy or move metadata, the -tagsFromFile feature is used. By default the original files are preserved with _original appended to their names -- be sure to verify that the new files are OK before erasing the originals. Once in write mode, exiftool will ignore any read-specific options.

Note: If FILE is a directory name then only supported file types in the directory are processed (in write mode only writable types are processed). However, files may be specified by name, or the -ext option may be used to force processing of files with any extension. Hidden files in the directory are also processed. Adding the -r option causes subdirectories to be processed recursively, but subdirectories with names beginning with "." are skipped unless -r. is used.

Below is a list of file types and meta information formats currently supported by ExifTool (r = read, w = write, c = create):

File Types
------------+-------------+-------------+-------------+------------
360   r/w   | DPX   r     | JNG   r/w   | ODP   r     | RSRC  r
3FR   r     | DR4   r/w/c | JP2   r/w   | ODS   r     | RTF   r
3G2   r/w   | DSS   r     | JPEG  r/w   | ODT   r     | RW2   r/w
3GP   r/w   | DV    r     | JSON  r     | OFR   r     | RWL   r/w
7Z    r     | DVB   r/w   | JXL   r/w   | OGG   r     | RWZ   r
A     r     | DVR-MS r    | K25   r     | OGV   r     | RM    r
AA    r     | DYLIB r     | KDC   r     | ONP   r     | SEQ   r
AAC   r     | EIP   r     | KEY   r     | OPUS  r     | SKETCH r
AAE   r     | EPS   r/w   | LA    r     | ORF   r/w   | SO    r
AAX   r/w   | EPUB  r     | LFP   r     | ORI   r/w   | SR2   r/w
ACR   r     | ERF   r/w   | LIF   r     | OTF   r     | SRF   r
AFM   r     | EXE   r     | LNK   r     | PAC   r     | SRW   r/w
AI    r/w   | EXIF  r/w/c | LRV   r/w   | PAGES r     | SVG   r
AIFF  r     | EXR   r     | M2TS  r     | PBM   r/w   | SWF   r
APE   r     | EXV   r/w/c | M4A/V r/w   | PCAP  r     | THM   r/w
ARQ   r/w   | F4A/V r/w   | MACOS r     | PCAPNG r    | TIFF  r/w
ARW   r/w   | FFF   r/w   | MAX   r     | PCD   r     | TNEF  r
ASF   r     | FITS  r     | MEF   r/w   | PCX   r     | TORRENT r
AVI   r     | FLA   r     | MIE   r/w/c | PDB   r     | TTC   r
AVIF  r/w   | FLAC  r     | MIFF  r     | PDF   r/w   | TTF   r
AZW   r     | FLIF  r/w   | MKA   r     | PEF   r/w   | TXT   r
BMP   r     | FLV   r     | MKS   r     | PFA   r     | VCF   r
BPG   r     | FPF   r     | MKV   r     | PFB   r     | VNT   r
BTF   r     | FPX   r     | MNG   r/w   | PFM   r     | VRD   r/w/c
C2PA  r     | GIF   r/w   | MOBI  r     | PGF   r     | VSD   r
CHM   r     | GLV   r/w   | MODD  r     | PGM   r/w   | WAV   r
COS   r     | GPR   r/w   | MOI   r     | PLIST r     | WDP   r/w
CR2   r/w   | GZ    r     | MOS   r/w   | PICT  r     | WEBP  r/w
CR3   r/w   | HDP   r/w   | MOV   r/w   | PMP   r     | WEBM  r
CRM   r/w   | HDR   r     | MP3   r     | PNG   r/w   | WMA   r
CRW   r/w   | HEIC  r/w   | MP4   r/w   | PPM   r/w   | WMV   r
CS1   r/w   | HEIF  r/w   | MPC   r     | PPT   r     | WPG   r
CSV   r     | HTML  r     | MPG   r     | PPTX  r     | WTV   r
CUR   r     | ICC   r/w/c | MPO   r/w   | PS    r/w   | WV    r
CZI   r     | ICO   r     | MQV   r/w   | PSB   r/w   | X3F   r/w
DCM   r     | ICS   r     | MRC   r     | PSD   r/w   | XCF   r
DCP   r/w   | IDML  r     | MRW   r/w   | PSP   r     | XISF  r
DCR   r     | IIQ   r/w   | MXF   r     | QTIF  r/w   | XLS   r
DFONT r     | IND   r/w   | NEF   r/w   | R3D   r     | XLSX  r
DIVX  r     | INSP  r/w   | NKA   r     | RA    r     | XMP   r/w/c
DJVU  r     | INSV  r     | NKSC  r/w   | RAF   r/w   | ZIP   r
DLL   r     | INX   r     | NRW   r/w   | RAM   r     |
DNG   r/w   | ISO   r     | NUMBERS r   | RAR   r     |
DOC   r     | ITC   r     | NXD   r     | RAW   r/w   |
DOCX  r     | J2C   r     | O     r     | RIFF  r     |

Meta Information
----------------------+----------------------+---------------------
EXIF           r/w/c  |  CIFF           r/w  |  Ricoh RMETA    r
GPS            r/w/c  |  AFCP           r/w  |  Picture Info   r
IPTC           r/w/c  |  Kodak Meta     r/w  |  Adobe APP14    r
XMP            r/w/c  |  FotoStation    r/w  |  MPF            r
MakerNotes     r/w/c  |  PhotoMechanic  r/w  |  Stim           r
Photoshop IRB  r/w/c  |  JPEG 2000      r    |  DPX            r
ICC Profile    r/w/c  |  DICOM          r    |  APE            r
MIE            r/w/c  |  Flash          r    |  Vorbis         r
JFIF           r/w/c  |  FlashPix       r    |  SPIFF          r
Ducky APP12    r/w/c  |  QuickTime      r    |  DjVu           r
PDF            r/w/c  |  Matroska       r    |  M2TS           r
PNG            r/w/c  |  MXF            r    |  PE/COFF        r
Canon VRD      r/w/c  |  PrintIM        r    |  AVCHD          r
Nikon Capture  r/w/c  |  FLAC           r    |  ZIP            r
GeoTIFF        r/w/c  |  ID3            r    |  (and more)
OPTIONS
Case is not significant for any command-line option (including tag and group names), except for single-character options when the corresponding upper-case option exists. Many single-character options have equivalent long-name versions (shown in brackets), and some options have inverses which are invoked with a leading double-dash. Unrecognized options are interpreted as tag names (for this reason, multiple single-character options may NOT be combined into one argument). Contrary to standard practice, options may appear after source file names on the exiftool command line.

Option Overview
Tag operations

-TAG or --TAG                    Extract or exclude specified tag
-TAG[+-^]=[VALUE]                Write new value for tag
-TAG[+-]<=DATFILE                Write tag value from contents of file
-[+]TAG[+-]<SRCTAG               Copy tag value (see -tagsFromFile)

-tagsFromFile SRCFILE            Copy tag values from file
-x TAG      (-exclude)           Exclude specified tag
Input-output text formatting

-args       (-argFormat)         Format metadata as exiftool arguments
-b          (-binary)            Output metadata in binary format
-c FMT      (-coordFormat)       Set format for GPS coordinates
-charset [[TYPE=]CHARSET]        Specify encoding for special characters
-csv[[+]=CSVFILE]                Export/import tags in CSV format
-csvDelim STR                    Set delimiter for CSV file
-d FMT      (-dateFormat)        Set format for date/time values
-D          (-decimal)           Show tag ID numbers in decimal
-E,-ex,-ec  (-escape(HTML|XML|C))Escape tag values for HTML, XML or C
-f          (-forcePrint)        Force printing of all specified tags
-g[NUM...]  (-groupHeadings)     Organize output by tag group
-G[NUM...]  (-groupNames)        Print group name for each tag
-h          (-htmlFormat)        Use HTML formatting for output
-H          (-hex)               Show tag ID numbers in hexadecimal
-htmlDump[OFFSET]                Generate HTML-format binary dump
-j[[+]=JSONFILE] (-json)         Export/import tags in JSON format
-l          (-long)              Use long 2-line output format
-L          (-latin)             Use Windows Latin1 encoding
-lang [LANG]                     Set current language
-listItem INDEX                  Extract specific item from a list
-n          (--printConv)        No print conversion
-p[-] STR   (-printFormat)       Print output in specified format
-php                             Export tags as a PHP Array
-plot                            Output tags as SVG plot file
-s[NUM]     (-short)             Short output format (-s for tag names)
-S          (-veryShort)         Very short output format
-sep STR    (-separator)         Set separator string for list items
-sort                            Sort output alphabetically
-struct                          Enable output of structured information
-t          (-tab)               Output in tab-delimited list format
-T          (-table)             Output in tabular format
-v[NUM]     (-verbose)           Print verbose messages
-w[+|!] EXT (-textOut)           Write (or overwrite!) output text files
-W[+|!] FMT (-tagOut)            Write output text file for each tag
-Wext EXT   (-tagOutExt)         Write only specified file types with -W
-X          (-xmlFormat)         Use RDF/XML output format
Processing control

-a          (-duplicates)        Allow duplicate tags to be extracted
-e          (--composite)        Do not generate composite tags
-ee[NUM]    (-extractEmbedded)   Extract information from embedded files
-ext[+] EXT (-extension)         Process files with specified extension
-F[OFFSET]  (-fixBase)           Fix the base for maker notes offsets
-fast[NUM]                       Increase speed when extracting metadata
-fileOrder[NUM] [-]TAG           Set file processing order
-i DIR      (-ignore)            Ignore specified directory name
-if[NUM] EXPR                    Conditionally process files
-m          (-ignoreMinorErrors) Ignore minor errors and warnings
-o OUTFILE  (-out)               Set output file or directory name
-overwrite_original              Overwrite original by renaming tmp file
-overwrite_original_in_place     Overwrite original by copying tmp file
-P          (-preserve)          Preserve file modification date/time
-password PASSWD                 Password for processing protected files
-progress[NUM][:[TITLE]]         Show file progress count
-q          (-quiet)             Quiet processing
-r[.]       (-recurse)           Recursively process subdirectories
-scanForXMP                      Brute force XMP scan
-u          (-unknown)           Extract unknown tags
-U          (-unknown2)          Extract unknown binary tags too
-wm MODE    (-writeMode)         Set mode for writing/creating tags
-z          (-zip)               Read/write compressed information
Other options

-@ ARGFILE                       Read command-line arguments from file
-k          (-pause)             Pause before terminating
-list[w|f|wf|g[NUM]|d|x]         List various exiftool capabilities
-ver                             Print exiftool version number
--                               End of options
Special features

-diff FILE2                      Compare metadata with another file
-geotag TRKFILE                  Geotag images from specified GPS log
-globalTimeShift SHIFT           Shift all formatted date/time values
-use MODULE                      Add features from plug-in module
Utilities

-delete_original[!]              Delete "_original" backups
-restore_original                Restore from "_original" backups
Advanced options

-api OPT[[^]=[VAL]]              Set ExifTool API option
-common_args                     Define common arguments
-config CFGFILE                  Specify configuration file name
-echo[NUM] TEXT                  Echo text to stdout or stderr
-efile[NUM][!] TXTFILE           Save names of files with errors
-execute[NUM]                    Execute multiple commands on one line
-fileNUM ALTFILE                 Load tags from alternate file
-list_dir                        List directories, not their contents
-srcfile FMT                     Process a different source file
-stay_open FLAG                  Keep reading -@ argfile even after EOF
-userParam PARAM[[^]=[VAL]]      Set user parameter (API UserParam opt)
Option Details
Tag operations
-TAG
Extract information for the specified tag (eg. -CreateDate). Multiple tags may be specified in a single command. A tag name is the handle by which a piece of information is referenced. See Image::ExifTool::TagNames for documentation on available tag names. A tag name may include leading group names separated by colons (eg. -EXIF:CreateDate, or -Doc1:XMP:Creator), and each group name may be prefixed by a digit to specify family number (eg. -1IPTC:City). (Note that the API SavePath and SaveFormat options must be used for the family 5 and 6 groups respectively to be available.) Use the -listg option to list available group names by family.

A special tag name of All may be used to indicate all meta information (ie. -All). This is particularly useful when a group name is specified to extract all information in a group (but beware that unless the -a option is also used, some tags in the group may be suppressed by same-named tags in other groups). The wildcard characters ? and * may be used in a tag name to match any single character and zero or more characters respectively. These may not be used in a group name, with the exception that a group name of * (or All) may be used to extract all instances of a tag (as if -a was used). Note that arguments containing wildcards must be quoted on the command line of most systems to prevent shell globbing.

A # may be appended to the tag name to disable the print conversion on a per-tag basis (see the -n option). This may also be used when writing or copying tags.

If no tags are specified, all available information is extracted (as if -All had been specified).

Note: Descriptions, not tag names, are shown by default when extracting information. Use the -s option to see the tag names instead.

--TAG
Exclude specified tag from extracted information. Same as the -x option. Group names and wildcards are permitted as described above for -TAG. Once excluded from the output, a tag may not be re-included by a subsequent option. May also be used following a -tagsFromFile option to exclude tags from being copied (when redirecting to another tag, it is the source tag that should be excluded), or to exclude groups from being deleted when deleting all information (eg. -all= --exif:all deletes all but EXIF information). But note that this will not exclude individual tags from a group delete (unless a family 2 group is specified, see note 4 below). Instead, individual tags may be recovered using the -tagsFromFile option (eg. -all= -tagsfromfile @ -artist).

To speed processing when reading XMP, exclusions in XMP groups also bypass processing of the corresponding XMP property and any contained properties. For example, --xmp-crs:all may speed processing significantly in cases where a large number of XMP-crs tags exist. To use this feature to bypass processing of a specific XMP property, the property name must be used instead of the ExifTool tag name (eg. --xmp-crs:dabs). Also, XMP-all may be used to to indicate any XMP namespace (eg. --xmp-all:dabs).

-TAG[+-^]=[VALUE]
Write a new value for the specified tag (eg. -comment=wow), or delete the tag if no VALUE is given (eg. -comment=). += and -= are used to add or remove existing entries from a list, or to shift date/time values (see Image::ExifTool::Shift.pl and notes 6 and 7 below for more details). += may also be used to increment numerical values (or decrement if VALUE is negative), and -= may be used to conditionally delete or replace a tag (see "WRITING EXAMPLES" for examples). ^= is used to write an empty string instead of deleting the tag when no VALUE is given, but otherwise it is equivalent to =. (Note that the caret must be quoted on the Windows command line.)

TAG may contain one or more leading family 0, 1, 2 or 7 group names, prefixed by optional family numbers, and separated colons. If no group name is specified, the tag is created in the preferred group, and updated in any other location where a same-named tag already exists. The preferred group in JPEG and TIFF-format images is the first group in the following list where TAG is valid: 1) EXIF, 2) IPTC, 3) XMP.

The wildcards * and ? may be used in tag names to assign the same value to multiple tags. When specified with wildcards, "Unsafe" tags are not written. A tag name of All is equivalent to * (except that it doesn't require quoting, while arguments with wildcards do on systems with shell globbing), and is often used when deleting all metadata (ie. -All=) or an entire group (eg. -XMP-dc:All=, see note 4 below). Note that not all groups are deletable, and that the JPEG APP14 "Adobe" group is not removed by default with -All= because it may affect the appearance of the image. However, color space information is removed, so the colors may be affected (but this may be avoided by copying back the tags defined by the ColorSpaceTags shortcut). Use the -listd option for a complete list of deletable groups, and see note 5 below regarding the "APP" groups. Also, within an image some groups may be contained within others, and these groups are removed if the containing group is deleted:

JPEG Image:
- Deleting EXIF or IFD0 also deletes ExifIFD, GlobParamIFD,
  GPS, IFD1, InteropIFD, MakerNotes, PrintIM and SubIFD.
- Deleting ExifIFD also deletes InteropIFD and MakerNotes.
- Deleting Photoshop also deletes IPTC.

TIFF Image:
- Deleting EXIF only removes ExifIFD which also deletes
  InteropIFD and MakerNotes.

MOV/MP4 Video:
- Deleting ItemList also deletes Keys tags.
Notes:

1) Many tag values may be assigned in a single command. If two assignments affect the same tag, the latter takes precedence (except for list-type tags, for which both values are written).

2) In general, MakerNotes tags are considered "Permanent", and may be edited but not created or deleted individually. This avoids many potential problems, including the inevitable compatibility problems with OEM software which may be very inflexible about the information it expects to find in the maker notes.

3) Changes to PDF files by ExifTool are reversible (by deleting the update with -PDF-update:all=) because the original information is never actually deleted from the file. So ExifTool alone may not be used to securely edit metadata in PDF files.

4) Specifying -GROUP:all= deletes the entire group as a block only if a single family 0 or 1 group is specified. Otherwise all deletable tags in the specified group(s) are removed individually, and in this case is it possible to exclude individual tags from a mass delete. For example, -time:all --Exif:Time:All removes all deletable Time tags except those in the EXIF. This difference also applies if family 2 is specified when deleting all groups. For example, -2all:all= deletes tags individually, while -all:all= deletes entire blocks.

5) The "APP" group names ("APP0" through "APP15") are used to delete JPEG application segments which are not associated with another deletable group. For example, specifying -APP14:All= will NOT delete the APP14 "Adobe" segment because this is accomplished with -Adobe:All. But note that these unnamed APP segments may not be excluded with --APPxx:all when deleting all information.

6) When shifting a value, the shift is applied to the original value of the tag, overriding any other values previously assigned to the tag on the same command line. To shift a date/time value and copy it to another tag in the same operation, use the -globalTimeShift option.

7) The += operator may not be used to shift a List-type date/time tag (eg. XMP-dc:Date) because += is used to add elements to the list. Instead, the -globalTimeShift option should be used.

Special feature: Integer values may be specified in hexadecimal with a leading 0x, and simple rational values may be specified as fractions.

-TAG<=DATFILE or -TAG<=FMT
Set the value of a tag from the contents of file DATFILE. The file name may also be given by a FMT string where %d, %f and %e represent the directory, file name and extension of the original FILE (see the -w option for more details). Note that quotes are required around this argument to prevent shell redirection since it contains a < symbol. If DATFILE/FMT is not provided, the effect is the same as -TAG=, and the tag is simply deleted. +<= or -<= may also be used to add or delete specific list entries, or to shift date/time values.

-tagsFromFile SRCFILE or FMT
Copy tag values from SRCFILE to FILE. Tag names on the command line after this option specify the tags to be copied, or excluded from the copy. Wildcards are permitted in these tag names. If no tags are specified, then all possible tags (see note 1 below) from the source file are copied to same-named tags in the preferred location of the output file (the same as specifying -all). More than one -tagsFromFile option may be used to copy tags from multiple files.

By default, this option will update any existing and writable same-named tags in the output FILE, but will create new tags only in their preferred groups. This allows some information to be automatically transferred to the appropriate group when copying between images of different formats. However, if a group name is specified for a tag then the information is written only to this group (unless redirected to another group, see below). If All is used as a group name, then the specified tag(s) are written to the same family 1 group they had in the source file (ie. the same specific location, like ExifIFD or XMP-dc). For example, the common operation of copying all writable tags to the same specific locations in the output FILE is achieved by adding -all:all. A different family may be specified by adding a leading family number to the group name (eg. -0all:all preserves the same general location, like EXIF or XMP).

SRCFILE may be the same as FILE to move information around within a single file. In this case, @ may be used to represent the source file (ie. -tagsFromFile @), permitting this feature to be used for batch processing multiple files. Specified tags are then copied from each file in turn as it is rewritten. For advanced batch use, the source file name may also be specified using a FMT string in which %d, %f and %e represent the directory, file name and extension of FILE. (eg. the current FILE would be represented by %d%f.%e, with the same effect as @). See the -w option for FMT string examples.

A powerful redirection feature allows a destination tag to be specified for each copied tag. With this feature, information may be written to a tag with a different name or group. This is done using "'-DSTTAG<SRCTAG'" or "'-SRCTAG>DSTTAG'" on the command line after -tagsFromFile, and causes the value of SRCTAG to be copied from SRCFILE and written to DSTTAG in FILE. Has no effect unless SRCTAG exists in SRCFILE. Note that this argument must be quoted to prevent shell redirection, and there is no = sign as when assigning new values. Source and/or destination tags may be prefixed by a group name and/or suffixed by #. Wildcards are allowed in both the source and destination tag names. A destination group and/or tag name of All or * writes to the same family 1 group and/or tag name as the source (but the family may be specified by adding a leading number to the group name, eg. 0All writes to the same family 0 group as the source). If no destination group is specified, the information is written to the preferred group. Whitespace around the > or < is ignored. As a convenience, -tagsFromFile @ is assumed for any redirected tags which are specified without a prior -tagsFromFile option. Copied tags may also be added or deleted from a list with arguments of the form "'-SRCTAG+<DSTTAG'" or "'-SRCTAG-<DSTTAG'" (but see Note 5 below).

An extension of the redirection feature allows strings involving tag names to be used on the right hand side of the < symbol with the syntax "'-DSTTAG<STR'", where tag names in STR are prefixed with a $ symbol. See the -p option and the "Advanced formatting feature" section for more details about this syntax. Strings starting with a = sign must insert a single space after the < to avoid confusion with the <= operator which sets the tag value from the contents of a file. A single space at the start of the string is removed if it exists, but all other whitespace in the string is preserved. See note 8 below about using the redirection feature with list-type stags, shortcuts or when using wildcards in tag names.

See "COPYING EXAMPLES" for examples using -tagsFromFile.

Notes:

1) Some tags (generally tags which may affect the appearance of the image) are considered "Unsafe" to write, and are only copied if specified explicitly (ie. no wildcards). See the tag name documentation for more details about "Unsafe" tags.

2) Be aware of the difference between excluding a tag from being copied (--TAG), and deleting a tag (-TAG=). Excluding a tag prevents it from being copied to the destination image, but deleting will remove a pre-existing tag from the image.

3) The maker note information is copied as a block, so it isn't affected like other information by subsequent tag assignments on the command line, and individual makernote tags may not be excluded from a block copy. Also, since the PreviewImage referenced from the maker notes may be rather large, it is not copied, and must be transferred separately if desired.

4) The order of operations is to copy all specified tags at the point of the -tagsFromFile option in the command line. Any tag assignment to the right of the -tagsFromFile option is made after all tags are copied. For example, new tag values are set in the order One, Two, Three then Four with this command:

exiftool -One=1 -tagsFromFile s.jpg -Two -Four=4 -Three d.jpg
This is significant in the case where an overlap exists between the copied and assigned tags because later operations may override earlier ones.

5) The normal behaviour of copied tags differs from that of assigned tags for list-type tags and conditional replacements because each copy operation on a tag overrides any previous operations. While this avoids duplicate list items when copying groups of tags from a file containing redundant information, it also prevents values of different tags from being copied into the same list when this is the intent. To accumulate values from different operations into the same list, add a + after the initial - of the argument. For example:

exiftool -tagsfromfile @ '-subject<make' '-+subject<model' ...
Similarly, -+DSTTAG must be used when conditionally replacing a tag to prevent overriding earlier conditions.

6) The -a option (allow duplicate tags) is always in effect when copying tags from SRCFILE, but the highest priority tag is always copied last so it takes precedence.

7) Structured tags are copied by default when copying tags. See the -struct option for details.

8) With the redirection feature, copying a tag directly (ie. "'-DSTTAG<SRCTAG'") is not the same as interpolating its value inside a string (ie. "'-DSTTAG<$SRCTAG'") for source tags which are list-type tags, shortcut tags, or tag names containing wildcards. When copying directly, the values of each matching source tag are copied individually to the destination tag (as if they were separate assignments). However, when interpolated inside a string, list items and the values of shortcut tags are concatenated (with a separator set by the -sep option), and wildcards are not allowed.Another difference is that a minor warning is generated if a tag doesn't exist when interpolating its value in a string (with $), but isn't when copying the tag directly.

Finally, the behaviour is different when a destination tag or group of All is used. When copying directly, a destination group and/or tag name of All writes to the same family 1 group and/or tag name as the source. But when interpolated in a string, the identity of the source tags are lost and the value is written to all possible groups/tags. For example, the string form must be used in the following command since the intent is to set the value of all existing date/time tags from CreateDate:

exiftool '-time:all<$createdate' -wm w FILE
-x TAG (-exclude)
Exclude the specified tag. There may be multiple -x options. This has the same effect as --TAG on the command line. See the --TAG documentation above for a complete description.

Input-output text formatting
Note that trailing spaces are removed from extracted values for most output text formats. The exceptions are -b, -csv, -j and -X.

-args (-argFormat)
Output information in the form of exiftool arguments, suitable for use with the -@ option when writing. May be combined with the -G option to include group names. This feature may be used to effectively copy tags between images, but allows the metadata to be altered by editing the intermediate file (out.args in this example):

exiftool -args -G1 --filename --directory src.jpg > out.args
exiftool -@ out.args -sep ', ' dst.jpg
Note: Be careful when copying information with this technique since it is easy to write tags which are normally considered "Unsafe". For instance, the FileName and Directory tags are excluded in the example above to avoid renaming and moving the destination file. Also note that the second command above will produce warning messages for any tags which are not writable.

As well, the -sep option should be used as in the second command above to maintain separate list items when writing metadata back to image files, and the -struct option may be used when extracting to preserve structured XMP information.

-b, --b (-binary, --binary)
Output requested metadata in binary format without tag names or descriptions (-b or -binary). This option is mainly used for extracting embedded images or other binary data, but it may also be useful for some text strings since control characters (such as newlines) are not replaced by '.' as they are in the default output. By default, list items are separated by a newline when extracted with the -b option and no terminator is added after each tag value, but the list separator may be changed with a -sep option and a terminator may be set by adding a second -sep option (see the -sep option for details). May be combined with -j, -php or -X to extract binary data in JSON, PHP or XML format, but note that "Unsafe" tags are not extracted as binary unless they are specified explicitly or the API RequestAll option is set to 3 or higher.

With a leading double dash (--b or --binary), tags which contain binary data are suppressed in the output when reading.

-c FMT (-coordFormat)
Set the print format for GPS coordinates. FMT uses the same syntax as a printf format string. The specifiers correspond to degrees, minutes and seconds in that order, but minutes and seconds are optional. For example, the following table gives the output for the same coordinate using various formats:

        FMT                  Output
-------------------    ------------------
"%d deg %d' %.2f"\"    54 deg 59' 22.80"  (default for reading)
"%d %d %.8f"           54 59 22.80000000  (default for copying)
"%d deg %.4f min"      54 deg 59.3800 min
"%.6f degrees"         54.989667 degrees
Notes:

1) To avoid loss of precision, the default coordinate format is different when copying tags using the -tagsFromFile option.

2) If the hemisphere is known, a reference direction (N, S, E or W) is appended to each printed coordinate, but adding a + or - to the format specifier (eg. %+.6f or %-.6f) prints a signed coordinate instead. (+ adds a leading "+" for positive coordinates, but - does not.)

3) This print formatting may be disabled with the -n option to extract coordinates as signed decimal degrees.

-charset [[TYPE=]CHARSET]
If TYPE is ExifTool or not specified, this option sets the ExifTool character encoding for output tag values when reading and input values when writing, with a default of UTF8. If no CHARSET is given, a list of available character sets is returned. Valid CHARSET values are:

CHARSET     Alias(es)        Description
----------  ---------------  ----------------------------------
UTF8        cp65001, UTF-8   UTF-8 characters (default)
Latin       cp1252, Latin1   Windows Latin1 (West European)
Latin2      cp1250           Windows Latin2 (Central European)
Cyrillic    cp1251, Russian  Windows Cyrillic
Greek       cp1253           Windows Greek
Turkish     cp1254           Windows Turkish
Hebrew      cp1255           Windows Hebrew
Arabic      cp1256           Windows Arabic
Baltic      cp1257           Windows Baltic
Vietnam     cp1258           Windows Vietnamese
Thai        cp874            Windows Thai
DOSLatinUS  cp437            DOS Latin US
DOSLatin1   cp850            DOS Latin1
DOSCyrillic cp866            DOS Cyrillic
MacRoman    cp10000, Roman   Macintosh Roman
MacLatin2   cp10029          Macintosh Latin2 (Central Europe)
MacCyrillic cp10007          Macintosh Cyrillic
MacGreek    cp10006          Macintosh Greek
MacTurkish  cp10081          Macintosh Turkish
MacRomanian cp10010          Macintosh Romanian
MacIceland  cp10079          Macintosh Icelandic
MacCroatian cp10082          Macintosh Croatian
TYPE may be FileName to specify the encoding of file names on the command line (ie. FILE arguments). In Windows, this triggers use of wide-character i/o routines, thus providing support for Unicode file names. See the "WINDOWS UNICODE FILE NAMES" section below for details.

Other values of TYPE listed below are used to specify the internal encoding of various meta information formats.

TYPE       Description                                  Default
---------  -------------------------------------------  -------
EXIF       Internal encoding of EXIF "ASCII" strings    (none)
ID3        Internal encoding of ID3v1 information       Latin
IPTC       Internal IPTC encoding to assume when        Latin
            IPTC:CodedCharacterSet is not defined
Photoshop  Internal encoding of Photoshop IRB strings   Latin
QuickTime  Internal encoding of QuickTime strings       MacRoman
RIFF       Internal encoding of RIFF strings            0
See https://exiftool.org/faq.html#Q10 for more information about coded character sets, and the Image::ExifTool Options for more details about the -charset settings.

-csv[[+]=CSVFILE]
Export information in CSV format, or import information if CSVFILE is specified. When importing, the CSV file must be in exactly the same format as the exported file. The first row of the CSVFILE must be the ExifTool tag names (with optional group names) for each column of the file, and values must be separated by commas. A special "SourceFile" column specifies the files associated with each row of information (and a SourceFile of "*" may be used to define default tags to be imported for all files which are combined with any tags specified for the specific SourceFile processed). The -csvDelim option may be used to change the input/output field delimiter if something other than a comma is required.

The following examples demonstrate basic use of the -csv option:

# generate CSV file with common tags from all images in a directory
exiftool -common -csv dir > out.csv

# update metadata for all images in a directory from CSV file
exiftool -csv=a.csv dir
When importing, empty values are ignored unless the -f option is used and the API MissingTagValue is set to an empty string (in which case the tag is deleted). Also, FileName and Directory columns are ignored if they exist (ie. ExifTool will not attempt to write these tags with a CSV import), but all other columns are imported. To force a tag to be deleted, use the -f option and set the value to "-" in the CSV file (or to the MissingTagValue if this API option was used). Multiple databases may be imported in a single command.

Specific tags may be imported from the CSV database by adding -TAG options to the command, or excluded with --TAG, with exclusions taking priority. Group names and wildcards are allowed. If no tags are specified, then all except FileName and Directory are used. Tags are imported in the same order as the database entries.

When exporting a CSV file, the -g or -G option adds group names to the tag headings. If the -a option is used to allow duplicate tag names, the duplicate tags are only included in the CSV output if the column headings are unique. Adding the -G4 option ensures a unique column heading for each tag. The -b option may be added to output binary data, encoded in base64 if necessary (indicated by ASCII "base64:" as the first 7 bytes of the value). Values may also be encoded in base64 if the -charset option is used and the value contains invalid characters.

When exporting specific tags, the CSV columns are arranged in the same order as the specified tags provided the column headings exactly match the specified tag names, otherwise the columns are sorted in alphabetical order.

When importing from a CSV file, only files specified on the command line are processed. Any extra entries in the CSV file are ignored.

List-type tags are stored as simple strings in a CSV file, but the -sep option may be used to split them back into separate items when importing.

Special feature: -csv+=CSVFILE may be used to add items to existing lists. This affects only list-type tags. Also applies to the -j option.

Note that this and the -plot options are fundamentally different than all other output format options because they require information from all input files to be buffered in memory before the output is written. This may result in excessive memory usage when processing a very large number of files with a single command. Also, when used with -csv, the -w option changes to specify a complete file name with no filename formatting codes or append mode allowed, and -W may not be used. When processing a large number of files, it is recommended to either use the JSON (-j) or XML (-X) output format, or use -p to generate a fixed-column CSV file instead of using the -csv option.

-csvDelim STR
Set the delimiter for separating CSV entries for CSV file input/output via the -csv option. STR may contain "\t", "\n", "\r" and "\\" to represent TAB, LF, CR and '\' respectively. A double quote is not allowed in the delimiter. Default is ','.

-d FMT (-dateFormat)
Set the format for date/time tag values. The FMT string may contain formatting codes beginning with a percent character (%) to represent the various components of a date/time value. ExifTool implements 3 format codes internally (see below), but other format codes are system dependent -- consult the strftime man page on your system for details. The default format is equivalent to "%Y:%m:%d %H:%M:%S". This option has no effect on date-only or time-only tags. Requires POSIX::strptime or Time::Piece for the inversion conversion when writing. Only one -d option may be used per command.

Additional format codes implemented internally by ExifTool:

1) %z represents the time zone in "+/-HHMM" format. Adding a colon (ie. %:z) adds a colon separator (eg. "-05:00"). If the date/time value doesn't contain a time zone then %z gives the system time zone for the specified date/time value.

2) %f represents fractional seconds, and supports an optional width to specify the number of digits after the decimal point (eg. %3f would give something like ".437"). Adding a minus sign drops the decimal point (eg. %-3f would give "437").

3) %s represents the number of seconds since 00:00 UTC Jan 1, 1970, taking into account the specified time zone (or system time zone if not specified).

-D (-decimal)
Show tag ID number in decimal when extracting information.

-E, -ex, -ec (-escapeHTML, -escapeXML, -escapeC)
Escape characters in output tag values for HTML (-E), XML (-ex) or C (-ec). For HTML, all characters with Unicode code points above U+007F are escaped as well as the following 5 characters: & (&amp;) ' (&#39;) " (&quot;) > (&gt;) and < (&lt;). For XML, only these 5 characters are escaped. The -E option is implied with -h, and -ex is implied with -X. For C, all control characters and the backslash are escaped. The inverse conversion is applied when writing tags.

-f (-forcePrint)
Force printing of tags even if they don't exist. This option applies to tags specified on the command line, or with the -p, -if (unless the API UndefTags option is set), -fileNUM or -tagsFromFile options. When -f is used, the value of any missing tag is set to a dash (-) by default, but this may be configured via the API MissingTagValue option. -f is also used to add a 'flags' attribute to the -listx output, or to allow tags to be deleted when writing with the -csv=CSVFILE feature.

-g[NUM][:NUM...] (-groupHeadings)
Organize output by tag group. NUM specifies a group family number, and may be 0 (general location), 1 (specific location), 2 (category), 3 (document number), 4 (instance number), 5 (metadata path), 6 (EXIF/TIFF format), 7 (tag ID) or 8 (file number). -g0 is assumed if a family number is not specified. May be combined with other options to add group names to the output. Multiple families may be specified by separating them with colons. By default the resulting group name is simplified by removing any leading Main: and collapsing adjacent identical group names, but this can be avoided by placing a colon before the first family number (eg. -g:3:1). Use the -listg option to list group names for a specified family. The API SavePath and SaveFormat options are automatically enabled if the respective family 5 or 6 group names are requested. See the API GetGroup documentation for more information.

-G[NUM][:NUM...] (-groupNames)
Same as -g but print group name for each tag. -G0 is assumed if NUM is not specified. May be combined with a number of other options to add group names to the output. Note that NUM may be added wherever -G is mentioned in the documentation. See the -g option above for details.

-h (-htmlFormat)
Use HTML table formatting for output. Implies the -E option. The formatting options -D, -H, -g, -G, -l and -s may be used in combination with -h to influence the HTML format.

-H (-hex)
Show tag ID number in hexadecimal when extracting information.

-htmlDump[OFFSET]
Generate a dynamic web page containing a hex dump of the EXIF information. This can be a very powerful tool for low-level analysis of EXIF information. The -htmlDump option is also invoked if the -v and -h options are used together. The verbose level controls the maximum length of the blocks dumped. An OFFSET may be given to specify the base for displayed offsets. If not provided, the EXIF/TIFF base offset is used. Use -htmlDump0 for absolute offsets. Currently only EXIF/TIFF and JPEG information is dumped, but the -u option can be used to give a raw hex dump of other file formats.

-j[[+]=JSONFILE] (-json)
Use JSON (JavaScript Object Notation) formatting for console output, or import JSON file if JSONFILE is specified. This option may be combined with -g to organize the output into objects by group, or -G to add group names to each tag. List-type tags with multiple items are output as JSON arrays unless -sep is used. By default XMP structures are flattened into individual tags in the JSON output, but the original structure may be preserved with the -struct option (this also causes all list-type XMP tags to be output as JSON arrays, otherwise single-item lists would be output as simple strings). The -a option is implied when -json is used, but entries with identical JSON names are suppressed in the output. (-G4 may be used to ensure that all tags have unique JSON names.)

Adding the -D or -H option changes tag values to JSON objects with "val" and "id" fields. Adding -l adds a "desc" field, and a "num" field if the numerical value is different from the converted "val", and "fmt" and "hex" fields for EXIF metadata if the API SaveFormat and SaveBin options are set respectively. The length of the "hex" output is limited by the API LimitLongValues setting. Setting the SaveBin option also causes the original values of Rational tags to be returned in string form as an extra "rat" field. The -b option may be added to output binary data, encoded in base64 if necessary (indicated by ASCII "base64:" as the first 7 bytes of the value), and -t may be added to include tag table information (see -t for details). The JSON output is UTF-8 regardless of any -L or -charset option setting, but the UTF-8 validation is disabled if a character set other than UTF-8 is specified.

Note that ExifTool quotes JSON values only if they don't look like numbers (regardless of the original storage format or the relevant metadata specification). This may be a problem when reading the JSON via a strongly typed language. However, the API StructFormat option may be set to "JSONQ" to force quoting of numbers. As well, the -sep option may be used to convert arrays into strings. For example:

exiftool -j -api structformat=jsonq -sep ", " ...
If JSONFILE is specified, the file is imported and the tag definitions from the file are used to set tag values on a per-file basis. The special "SourceFile" entry in each JSON object associates the information with a specific target file. An object with a missing SourceFile or a SourceFile of "*" defines default tags for all target files which are combined with any tags specified for the specific SourceFile processed. The imported JSON file must have the same format as the exported JSON files with the exception that options exporting JSON objects instead of simple values are not compatible with the import file format (ie. export with -D, -H, -l, or -T is not compatible, and use -G instead of -g). Additionally, tag names in the input JSON file may be suffixed with a # to disable print conversion.

Specific tags may be imported from the JSON database by adding -TAG options to the command, or excluded with --TAG, with exclusions taking priority. Group names and wildcards are allowed. If no tags are specified, then all except FileName and Directory are used. Tags are imported in the same order as the database entries.

Unlike CSV import, empty values are not ignored, and will cause an empty value to be written if supported by the specific metadata type. Tags are deleted by using the -f option and setting the tag value to "-" (or to the MissingTagValue setting if this API option was used). Importing with -j+=JSONFILE causes new values to be added to existing lists.

-l (-long)
Use long 2-line Canon-style output format. Adds a description and unconverted value (if it is different from the converted value) to the XML, JSON or PHP output when -X, -j or -php is used. May also be combined with -listf, -listr or -listwf to add descriptions of the file types.

-L (-latin)
Use Windows Latin1 encoding (cp1252) for output tag values instead of the default UTF-8. When writing, -L specifies that input text values are Latin1 instead of UTF-8. Equivalent to -charset latin.

-lang [LANG]
Set current language for tag descriptions and converted values. LANG is de, fr, ja, etc. Use -lang with no other arguments to get a list of available languages. The default language is en if -lang is not specified. Note that tag/group names are always English, independent of the -lang setting, and translation of warning/error messages has not yet been implemented. May also be combined with -listx to output descriptions in one language only.

By default, ExifTool uses UTF-8 encoding for special characters, but the -L or -charset option may be used to invoke other encodings. Note that ExifTool uses Unicode::LineBreak if available to help preserve the column alignment of the plain text output for languages with a variable-width character set.

Currently, the language support is not complete, but users are welcome to help improve this by submitting their own translations. To submit a translation, follow these steps (you must have Perl installed for this):

1. Download and unpack the latest Image-ExifTool full distribution.

2. 'cd' into the Image-ExifTool directory.

3. Run this command to make an XML file of the desired tags (eg. EXIF):

./exiftool -listx -exif:all > out.xml
4. Copy this text into a file called 'import.pl' in the exiftool directory:

push @INC, 'lib';
require Image::ExifTool::TagInfoXML;
my $file = shift or die "Expected XML file name\n";
$Image::ExifTool::TagInfoXML::makeMissing = shift;
Image::ExifTool::TagInfoXML::BuildLangModules($file,8);
5. Run the 'import.pl' script to Import the XML file, generating the 'MISSING' entries for your language (eg. Russian):

perl import.pl out.xml ru
6. Edit the generated language module lib/Image/ExifTool/Lang/ru.pm, and search and replace all 'MISSING' strings in the file with your translations.

7. Email the module ('ru.pm' in this example) to exiftool@gmail.com

8. Thank you!!

-listItem INDEX
For list-type tags, this causes only the item with the specified index to be extracted. INDEX is 0 for the first item in the list. Negative indices may also be used to reference items from the end of the list. Has no effect on single-valued tags. Also applies to tag values when copying from a tag, and in -if, -p and -fileNUM arguments.

-n (--printConv)
Disable print conversion for all tags. By default, extracted values are converted to a more human-readable format, but the -n option disables this conversion, revealing the machine-readable values. For example:

> exiftool -Orientation -S a.jpg
Orientation: Rotate 90 CW
> exiftool -Orientation -S -n a.jpg
Orientation: 6
The print conversion may also be disabled on a per-tag basis by suffixing the tag name with a # character:

> exiftool -Orientation# -Orientation -S a.jpg
Orientation: 6
Orientation: Rotate 90 CW
These techniques may also be used to disable the inverse print conversion when writing. For example, the following commands all have the same effect:

> exiftool -Orientation='Rotate 90 CW' a.jpg
> exiftool -Orientation=6 -n a.jpg
> exiftool -Orientation#=6 a.jpg
-p[-] STR or FMTFILE (-printFormat)
Print output in the format specified by the given string or file. The argument is interpreted as a string unless a file of that name exists, in which case the string is loaded from the contents of the file. Tag names in the format string or file begin with a $ symbol and may contain leading group names and/or a trailing # (to disable print conversion). Case is not significant. Braces {} may be used around the tag name to separate it from subsequent text (and must be used if subsequent text begins with an alphanumeric character, hyphen, underline, colon or number sign). Use $$ to represent a $ symbol, and $/ for a newline. When the string argument is used (ie. STR), a newline is added to the end of the string unless -p- is specified or the -b option is used.

Multiple -p options may be used. Lines beginning with #[HEAD] and #[TAIL] are output before the first processed file and after the last processed file respectively. Lines beginning with #[SECT] and #[ENDS] are output before and after each section of files. A section is defined as a group of consecutive files with the same section header (eg. files are grouped by directory if #[SECT] contains $directory). Lines beginning with #[BODY] and lines not beginning with # are output for each processed file. Lines beginning with #[IF] are not output, but all BODY lines are skipped if any tag on an IF line doesn't exist. Other lines beginning with # are ignored. (To output a line beginning with #, use #[BODY]#.) For example, this format file:

# this is a comment line
#[HEAD]-- Generated by ExifTool $exifToolVersion --
File: $FileName - $DateTimeOriginal
(f/$Aperture, ${ShutterSpeed}s, ISO $EXIF:ISO)
#[TAIL]-- end --
with this command:

exiftool -p test.fmt a.jpg b.jpg
produces output like this:

-- Generated by ExifTool 13.36 --
File: a.jpg - 2003:10:31 15:44:19
(f/5.6, 1/60s, ISO 100)
File: b.jpg - 2006:05:23 11:57:38
(f/8.0, 1/13s, ISO 100)
-- end --
The values of List-type tags with multiple items, Shortcut tags representing multiple tags, and matching tags when the All group is specified are joined according the -sep option setting when interpolated in the string. (Note that when All is used as a group name, dupicate tags are included regardless of the Duplicates option setting.) When All is used as a tag name, a value of 1 is returned if any tag exists in the specified group, or 0 otherwise (unless the All group is also specified, in which case the values of all matching tags are joined).

The -p output iterates through the family 3 group names, with each sub-document producing additional output when combined with the -ee (ExtractEmbedded) option.

If a specified tag does not exist, a minor warning is issued and the line with the missing tag is not printed. However, the -f option may be used to set the value of missing tags to '-' (but this may be configured via the API MissingTagValue option), or the -m option may be used to ignore minor warnings and leave the missing values empty. Alternatively, -q -q may be used to simply suppress the warning messages.

The "Advanced formatting feature" may be used to modify the values of individual tags within the -p option string.

Note that the API RequestTags option is automatically set for all tags used in the FMTFILE or STR. This allows all other tags to be ignored using -API IgnoreTags=all, resulting in reduced memory usage and increased speed.

-php
Format output as a PHP Array. The -g, -G, -D, -H, -l, -sep and -struct options combine with -php, and duplicate tags are handled in the same way as with the -json option. As well, the -b option may be added to output binary data, and -t may be added to include tag table information (see -t for details). Here is a simple example showing how this could be used in a PHP script:

<?php
eval('$array=' . `exiftool -php -q image.jpg`);
print_r($array);
?>
-plot
Write output for all specified tags and all input files as a single SVG-formatted plot. When combined with this feature, the -w option argument is a complete file name with no format codes and the append feature may not be used. Each tag specified on the command line represents a dataset in the plot (or more for array values or if the Split plot setting is used). Non-numerical values are ignored. Each input file may contribute multiple points to a dataset if it contains sub-documents and the -ee option is used, or if the tag value is a delimited string of numbers (valid delimiters are: space, comma, semicolon, tab and newline). Line, Scatter and Histogram plot types are available. See the API Plot Option and https://exiftool.org/plot.html for more details and information about the plot settings.

-s[NUM] (-short)
Short output format. Prints tag names instead of descriptions. Add NUM or up to 3 -s options for even shorter formats:

-s1 or -s        - print tag names instead of descriptions
-s2 or -s -s     - no extra spaces to column-align values
-s3 or -s -s -s  - print values only (no tag names)
Also effective when combined with -t, -h, -X or -listx options.

-S (-veryShort)
Very short format. The same as -s2 or two -s options. Tag names are printed instead of descriptions, and no extra spaces are added to column-align values.

-sep STR (-separator)
Specify separator string for items in list-type tags. When reading, the default is to join list items with ", ". When writing, this option causes values assigned to list-type tags to be split into individual items at each substring matching STR (otherwise they are not split by default). Space characters in STR match zero or more whitespace characters in the value.

Note that an empty separator ("") is allowed, and will join items with no separator when reading, or split the value into individual characters when writing.

For pure binary output (-b used without -j, -php or -X), the first -sep option specifies a list-item separator, and a second -sep option specifies a terminator for the end of the list (or after each value if not a list). In these strings, \n, \r and \t may be used to represent a newline, carriage return and tab respectively. By default, binary list items are separated by a newline, and no terminator is added.

-sort, --sort
Sort output by tag description, or by tag name if the -s option is used. When sorting by description, the sort order will depend on the -lang option setting. Without the -sort option, tags appear in the order they were specified on the command line, or if not specified, the order they were extracted from the file. By default, tags are organized by groups when combined with the -g or -G option, but this grouping may be disabled with --sort.

-struct, --struct
Output structured XMP information instead of flattening to individual tags. This option works well when combined with the XML (-X) and JSON (-j) output formats. For other output formats, XMP structures and lists are serialized into the same format as when writing structured information (see https://exiftool.org/struct.html for details). When copying, structured tags are copied by default unless --struct is used to disable this feature (although flattened tags may still be copied by specifying them individually unless -struct is used). These options have no effect when assigning new values since both flattened and structured tags may always be used when writing.

-t (-tab)
Output a tab-delimited list of description/values (useful for database import). May be combined with -s to print tag names instead of descriptions, or -S to print tag values only, tab-delimited on a single line. The -t option may be combined with -j, -php or -X to add tag table information (table, tag id, and index for cases where multiple conditional tags exist with the same ID), which allows the corresponding tag to be located in the -listx output.

-T (-table)
Output tag values in table form. Equivalent to -t -S -q -f.

-v[NUM] (-verbose)
Print verbose messages. NUM specifies the level of verbosity in the range 0-5, with higher numbers being more verbose. If NUM is not given, then each -v option increases the level of verbosity by 1. With any level greater than 0, most other options are ignored and normal console output is suppressed unless specific tags are extracted. Using -v0 causes the console output buffer to be flushed after each line (which may be useful to avoid delays when piping exiftool output), and prints the name of each processed file when writing and the new file name when renaming, moving or copying. Verbose levels above -v0 do not flush after each line. Also see the -progress option.

-w[+|!] EXT or FMT (-textOut)
Write console output to files with names ending in EXT, one for each source file. The output file name is obtained by replacing the source file extension (including the '.') with the specified extension (and a '.' is added to the start of EXT if it doesn't already contain one). Alternatively, a FMT string may be used to give more control over the output file name and directory. In the format string, %d, %f and %e represent the directory, filename and extension of the source file, and %c represents a copy number which is automatically incremented if the file already exists. %d includes the trailing '/' if necessary, but %e does not include the leading '.'. For example:

-w %d%f.txt       # same effect as "-w txt"
-w dir/%f_%e.out  # write files to "dir" as "FILE_EXT.out"
-w dir2/%d%f.txt  # write to "dir2", keeping dir structure
-w a%c.txt        # write to "a.txt" or "a1.txt" or "a2.txt"...
Existing files will not be changed unless an exclamation point is added to the option name (ie. -w! or -textOut!) to overwrite the file, or a plus sign (ie. -w+ or -textOut+) to append to the existing file. Both may be used (ie. -w+! or -textOut+!) to overwrite output files that didn't exist before the command was run, and append the output from multiple source files. For example, to write one output file for all source files in each directory:

exiftool -filename -createdate -T -w+! %d/out.txt -r DIR
Capitalized format codes %D, %F, %E and %C provide slightly different alternatives to the lower case versions. %D does not include the trailing '/', %F is the full filename including extension, %E includes the leading '.', and %C increments the count for each processed file (see below).

Notes:

1) In a Windows BAT file the % character is represented by %%, so an argument like %d%f.txt is written as %%d%%f.txt.

2) If the argument for -w does not contain a valid format code (eg. %f), then it is interpreted as a file extension, but there are three different ways to create a single output file from multiple source files:

# 1. Shell redirection
exiftool FILE1 FILE2 ... > out.txt

# 2. With the -w option and a zero-width format code
exiftool -w+! %0fout.txt FILE1 FILE2 ...

# 3. With the -W option (see the -W option below)
exiftool -W+! out.txt FILE1 FILE2 ...
3) The -w option changes when used with a multi-file output format (-csv or -plot). With these, the argument of -w is a complete file name with no formatting codes, and the append feature may not be used.

Advanced features:

A substring of the original file name, directory or extension may be taken by specifying a field width immediately following the '%' character. If the width is negative, the substring is taken from the end. The substring position (characters to ignore at the start or end of the string) may be given by a second optional value after a decimal point. For example:

Input File Name     Format Specifier    Output File Name
----------------    ----------------    ----------------
Picture-123.jpg     %7f.txt             Picture.txt
Picture-123.jpg     %-.4f.out           Picture.out
Picture-123.jpg     %7f.%-3f            Picture.123
Picture-123a.jpg    Meta%-3.1f.txt      Meta123.txt
(Note that special characters may have a width of greater than one.)

For %d and %D, the field width/position specifiers may be applied to the directory levels instead of substring position by using a colon instead of a decimal point in the format specifier. For example:

Source Dir     Format   Result       Notes
------------   ------   ----------   ------------------
pics/2012/02   %2:d     pics/2012/   take top 2 levels
pics/2012/02   %-:1d    pics/2012/   up one directory level
pics/2012/02   %:1d     2012/02/     ignore top level
pics/2012/02   %1:1d    2012/        take 1 level after top
pics/2012/02   %-1:D    02           bottom level folder name
/Users/phil    %:2d     phil/        ignore top 2 levels
(Note that the root directory counts as one level when an absolute path is used as in the last example above.)

For %c, these modifiers have a different effects. If a field width is given, the copy number is padded with zeros to the specified width. A leading '-' adds a dash before the copy number, and a '+' adds an underline. By default, the copy number is omitted from the first file of a given name, but this can be changed by adding a decimal point to the modifier. For example:

-w A%-cZ.txt      # AZ.txt, A-1Z.txt, A-2Z.txt ...
-w B%5c.txt       # B.txt, B00001.txt, B00002.txt ...
-w C%.c.txt       # C0.txt, C1.txt, C2.txt ...
-w D%-.c.txt      # D-0.txt, D-1.txt, D-2.txt ...
-w E%-.4c.txt     # E-0000.txt, E-0001.txt, E-0002.txt ...
-w F%-.4nc.txt    # F-0001.txt, F-0002.txt, F-0003.txt ...
-w G%+c.txt       # G.txt, G_1.txt G_2.txt ...
-w H%-lc.txt      # H.txt, H-b.txt, H-c.txt ...
-w I.%.3uc.txt    # I.AAA.txt, I.AAB.txt, I.AAC.txt ...
A special feature allows the copy number to be incremented for each processed file by using %C (upper case) instead of %c. This allows a sequential number to be added to output file names, even if the names are different. For %C, a copy number of zero is not omitted as it is with %c. A leading '-' causes the number to be reset at the start of each new directory (in the original directory structure if the files are being moved), and '+' has no effect. The number before the decimal place gives the starting index, the number after the decimal place gives the field width. To preserve synchronization with the processed file number, by default the copy number is not incremented to avoid file name collisions, so any existing same-named file will cause an error. However using a colon instead of a decimal point causes the number to be incremented to avoid collisions with existing files.

The following examples show the output filenames when used with the command exiftool rose.jpg star.jpg jet.jpg ...:

-w %C%f.txt       # 0rose.txt, 1star.txt, 2jet.txt
-w %f-%10C.txt    # rose-10.txt, star-11.txt, jet-12.txt
-w %.3C-%f.txt    # 000-rose.txt, 001-star.txt, 002-jet.txt
-w %57.4C%f.txt   # 0057rose.txt, 0058star.txt, 0059jet.txt
All format codes may be modified by 'l' or 'u' to specify lower or upper case respectively (ie. %le for a lower case file extension). When used to modify %c or %C, the numbers are changed to an alphabetical base (see example H above). Also, %c and %C may be modified by 'n' to count using natural numbers starting from 1, instead of 0 (see example F above).

This same FMT syntax is used with the -o and -tagsFromFile options, although %c and %C are only valid for output file names.

-W[+|!] FMT (-tagOut)
This enhanced version of the -w option allows a separate output file to be created for each extracted tag. See the -w option documentation above for details of the basic functionality. Listed here are the differences between -W and -w:

1) With -W, a new output file is created for each extracted tag.

2) -W supports four additional format codes: %t, %g and %s represent the tag name, group name, and suggested extension for the output file (based on the format of the data), and %o represents the value of the OriginalRawFileName or OriginalFileName tag from the input file (including extension). The %g code may be followed by a single digit to specify the group family number (eg. %g1), otherwise family 0 is assumed. The substring width/position/case specifiers may be used with these format codes in exactly the same way as with %f and %e.

3) The argument for -W is interpreted as a file name if it contains no format codes. (For -w, this would be a file extension.) This change allows a simple file name to be specified, which, when combined with the append feature, provides a method to write metadata from multiple source files to a single output file without the need for shell redirection. For example, the following pairs of commands give the same result:

# overwriting existing text file
exiftool test.jpg > out.txt     # shell redirection
exiftool test.jpg -W+! out.txt  # equivalent -W option

# append to existing text file
exiftool test.jpg >> out.txt    # shell redirection
exiftool test.jpg -W+ out.txt   # equivalent -W option
4) Adding the -v option to -W sends a list of the tags and output file names to the console instead of giving a verbose dump of the entire file. (Unless appending all output to one file for each source file by using -W+ with an output file FMT that does not contain %t, %g, %s or %o.)

5) Individual list items are stored in separate files when -W is combined with -b, but note that for separate files to be created %c or %C must be used in FMT to give the files unique names.

-Wext EXT, --Wext EXT (-tagOutExt)
This option is used to specify the type of output file(s) written by the -W option. An output file is written only if the suggested extension matches EXT. Multiple -Wext options may be used to write more than one type of file. Use --Wext to write all but the specified type(s).

-X (-xmlFormat)
Use ExifTool-specific RDF/XML formatting for console output. Implies the -a option, so duplicate tags are extracted. The formatting options -b, -D, -H, -l, -s, -sep, -struct and -t may be used in combination with -X to affect the output, but note that the tag ID (-D, -H and -t), binary data (-b) and structured output (-struct) options are not effective for the short output (-s). Another restriction of -s is that only one tag with a given group and name may appear in the output. Note that the tag ID options (-D, -H and -t) will produce non-standard RDF/XML unless the -l option is also used.

By default, -X outputs flattened tags, so -struct should be added if required to preserve XMP structures. List-type tags with multiple values are formatted as an RDF Bag, but they are combined into a single string when -s or -sep is used. Using -L changes the XML encoding from "UTF-8" to "windows-1252". Other -charset settings change the encoding only if there is a corresponding standard XML character set. The -b option causes binary data values to be written, encoded in base64 if necessary. The -t option adds tag table information to the output (see -t for details).

Note: This output is NOT the same as XMP because it uses dynamically-generated property names corresponding to the ExifTool tag names with ExifTool family 1 group names as namespaces, and not the standard XMP properties and namespaces. To write XMP instead, use the -o option with an XMP extension for the output file.

Processing control
-a, --a (-duplicates, --duplicates)
Allow (-a) or suppress (--a) duplicate tag names to be extracted. By default, duplicate tags are suppressed when reading unless the -ee or -X options are used or the Duplicates option is enabled in the configuration file. When writing, this option allows multiple Warning messages to be shown. Duplicate tags are always extracted when copying.

-e (--composite)
Extract existing tags only -- don't generate composite tags.

-ee[NUM] (-extractEmbedded)
Extract information from embedded documents in EPS files, embedded EPS information and JPEG and Jpeg2000 images in PDF files, embedded MPF images in JPEG and MPO files, streaming metadata in AVCHD videos, and the resource fork of Mac OS files. Implies the -a option. Use -g3 or -G3 to identify the originating document for extracted information. Embedded documents containing sub-documents are indicated with dashes in the family 3 group name. (eg. Doc2-3 is the 3rd sub-document of the 2nd embedded document.) Note that this option may increase processing time substantially, especially for PDF files with many embedded images or videos with streaming metadata.

When used with -ee, the -p option is evaluated for each embedded document as if it were a separate input file. This allows, for example, generation of GPS track logs from timed metadata in videos. See https://exiftool.org/geotag.html#Inverse for examples.

Setting NUM to 2 causes the H264 video stream in MP4 videos to be parsed until the first Supplemental Enhancement Information (SEI) message is decoded, or 3 to parse the entire H624 stream and decode all SEI information. For M2TS videos, a setting of 3 causes the entire file to be parsed in search of unlisted programs which may contain timed GPS.

-ext[+] EXT, --ext EXT (-extension)
Process only files with (-ext) or without (--ext) a specified extension. There may be multiple -ext and --ext options. A plus sign may be added (ie. -ext+) to add the specified extension to the normally processed files. EXT may begin with a leading '.', which is ignored. Case is not significant. "*" may be used to process files with any extension (or none at all), as in the last three examples:

exiftool -ext JPG DIR             # process only JPG files
exiftool --ext cr2 --ext dng DIR  # supported files but CR2/DNG
exiftool -ext+ txt DIR            # supported files plus TXT
exiftool -ext "*" DIR             # process all files
exiftool -ext "*" --ext xml DIR   # process all but XML files
exiftool -ext "*" --ext . DIR     # all but those with no ext
Using this option has two main advantages over specifying *.EXT on the command line: 1) It applies to files in subdirectories when combined with the -r option. 2) The -ext option is case-insensitive, which is useful when processing files on case-sensitive filesystems.

Note that all files specified on the command line will be processed regardless of extension unless the -ext option is used.

-F[OFFSET] (-fixBase)
Fix the base for maker notes offsets. A common problem with some image editors is that offsets in the maker notes are not adjusted properly when the file is modified. This may cause the wrong values to be extracted for some maker note entries when reading the edited file. This option allows an integer OFFSET to be specified for adjusting the maker notes base offset. If no OFFSET is given, ExifTool takes its best guess at the correct base. Note that exiftool will automatically fix the offsets for images which store original offset information (eg. newer Canon models). Offsets are fixed permanently if -F is used when writing EXIF to an image. eg)

exiftool -F -exif:resolutionunit=inches image.jpg
-fast[NUM]
Increase speed of extracting information. With -fast (or -fast1), ExifTool will not scan to the end of a JPEG image to check for an AFCP or PreviewImage trailer, or past the first comment in GIF images or the audio/video data in WAV/AVI files to search for additional metadata. These speed benefits are small when reading images directly from disk, but can be substantial if piping images through a network connection. Also bypasses CRC validation when writing PNG images which can be very slow. For more substantial speed benefits, -fast2 also causes exiftool to avoid extracting any EXIF MakerNote information, and to stop processing at the IDAT chunk of PNG images and the mdat atom of QuickTime-format files (but note that some files may store metadata after this). -fast3 avoids extracting metadata from the file, and returns only pseudo System tags, but still reads the file header to obtain an educated guess at FileType. -fast4 doesn't even read the file header, and returns only System tags and a FileType based on the file extension. -fast5 also disables generation of the Composite tags (like -e). Has no effect when writing.

Note that a separate -fast setting may be used for evaluation of a -if condition, or when ordering files with the -fileOrder option. See the -if and -fileOrder options for details.

-fileOrder[NUM] [-]TAG
Set file processing order according to the sorted value of the specified TAG. Without this option, files are processed in the order returned by the system, which is commonly by file name, but this is filesystem dependent. For example, to process files in order of date:

exiftool -fileOrder DateTimeOriginal DIR
Additional -fileOrder options may be added for secondary sort keys. Numbers are sorted numerically, and all other values are sorted alphabetically. Files missing the specified tag are sorted last. The sort order may be reversed by prefixing the tag name with a - (eg. -fileOrder -createdate). Print conversion of the sorted values is disabled with the -n option, or a # appended to the tag name. Other formatting options (eg. -d) have no effect on the sorted values. Note that the -fileOrder option can incur large performance penalty since it involves an additional initial processing pass of all files, but this impact may be reduced by specifying a NUM to effectively set the -fast level for the initial pass. For example, -fileOrder4 may be used if TAG is a pseudo System tag. If multiple -fileOrder options are used, the extraction is done at the lowest -fast level. Note that files are sorted across directory boundaries if multiple input directories are specified.

-i DIR (-ignore)
Ignore specified directory name. DIR may be either an individual folder name, or a full path, and is case sensitive. If a full path is specified, it must match the Directory tag exactly to be ignored. Use multiple -i options to ignore more than one directory name. A special DIR value of SYMLINKS may be specified to avoid recursing into directories which are symbolic links when the -r option is used (note this does not currently work under Windows). As well, a value of HIDDEN may be used to ignore files with names that start with a "." (ie. hidden files on Unix systems) when scanning a directory.

-if[NUM] EXPR
Specify a condition to be evaluated before processing each FILE. EXPR is a Perl-like logic expression containing tag names prefixed by $ symbols. It is evaluated with the tags from each FILE in turn, and the file is processed only if the expression returns true. Unlike Perl variable names, tag names are not case sensitive and may contain a hyphen. As well, tag names may have a leading group names separated by colons, and/or a trailing # character to disable print conversion. The expression $GROUP:all evaluates to 1 if any tag exists in the specified GROUP, or 0 otherwise (see note 2 below). When multiple -if options are used, all conditions must be satisfied to process the file. Returns an exit status of 2 if all files fail the condition. Below are a few examples:

# extract shutterspeed from all Canon images in a directory
exiftool -shutterspeed -if '$make eq "Canon"' dir

# add one hour to all images created on or after Apr. 2, 2006
exiftool -alldates+=1 -if '$CreateDate ge "2006:04:02"' dir

# set EXIF ISO value if possible, unless it is set already
exiftool '-exif:iso<iso' -if 'not $exif:iso' dir

# find images containing a specific keyword (case insensitive)
exiftool -if '$keywords =~ /harvey/i' -filename dir
Adding NUM to the -if option causes a separate processing pass to be executed for evaluating EXPR at a -fast level given by NUM (see the -fast option documentation for details). Without NUM, only one processing pass is done at the level specified by the -fast option. For example, using -if5 is possible if EXPR uses only pseudo System tags, and may significantly speed processing if enough files fail the condition.

The expression has access to the current ExifTool object through $self, and the following special functions are available to allow short-circuiting of the file processing. Both functions have a return value of 1. Case is significant for function names.

End()    - end processing after this file
EndDir() - end processing of files in the current directory
           after this file (not compatible with -fileOrder)
Notes:

1) The -n and -b options also apply to tags used in EXPR.

2) The API RequestTags option is automatically set for all tags used in the -if condition.

3) Tags in the string are interpolated in a similar way to -p before the expression is evaluated. In this interpolation, $/ is converted to a newline and $$ represents a single $ symbol. So Perl variables, if used, require a double $, and regular expressions ending in $/ must use $$/ instead.

4) The condition accesses only tags from the file being processed unless the -fileNUM option is used to read an alternate file and the corresponding family 8 group name is specified for the tag. See the -fileNUM option details for more information.

5) The -a (Duplicates) option is implied when -if is used without a fast NUM, and the values of duplicate tags are accessible by specifying a group name in the expression (such as a family 4 instance number, eg. $Copy1:TAG, $Copy2:TAG, etc).

6) A special "OK" UserParam is available to test the success of the previous command when -execute was used, and may be used like any other tag in the condition (ie. "$OK").

7) The values of undefined tags in the expression are affected by the -f and -m options unless the API UndefTags option is also set.

8) The condition fails if a Perl error occurs. This could happen for instance if an undefined value (eg. a missing tag) is used improperly.

-m (-ignoreMinorErrors)
Ignore minor errors and warnings. This enables writing to files with minor errors and disables some validation checks which could result in minor warnings. Generally, minor errors/warnings indicate a problem which usually won't result in loss of metadata if ignored. However, there are exceptions, so ExifTool leaves it up to you to make the final decision. Minor errors and warnings are indicated by "[minor]" at the start of the message. Warnings which affect processing when ignored are indicated by "[Minor]" (with a capital "M"). Note that this causes missing values in -tagsFromFile, -p, -if and -fileNUM strings to be set to an empty string rather than an undefined value (but this may be avoided for -if using the API UndefTags option).

-o OUTFILE or FMT (-out)
Set the output file or directory name when writing information. Without this option, when any "real" tags are written the original file is renamed to FILE_original and output is written to FILE. When writing only FileName and/or Directory "pseudo" tags, -o causes the file to be copied instead of moved, but directories specified for either of these tags take precedence over that specified by the -o option.

OUTFILE may be - to write to stdout. The output file name may also be specified using a FMT string in which %d, %f and %e represent the directory, file name and extension of FILE. Also, %c may be used to add a copy number. See the -w option for FMT string examples.

The output file is taken to be a directory name if it already exists as a directory or if the name ends with '/'. Output directories are created if necessary. Existing files will not be overwritten. Combining the -overwrite_original option with -o causes the original source file to be erased after the output file is successfully written.

A special feature of this option allows the creation of certain types of files from scratch, or with the metadata from another type of file. The following file types may be created using this technique:

XMP, EXIF, EXV, MIE, ICC/ICM, VRD, DR4
The output file type is determined by the extension of OUTFILE (specified as -.EXT when writing to stdout). The output file is then created from a combination of information in FILE (as if the -tagsFromFile option was used), and tag values assigned on the command line. If no FILE is specified, the output file may be created from scratch using only tags assigned on the command line.

-overwrite_original
Overwrite the original FILE (instead of preserving it by adding _original to the file name) when writing information to an image. Caution: This option should only be used if you already have separate backup copies of your image files. The overwrite is implemented by renaming a temporary file to replace the original. This deletes the original file and replaces it with the edited version in a single operation. When combined with -o, this option causes the original file to be deleted if the output file was successfully written (ie. the file is moved instead of copied).

-overwrite_original_in_place
Similar to -overwrite_original except that an extra step is added to allow the original file attributes to be preserved. For example, on a Mac this causes the original file creation date, type, creator, label color, icon, Finder tags, other extended attributes and hard links to the file to be preserved (but note that the Mac OS resource fork is always preserved unless specifically deleted with -rsrc:all=). This is implemented by opening the original file in update mode and replacing its data with a copy of a temporary file before deleting the temporary. The extra step results in slower performance, so the -overwrite_original option should be used instead unless necessary.

Note that this option reverts to the behaviour of the -overwrite_original option when also writing the FileName and/or Directory tags.

-P (-preserve)
Preserve the filesystem modification date/time (FileModifyDate) of the original file when writing. Note that some filesystems store a creation date (ie. FileCreateDate on Windows and Mac systems) which is not affected by this option. This creation date is preserved on Windows systems where Win32API::File and Win32::API are available regardless of this setting. For other systems, the -overwrite_original_in_place option may be used if necessary to preserve the creation date. The -P option is superseded by any value written to the FileModifyDate tag.

-password PASSWD
Specify password to allow processing of password-protected PDF documents. If a password is required but not given, a warning is issued and the document is not processed. This option is ignored if a password is not required.

-progress[NUM][:[TITLE]]
Show the progress when processing files. Without a colon, the -progress option adds a progress count in brackets after the name of each processed file, giving the current file number and the total number of files to be processed. Implies the -v0 option, causing the names of processed files to also be printed when writing. When combined with the -if option, the total count includes all files before the condition is applied, but files that fail the condition will not have their names printed. If NUM is specified, the progress is shown every NUM input files.

If followed by a colon (ie. -progress:), the console window title is set according to the specified TITLE string. If no TITLE is given, a default TITLE string of "ExifTool %p%%" is assumed. In the string, %f represents the file name, %p is the progress as a percent, %r is the progress as a ratio, %##b is a progress bar of width "##" (where "##" is an integer specifying the bar width in characters, or 20 characters by default if "##" is omitted), and %% is a % character. May be combined with the normal -progress option to also show the progress count in console messages. (Note: For this feature to function correctly on Mac/Linux, stderr must go to the console.)

-q (-quiet)
Quiet processing. One -q suppresses normal informational messages, and a second -q suppresses warnings as well. Error messages can not be suppressed, although minor errors may be downgraded to warnings with the -m option, which may then be suppressed with -q -q.

-r[.] (-recurse)
Recursively process files in subdirectories. Only meaningful if FILE is a directory name. Subdirectories with names beginning with "." are not processed unless "." is added to the option name (ie. -r. or -recurse.). By default, exiftool will also follow symbolic links to directories if supported by the system, but this may be disabled with -i SYMLINKS (see the -i option for details). Combine this with -ext options to control the types of files processed.

-scanForXMP
Scan all files (even unsupported formats) for XMP information unless found already. When combined with the -fast option, only unsupported file types are scanned. Warning: It can be time consuming to scan large files.

-u (-unknown)
Extract values of unknown tags. Add another -u to also extract unknown information from binary data blocks. This option applies to tags with numerical tag ID's, and causes tag names like "Exif_0xc5d9" to be generated for unknown information. It has no effect on information types which have human-readable tag ID's (such as XMP), since unknown tags are extracted automatically from these formats.

-U (-unknown2)
Extract values of unknown tags as well as unknown information from some binary data blocks. This is the same as two -u options.

-wm MODE (-writeMode)
Set mode for writing/creating tags. MODE is a string of one or more characters from the list below. The default write mode is wcg.

w - Write existing tags
c - Create new tags
g - create new Groups as necessary
For example, use -wm cg to only create new tags (and avoid editing existing ones).

The level of the group is the SubDirectory level in the metadata structure. For XMP or IPTC this is the full XMP/IPTC block (the family 0 group), but for EXIF this is the individual IFD (the family 1 group).

-z (-zip)
When reading, causes information to be extracted from .gz and .bz2 compressed images (only one image per archive; requires gzip and bzip2 to be available). When writing, causes compressed information to be written if supported by the metadata format (eg. PNG supports compressed textual metadata, JXL supports compressed EXIF and XML, and MIE supports any compressed metadata), disables the recommended padding in embedded XMP (saving 2424 bytes when writing XMP in a file), and writes XMP in shorthand format -- the equivalent of setting the API Compress=1 and Compact="NoPadding,Shorthand".

Other options
-@ ARGFILE
Read command-line arguments from the specified file. The file contains one argument per line (NOT one option per line -- some options require additional arguments, and all arguments must be placed on separate lines). Blank lines and lines beginning with # are ignored (unless they start with #[CSTR], in which case the rest of the line is treated as a C string, allowing standard C escape sequences such as "\n" for a newline). White space at the start of a line is removed. Normal shell processing of arguments is not performed, which among other things means that arguments should not be quoted and spaces are treated as any other character. ARGFILE may exist relative to either the current directory or the exiftool directory unless an absolute pathname is given.

For example, the following ARGFILE will set the value of Copyright to "Copyright YYYY, Phil Harvey", where "YYYY" is the year of CreateDate:

-d
%Y
-copyright<Copyright $createdate, Phil Harvey
Arguments in ARGFILE behave exactly the same as if they were entered at the location of the -@ option on the command line, with the exception that the -config and -common_args options may not be used in an ARGFILE.

-k (-pause)
Pause with the message -- press any key -- or -- press RETURN -- (depending on your system) before terminating. This option is used to prevent the command window from closing when run as a Windows drag and drop application.

-list, -listw, -listf, -listr, -listwf, -listg[NUM], -listd, -listx, -listgeo
Print a list of all valid tag names (-list), all writable tag names (-listw), all supported file extensions (-listf), all recognized file extensions (-listr), all writable file extensions (-listwf), all tag groups [in a specified family] (-listg[NUM]), all deletable tag groups (-listd), an XML database of tag details including language translations (-listx), or the Geolocation database (-listgeo). The -list, -listw and -listx options may be followed by an additional argument of the form -GROUP:All to list only tags in a specific group, where GROUP is one or more family 0-2 group names (excepting EXIF IFD groups) separated by colons. With -listg, NUM may be given to specify the group family, otherwise family 0 is assumed. The -l or -v option may be combined with -listf, -listr or -listwf to add file descriptions to the list. The -lang option may be combined with -listx to output descriptions in a single language, and the -sort and/or -lang options may be combined with -listgeo (installation of the alternate database is required for the additional languages). Also, the API GeolocMinPop, GeolocFeature and GeolocAltNames options apply to the -listgeo output. Here are some examples:

-list               # list all tag names
-list -EXIF:All     # list all EXIF tags
-list -xmp:time:all # list all XMP tags relating to time
-listw -XMP-dc:All  # list all writable XMP-dc tags
-listf              # list all supported file extensions
-listr              # list all recognized file extensions
-listwf             # list all writable file extensions
-listg1             # list all groups in family 1
-listd              # list all deletable groups
-listx -EXIF:All    # list database of EXIF tags in XML format
-listx -XMP:All -s  # list short XML database of XMP tags
-listgeo -lang de   # list geolocation database in German
When combined with -listx, the -s option shortens the output by omitting the descriptions and values (as in the last example above), and -f adds 'flags' and 'struct' attributes if applicable. The flags are formatted as a comma-separated list of the following possible values: Avoid, Binary, List, Mandatory, Permanent, Protected, Unknown and Unsafe (see the Tag Name documentation). For XMP List tags, the list type (Alt, Bag or Seq) is also given, and flattened structure tags are indicated by a Flattened flag with 'struct' giving the ID of the parent structure.

Note that none of the -list options require an input FILE.

-ver
Print exiftool version number. The -v option may be added to print addition system information (see the README file of the full distribution for more details about optional libraries), or -v2 to also list the Perl include directories.

--
Indicates the end of options. Any remaining arguments are treated as file names, even if they begin with a dash (-).

Special features
-diff FILE2
Compare metadata in FILE with FILE2. The FILE2 name may include filename formatting codes (see the -w option). All extracted tags from the files are compared, but the extracted tags may be controlled by adding -TAG or --TAG options. For example, below is a command to compare all the same-named files in two different directories, ignoring the System tags:

exiftool DIR1 -diff DIR2/%f.%e --system:all
The -g and -G options may be used to organize the output by the specified family of groups, with -G1 being the default. The -a option is implied. Adding -v includes a count of the number of tags that are the same in each group, and -v2 also indicates when zero tags were the same. The following text formatting options are valid when -diff is used: -c, -charset, -d, -E, -ec, -ex, -L, -lang, -n, -s, -sep, -struct and -w.

-geotag TRKFILE
Geotag images from the specified GPS track log file. Using the -geotag option is equivalent to writing a value to the Geotag tag. The GPS position is interpolated from the track at a time specified by the value written to the Geotime tag. If Geotime is not specified, the value is copied from SubSecDateTimeOriginal# if it exists, otherwise DateTimeOriginal# (the # is added to copy the unformatted value, avoiding potential conflicts with the -d option). For example, the following two commands are equivalent if SubSecDateTimeOriginal exists in the file:

exiftool -geotag trk.log image.jpg
exiftool -geotag trk.log "-Geotime<SubSecDateTimeOriginal#" image.jpg
If the Geotime value does not contain a time zone then the local system timezone is assumed. Writing Geotime causes the following tags to be written (provided they can be calculated from the track log, and they are supported by the destination metadata format): GPSLatitude, GPSLatitudeRef, GPSLongitude, GPSLongitudeRef, GPSAltitude, GPSAltitudeRef, GPSDateStamp, GPSTimeStamp, GPSDateTime, GPSTrack, GPSTrackRef, GPSSpeed, GPSSpeedRef, GPSImgDirection, GPSImgDirectionRef, GPSMeasureMode, GPSDOP, GPSPitch, GPSRoll, GPSCoordinates, AmbientTemperature and CameraElevationAngle. By default, in image files tags are created in EXIF, and updated in XMP only if they already exist. In QuickTime-format files GPSCoordinates is created in the preferred location (ItemList by default) as well as in XMP. However, EXIF:Geotime, XMP:Geotime or QuickTime:Geotime may be specified to write to write only to one group. Also, ItemList:Geotime, Keys:Geotime or UserData:Geotime may be used to write to a specific location in QuickTime-format files. Note that GPSPitch and GPSRoll are non-standard, and require user-defined tags in order to be written.

The Geosync tag may be used to specify a time correction which is applied to each Geotime value for synchronization with GPS time. For example, the following command compensates for image times which are 1 minute and 20 seconds behind GPS:

exiftool -geosync=+1:20 -geotag a.log DIR
Advanced Geosync features allow a piecewise linear time drift correction and synchronization from previously geotagged images. See "geotag.html" in the full ExifTool distribution for more information.

Multiple -geotag options may be used to concatenate GPS track log data. Also, a single -geotag option may be used to load multiple track log files by using wildcards in the TRKFILE name, but note that in this case TRKFILE must be quoted on most systems (with the notable exception of Windows) to prevent filename expansion. For example:

exiftool -geotag "TRACKDIR/*.log" IMAGEDIR
Currently supported track file formats are GPX, NMEA RMC/GGA/GLL, KML, IGC, Garmin XML and TCX, Magellan PMGNTRK, Honeywell PTNTHPR, Bramor gEO, Winplus Beacon TXT, and GPS/IMU CSV files. See "GEOTAGGING EXAMPLES" for examples. Also see "geotag.html" in the full ExifTool distribution and the Image::ExifTool Options for more details and for information about geotag configuration options.

The API Geolocation option may be set to the value "geotag" to also write the name, province/state and country of the nearest city while geotagging. See https://exiftool.org/geolocation.html for details.

-globalTimeShift SHIFT
Shift all formatted date/time values by the specified amount when reading. Does not apply to unformatted (-n) output. SHIFT takes the same form as the date/time shift when writing (see Image::ExifTool::Shift.pl for details), with a negative shift being indicated with a minus sign (-) at the start of the SHIFT string. For example:

# return all date/times, shifted back by 1 hour
exiftool -globalTimeShift -1 -time:all a.jpg

# set the file name from the shifted CreateDate (-1 day) for
# all images in a directory
exiftool "-filename<createdate" -globaltimeshift "-0:0:1 0:0:0" \
    -d %Y%m%d-%H%M%S.%%e dir
-use MODULE
Add features from specified plug-in MODULE. Currently, the MWG module is the only plug-in module distributed with exiftool. This module adds read/write support for tags as recommended by the Metadata Working Group. As a convenience, -use MWG is assumed if the group name prefix starts with MWG: exactly for any requested tag. See the MWG Tags documentation for more details. Note that this option is not reversible, and remains in effect until the application terminates, even across the -execute option.

Utilities
-restore_original
-delete_original[!]
These utility options automate the maintenance of the _original files created by exiftool. They have no effect on files without an _original copy. The -restore_original option restores the specified files from their original copies by renaming the _original files to replace the edited versions. For example, the following command restores the originals of all JPG images in directory DIR:

exiftool -restore_original -ext jpg DIR
The -delete_original option deletes the _original copies of all files specified on the command line. Without a trailing ! this option prompts for confirmation before continuing. For example, the following command deletes a.jpg_original if it exists, after asking "Are you sure?":

exiftool -delete_original a.jpg
These options may not be used with other options to read or write tag values in the same command, but may be combined with options such -ext, -if, -r, -q and -v.

Advanced options
Among other things, the advanced options allow complex processing to be performed from a single command without the need for additional scripting. This may be particularly useful for implementations such as Windows drag-and-drop applications. These options may also be used to improve performance in multi-pass processing by reducing the overhead required to load exiftool for each invocation.

-api [OPT[[^]=[VAL]]]
Set ExifTool API option. OPT is an API option name. The option value is set to 1 if =VAL is omitted. If VAL is omitted, the option value is set to undef if = is used, or an empty string with ^=. If OPT is not specified a list of available options is returned. The option name is not case senstive, but the option values are. See Image::ExifTool Options for option details. This overrides API options set via the config file. Note that the exiftool app sets some API options internally, and attempts to change these via the command line will have no effect.

-common_args
Specifies that all arguments following this option are common to all executed commands when -execute is used. This and the -config option are the only options that may not be used inside a -@ ARGFILE. Note that by definition this option and its arguments MUST come after all other options on the command line.

-config CFGFILE
Load specified configuration file instead of the default ".ExifTool_config". If used, this option must come before all other arguments on the command line and applies to all -execute'd commands. This file is used to create user-defined tags as well as set default ExifTool options. The CFGFILE must exist relative to the current working directory or the exiftool application directory unless an absolute path is specified. Loading of the default config file may be disabled by setting CFGFILE to an empty string (ie. ""). See https://exiftool.org/config.html and config_files/example.config in the full ExifTool distribution for details about the configuration file syntax.

-echo[NUM] TEXT
Echo TEXT to stdout (-echo or -echo1) or stderr (-echo2). Text is output as the command line is parsed, before the processing of any input files. NUM may also be 3 or 4 to output text (to stdout or stderr respectively) after processing is complete. For -echo3 and -echo4, "${status}" may be used in the TEXT string to represent the numerical exit status of the command (see "EXIT STATUS").

-efile[NUM][!] TXTFILE
Save the names of files giving errors (NUM missing or 1), files that were unchanged (NUM is 2), files that fail the -if condition (NUM is 4), files that were updated (NUM is 8), files that were created (NUM is 16), or any combination thereof by summing NUM (eg. -efile3 is the same has having both -efile and -efile2 options with the same TXTFILE). By default, file names are appended to any existing TXTFILE, but TXTFILE is overwritten if an exclamation point is added to the option (eg. -efile!). Saves the name of the file specified by the -srcfile option if applicable.

-execute[NUM]
Execute command for all arguments up to this point on the command line (plus any arguments specified by -common_args). The result is as if the commands were executed as separate command lines (with the exception of the -config and -use options which remain in effect for subsequent commands). Allows multiple commands to be executed from a single command line. NUM is an optional number that is echoed in the "{ready}" message when using the -stay_open feature. If a NUM is specified, the -q option no longer suppresses the output "{readyNUM}" message.

-fileNUM ALTFILE
Read tags from an alternate source file. Among other things, this allows tags from different files to be compared and combined using the -if and -p options. NUM is any string of digits. Tags from alternate files are accessed via the corresponding family 8 group name (eg. File1:TAG for the -file1 option, File2:TAG for -file2, etc). ALTFILE may contain filename formatting codes like the -w option (%d, %f, etc), and/or tag names with a leading $ symbol to access tags from the source file in the same way as the -p option (so any other dollar symbol in the file name must be doubled, eg. money$$.jpg). For example, assuming that the OriginalFileName tag has been set in the edited file, a command to copy Rights from the original file could look like this:

exiftool -file1 '$originalfilename' '-rights<file1:rights' edited.jpg
Subtle note: If a -tagsFromFile option is used, tags in the ALTFILE argument come from the SRCFILE that applies to the first argument accessing tags from the corresponding FileNUM group.

ALTFILE may also be @ to access tags from the specified FILE, which may be useful when the -srcfile option is used to process a different source file.

User-defined Composite tags may access tags from alternate files using the appropriate (case-sensitive) family 8 group name.

The -fast option, if used, also applies to processing of the alternate files.

-list_dir
List directories themselves instead of their contents. This option effectively causes directories to be treated as normal files when reading and writing. For example, with this option the output of the ls -la command on Mac/Linux may be approximated by this exiftool command:

exiftool -list_dir -T -ls-l -api systemtags -fast5 .* *
(The -T option formats the output in tab-separated columns, -ls-l is a shortcut tag, the API SystemTags option is required to extract some necessary tags, and the -fast5 option is added for speed since only system tags are being extracted.)

-srcfile FMT
Specify a different source file to be processed based on the name of the original FILE. This may be useful in some special situations for processing related preview images or sidecar files. See the -w option for a description of the FMT syntax. Note that file name FMT strings for all options are based on the original FILE specified from the command line, not the name of the source file specified by -srcfile.

For example, to copy metadata from NEF files to the corresponding JPG previews in a directory where other JPG images may exist:

exiftool -ext nef -tagsfromfile @ -srcfile %d%f.jpg dir
If more than one -srcfile option is specified, the files are tested in order and the first existing source file is processed. If none of the source files already exist, then exiftool uses the first -srcfile specified.

A FMT of @ may be used to represent the original FILE, which may be useful when specifying multiple -srcfile options (eg. to fall back to processing the original FILE if no sidecar exists).

When this option is used, two special UserParam tags (OriginalFileName and OriginalDirectory) are generated to allow access to the original FILE name and directory.

-stay_open FLAG
If FLAG is 1 or True (case insensitive), causes exiftool keep reading from the -@ ARGFILE even after reaching the end of file. This feature allows calling applications to pre-load exiftool, thus avoiding the overhead of loading exiftool for each command. The procedure is as follows:

1) Execute exiftool -stay_open True -@ ARGFILE, where ARGFILE is the name of an existing (possibly empty) argument file or - to pipe arguments from the standard input.

2) Write exiftool command-line arguments to ARGFILE, one argument per line (see the -@ option for details).

3) Write -execute\n to ARGFILE, where \n represents a newline sequence. (Note: You may need to flush your write buffers here if using buffered output.) ExifTool will then execute the command with the arguments received up to this point, send a "{ready}" message to stdout when done (unless the -q or -T option is used), and continue trying to read arguments for the next command from ARGFILE. To aid in command/response synchronization, any number appended to the -execute option is echoed in the "{ready}" message. For example, -execute613 results in "{ready613}". When this number is added, -q no longer suppresses the "{ready}" message. (Also, see the -echo3 and -echo4 options for additional ways to pass signals back to your application.)

4) Repeat steps 2 and 3 for each command.

5) Write -stay_open\nFalse\n (or -stay_open\n0\n) to ARGFILE when done. This will cause exiftool to process any remaining command-line arguments then exit normally.

The input ARGFILE may be changed at any time before step 5 above by writing the following lines to the currently open ARGFILE:

-stay_open
True
-@
NEWARGFILE
This causes ARGFILE to be closed, and NEWARGFILE to be kept open. (Without the -stay_open here, exiftool would have returned to reading arguments from ARGFILE after reaching the end of NEWARGFILE.)

Note: When writing arguments to a disk file there is a delay of up to 0.01 seconds after writing -execute\n before exiftool starts processing the command. This delay may be avoided by sending a CONT signal to the exiftool process immediately after writing -execute\n. (There is no associated delay when writing arguments via a pipe with -@ -, so the signal is not necessary when using this technique.)

-userParam PARAM[[^]=[VAL]]
Set user parameter. PARAM is an arbitrary user parameter name. This is an interface to the API UserParam option (see the Image::ExifTool Options documentation), and provides a method to access user-defined parameters in arguments to the -if, -p and -fileNUM options as if they were any other tag. Appending a hash tag (#) to PARAM (eg. -userParam MyTag#=yes) also causes the parameter to be extracted as a normal tag in the UserParam group. Similar to the -api option, the parameter value is set to 1 if =VAL is omitted, undef if just VAL is omitted with =, or an empty string if VAL is omitted with ^=.

exiftool -p '$test from $filename' -userparam test=Hello FILE
Advanced formatting feature
An advanced formatting feature allows modification of the value of any tag interpolated within a -if, -p or -fileNUM argument, or a -tagsFromFile redirection string. Tag names within these strings are prefixed by a $ symbol, and an arbitrary Perl expression may be applied to the tag value by placing braces around the tag name and inserting the expression after the name, separated by a semicolon (ie. ${TAG;EXPR}). The expression acts on the value of the tag through the default input variable ($_), and has access to the full ExifTool API through the current ExifTool object ($self) and the tag key ($tag). It may contain any valid Perl code, including translation (tr///) and substitution (s///) operations, but note that braces within the expression must be balanced. If the expression does not modify $_ the original tag value is returned. The example below prints the camera Make with spaces translated to underlines, and multiple consecutive underlines replaced by a single underline:

exiftool -p '${make;tr/ /_/;s/__+/_/g}' image.jpg
An @ may be added after the tag name to make the expression act on individual list items for list-type tags, simplifying list processing. Set $_ to undef to remove an item from the list. As an example, the following command returns all subjects not containing the string "xxx":

exiftool -p '${subject@;$_=undef if /xxx/}' image.jpg
A default expression of tr(/\\?*:|"<>\0)()d is assumed if the expression is empty (ie. ${TAG;}). This removes the characters / \ ? * : | < > and null from the printed value. (These characters are illegal in Windows file names, so this feature is useful if tag values are used in file names.)

Helper functions
Note that function names are case sensitive.

DateFmt

Simplifies reformatting of individual date/time values. This function acts on a standard EXIF-formatted date/time value in $_ and formats it according to the specified format string (see the -d option). To avoid trying to reformat an already-formatted date/time value, a # must be added to the tag name (as in the example below) if the -d option is also used. For example:

exiftool -p '${createdate#;DateFmt("%Y-%m-%d_%H%M%S")}' a.jpg
ShiftTime

Shifts EXIF-formatted date/time string by a specified amount. Start with a leading minus sign to shift backwards in time. See Image::ExifTool::Shift.pl for details about shift syntax. For example, to shift a date/time value back by one year:

exiftool -p '${createdate;ShiftTime("-1:0:0 0")}' a.jpg
NoDups

Removes duplicate items from a list with a separator specified by the -sep option. This function is most useful when copying list-type tags. For example, the following command may be used to remove duplicate Keywords:

exiftool -sep '##' '-keywords<${keywords;NoDups}' a.jpg
The -sep option is necessary to split the string back into individual list items when writing to a list-type tag.

An optional flag argument may be set to 1 to cause NoDups to set $_ to undef if no duplicates existed, thus preventing the file from being rewritten unnecessarily:

exiftool -sep '##' '-keywords<${keywords;NoDups(1)}' a.jpg
ExifTool 12.64 adds an API NoDups option which makes the NoDups helper function largely redundant, with all the functionality except the ability to avoid rewriting the file if there are no duplicates, but with the advantage the duplicates may be removed when accumulating list items from multiple sources. An equivalent to the above commands using this feature would be:

exiftool -tagsfromfile @ -keywords -api nodups a.jpg
SetTags

Used to set tags in extracted images. With no arguments, copies all tags from the source file to the embedded image:

exiftool -p '${previewimage;SetTags}' -b a.arw > preview.jpg
Arguments may be added to copy or set specific tags. Arguments take exactly the same form as those on the command line when copying or writing tags, but without the leading dash. For example:

exiftool -p '${previewimage;SetTags("comment=test","title<filename")}' ...
WINDOWS UNICODE FILE NAMES
In Windows, command-line arguments are specified using the current code page and are recoded automatically to the system code page. This recoding is not done for arguments in ExifTool arg files, so by default filenames in arg files use the system code page. Unfortunately, these code pages are not complete character sets, so not all file names may be represented.

ExifTool 9.79 and later allow the file name encoding to be specified with -charset filename=CHARSET, where CHARSET is the name of a valid ExifTool character set, preferably UTF8 (see the -charset option for a complete list). Setting this triggers the use of Windows wide-character i/o routines, thus providing support for most Unicode file names (see note 4). But note that it is not trivial to pass properly encoded file names on the Windows command line (see https://exiftool.org/faq.html#Q18 for details), so placing them in a UTF-8 encoded -@ argfile and using -charset filename=utf8 is recommended if possible.

A warning is issued if a specified filename contains special characters and the filename character set was not provided. However, the warning may be disabled by setting -charset filename="", and ExifTool may still function correctly if the system code page matches the character set used for the file names.

When a directory name is provided, the file name encoding need not be specified (unless the directory name contains special characters), and ExifTool will automatically use wide-character routines to scan the directory.

The filename character set applies to the FILE arguments as well as filename arguments of -@, -geotag, -o, -p, -srcfile, -tagsFromFile, -csv=, -j= and -TAG<=. However, it does not apply to the -config filename, which always uses the system character set. The -charset filename= option must come before the -@ option to be effective, but the order doesn't matter with respect to other options.

Notes:

1) FileName and Directory tag values still use the same encoding as other tag values, and are converted to/from the filename character set when writing/reading if specified.

2) Unicode support is not yet implemented for other Windows-based systems like Cygwin.

3) See "WRITING READ-ONLY FILES" below for a note about editing read-only files with Unicode names.

4) Unicode file names with surrogate pairs (code points over U+FFFF) still cause problems.

WRITING READ-ONLY FILES
In general, ExifTool may be used to write metadata to read-only files provided that the user has write permission in the directory. However, there are three cases where file write permission is also required:

1) When using the -overwrite_original_in_place option.

2) When writing only pseudo System tags (eg. FileModifyDate).

3) On Windows if the file has Unicode characters in its name, and a) the -overwrite_original option is used, or b) the _original backup already exists.

Hidden files in Windows behave as read-only files when attempting to write any real tags to the file -- an error is generated when using the -overwrite_original_in_place, otherwise writing should be successful and the hidden attribute will be removed. But the -if option may be used to avoid processing hidden files (provided Win32API::File is available):

exiftool -if "$fileattributes !~ /Hidden/" ...
READING EXAMPLES
Note: Beware when cutting and pasting these examples into your terminal! Some characters such as single and double quotes and hyphens may have been changed into similar-looking yet functionally-different characters by the text formatter used to display this documentation. Also note that in the Windows cmd shell double quotes must be used instead of the single quotes used in the examples.

exiftool -a -u -g1 a.jpg
Print all meta information in an image, including duplicate and unknown tags, sorted by group (for family 1). For performance reasons, this command may not extract all available metadata. (Metadata in embedded documents, metadata extracted by external utilities, and metadata requiring excessive processing time may not be extracted). Add -ee3 and -api RequestAll=3 to the command to extract absolutely everything available.

exiftool -common dir
Print common meta information for all images in dir. -common is a shortcut tag representing common EXIF meta information.

exiftool -T -createdate -aperture -shutterspeed -iso dir > out.txt
List specified meta information in tab-delimited column form for all images in dir to an output text file named "out.txt".

exiftool -s -ImageSize -ExposureTime b.jpg
Print ImageSize and ExposureTime tag names and values.

exiftool -l -canon c.jpg d.jpg
Print standard Canon information from two image files.

exiftool -r -w .txt -common pictures
Recursively extract common meta information from files in pictures directory, writing text output to .txt files with the same names.

exiftool -b -ThumbnailImage image.jpg > thumbnail.jpg
Save thumbnail image from image.jpg to a file called thumbnail.jpg.

exiftool -b -JpgFromRaw -w _JFR.JPG -ext NEF -r .
Recursively extract JPG image from all Nikon NEF files in the current directory, adding _JFR.JPG for the name of the output JPG files.

exiftool -a -b -W %d%f_%t%-c.%s -preview:all dir
Extract all types of preview images (ThumbnailImage, PreviewImage, JpgFromRaw, etc.) from files in directory "dir", adding the tag name to the output preview image file names.

exiftool -d '%r %a, %B %e, %Y' -DateTimeOriginal -S -s -ext jpg .
Print formatted date/time for all JPG files in the current directory.

exiftool -IFD1:XResolution -IFD1:YResolution image.jpg
Extract image resolution from EXIF IFD1 information (thumbnail image IFD).

exiftool '-*resolution*' image.jpg
Extract all tags with names containing the word "Resolution" from an image.

exiftool -xmp:author:all -a image.jpg
Extract all author-related XMP information from an image.

exiftool -xmp -b a.jpg > out.xmp
Extract complete XMP data record intact from a.jpg and write it to out.xmp using the special XMP tag (see the Extra tags in Image::ExifTool::TagNames).

exiftool -p '$filename has date $dateTimeOriginal' -q -f dir
Print one line of output containing the file name and DateTimeOriginal for each image in directory dir.

exiftool -ee3 -p '$gpslatitude, $gpslongitude, $gpstimestamp' a.m2ts
Extract all GPS positions from an AVCHD video.

exiftool -icc_profile -b -w icc image.jpg
Save complete ICC_Profile from an image to an output file with the same name and an extension of .icc.

exiftool -htmldump -w tmp/%f_%e.html t/images
Generate HTML pages from a hex dump of EXIF information in all images from the t/images directory. The output HTML files are written to the tmp directory (which is created if it didn't exist), with names of the form 'FILENAME_EXT.html'.

exiftool -a -b -ee -embeddedimage -W Image_%.3g3.%s file.pdf
Extract embedded JPG and JP2 images from a PDF file. The output images will have file names like "Image_#.jpg" or "Image_#.jp2", where "#" is the ExifTool family 3 embedded document number for the image.

WRITING EXAMPLES
Note that quotes are necessary around arguments which contain certain special characters such as >, < or any white space. These quoting techniques are shell dependent, but the examples below will work for most Unix shells. With the Windows cmd shell however, double quotes should be used (eg. -Comment="This is a new comment").

exiftool -tagsfromfile src.jpg -exif:all --subifd:all dst.jpg
Write new comment to a JPG image (replaces any existing comment).

exiftool -comment= -o newdir -ext jpg .
Remove comment from all JPG images in the current directory, writing the modified images to a new directory.

exiftool -keywords=EXIF -keywords=editor dst.jpg
Replace existing keyword list with two new keywords (EXIF and editor).

exiftool -Keywords+=word -o newfile.jpg src.jpg
Copy a source image to a new file, and add a keyword (word) to the current list of keywords.

exiftool -exposurecompensation+=-0.5 a.jpg
Decrement the value of ExposureCompensation by 0.5 EV. Note that += with a negative value is used for decrementing because the -= operator is used for conditional deletion (see next example).

exiftool -credit-=xxx dir
Delete Credit information from all files in a directory where the Credit value was xxx.

exiftool -xmp:description-de='k&uuml;hl' -E dst.jpg
Write alternate language for XMP:Description, using HTML character escaping to input special characters.

exiftool -all= dst.jpg
Delete all meta information from an image. Note: You should NOT do this to RAW images (except DNG) since proprietary RAW image formats often contain information in the makernotes that is necessary for converting the image.

exiftool -all= -comment='lonely' dst.jpg
Delete all meta information from an image and add a comment back in. (Note that the order is important: -comment='lonely' -all= would also delete the new comment.)

exiftool -all= --jfif:all dst.jpg
Delete all meta information except JFIF group from an image.

exiftool -Photoshop:All= dst.jpg
Delete Photoshop meta information from an image (note that the Photoshop information also includes IPTC).

exiftool -r -XMP-crss:all= DIR
Recursively delete all XMP-crss information from images in a directory.

exiftool '-ThumbnailImage<=thumb.jpg' dst.jpg
Set the thumbnail image from specified file (Note: The quotes are necessary to prevent shell redirection).

exiftool '-JpgFromRaw<=%d%f_JFR.JPG' -ext NEF -r .
Recursively write JPEG images with filenames ending in _JFR.JPG to the JpgFromRaw tag of like-named files with extension .NEF in the current directory. (This is the inverse of the -JpgFromRaw command of the "READING EXAMPLES" section above.)

exiftool -DateTimeOriginal-='0:0:0 1:30:0' dir
Adjust original date/time of all images in directory dir by subtracting one hour and 30 minutes. (This is equivalent to -DateTimeOriginal-=1.5. See Image::ExifTool::Shift.pl for details.)

exiftool -createdate+=3 -modifydate+=3 a.jpg b.jpg
Add 3 hours to the CreateDate and ModifyDate timestamps of two images.

exiftool -AllDates+=1:30 -if '$make eq "Canon"' dir
Shift the values of DateTimeOriginal, CreateDate and ModifyDate forward by 1 hour and 30 minutes for all Canon images in a directory. (The AllDates tag is provided as a shortcut for these three tags, allowing them to be accessed via a single tag.)

exiftool -xmp:city=Kingston image1.jpg image2.nef
Write a tag to the XMP group of two images. (Without the xmp: this tag would get written to the IPTC group since City exists in both, and IPTC is preferred by default.)

exiftool -LightSource-='Unknown (0)' dst.tiff
Delete LightSource tag only if it is unknown with a value of 0.

exiftool -whitebalance-=auto -WhiteBalance=tung dst.jpg
Set WhiteBalance to Tungsten only if it was previously Auto.

exiftool -comment-= -comment='new comment' a.jpg
Write a new comment only if the image doesn't have one already.

exiftool -o %d%f.xmp dir
Create XMP meta information data files for all images in dir.

exiftool -o test.xmp -owner=Phil -title='XMP File'
Create an XMP data file only from tags defined on the command line.

exiftool '-ICC_Profile<=%d%f.icc' image.jpg
Write ICC_Profile to an image from a .icc file of the same name.

exiftool -hierarchicalkeywords='{keyword=one,children={keyword=B}}'
Write structured XMP information. See https://exiftool.org/struct.html for more details.

exiftool -trailer:all= image.jpg
Delete any trailer found after the end of image (EOI) in a JPEG file. A number of digital cameras store a large PreviewImage after the JPEG EOI, and the file size may be reduced significantly by deleting this trailer. See the JPEG Tags documentation for a list of recognized JPEG trailers.

COPYING EXAMPLES
These examples demonstrate the ability to copy tag values between files.

exiftool -tagsFromFile src.cr2 dst.jpg
Copy the values of all writable tags from src.cr2 to dst.jpg, writing the information to same-named tags in the preferred groups.

exiftool -TagsFromFile src.jpg -all:all dst.jpg
Copy the values of all writable tags from src.jpg to dst.jpg, preserving the original tag groups.

exiftool -all= -tagsfromfile src.jpg -exif:all dst.jpg
Erase all meta information from dst.jpg image, then copy EXIF tags from src.jpg.

exiftool -exif:all= -tagsfromfile @ -all:all -unsafe bad.jpg
Rebuild all EXIF meta information from scratch in an image. This technique can be used in JPEG images to repair corrupted EXIF information which otherwise could not be written due to errors. The Unsafe tag is a shortcut for unsafe EXIF tags in JPEG images which are not normally copied. See the tag name documentation for more details about unsafe tags.

exiftool -Tagsfromfile a.jpg out.xmp
Copy meta information from a.jpg to an XMP data file. If the XMP data file out.xmp already exists, it will be updated with the new information. Otherwise the XMP data file will be created. Only metadata-only files may be created like this (files containing images may be edited but not created). See "WRITING EXAMPLES" above for another technique to generate XMP files.

exiftool -tagsFromFile a.jpg -XMP:All= -ThumbnailImage= -m b.jpg
Copy all meta information from a.jpg to b.jpg, deleting all XMP information and the thumbnail image from the destination.

exiftool -TagsFromFile src.jpg -title -author=Phil dst.jpg
Copy title from one image to another and set a new author name.

exiftool -TagsFromFile a.jpg -ISO -TagsFromFile b.jpg -comment dst.jpg
Copy ISO from one image and Comment from another image to a destination image.

exiftool -tagsfromfile src.jpg -exif:all --subifd:all dst.jpg
Copy only the EXIF information from one image to another, excluding SubIFD tags.

exiftool '-FileModifyDate<DateTimeOriginal' dir
Use the original date from the meta information to set the same file's filesystem modification date for all images in a directory. (Note that -TagsFromFile @ is assumed if no other -TagsFromFile is specified when redirecting information as in this example.)

exiftool -TagsFromFile src.jpg '-xmp:all<all' dst.jpg
Copy all possible information from src.jpg and write in XMP format to dst.jpg.

exiftool '-Description<${FileName;s/\.[^.]*$//}' dir
Set the image Description from the file name after removing the extension. This example uses the "Advanced formatting feature" to perform a substitution operation to remove the last dot and subsequent characters from the file name.

exiftool -@ iptc2xmp.args -iptc:all= a.jpg
Translate IPTC information to XMP with appropriate tag name conversions, and delete the original IPTC information from an image. This example uses iptc2xmp.args, which is a file included with the ExifTool distribution that contains the required arguments to convert IPTC information to XMP format. Also included with the distribution are xmp2iptc.args (which performs the inverse conversion) and a few more .args files for other conversions between EXIF, IPTC and XMP.

exiftool -tagsfromfile %d%f.CR2 -r -ext JPG dir
Recursively rewrite all JPG images in dir with information copied from the corresponding CR2 images in the same directories.

exiftool '-keywords+<make' image.jpg
Add camera make to list of keywords.

exiftool '-comment<ISO=$exif:iso Exposure=${shutterspeed}' dir
Set the Comment tag of all images in dir from the values of the EXIF:ISO and ShutterSpeed tags. The resulting comment will be in the form "ISO=100 Exposure=1/60".

exiftool -TagsFromFile src.jpg -icc_profile dst.jpg
Copy ICC_Profile from one image to another.

exiftool -TagsFromFile src.jpg -all:all dst.mie
Copy all meta information in its original form from a JPEG image to a MIE file. The MIE file will be created if it doesn't exist. This technique can be used to store the metadata of an image so it can be inserted back into the image (with the inverse command) later in a workflow.

exiftool -o dst.mie -all:all src.jpg
This command performs exactly the same task as the command above, except that the -o option will not write to an output file that already exists.

exiftool -b -jpgfromraw -w %d%f_%ue.jpg -execute -b -previewimage -w %d%f_%ue.jpg -execute -tagsfromfile @ -srcfile %d%f_%ue.jpg -overwrite_original -common_args --ext jpg DIR
[Advanced] Extract JpgFromRaw or PreviewImage from all but JPG files in DIR, saving them with file names like image_EXT.jpg, then add all meta information from the original files to the extracted images. Here, the command line is broken into three sections (separated by -execute options), and each is executed as if it were a separate command. The -common_args option causes the --ext jpg DIR arguments to be applied to all three commands, and the -srcfile option allows the extracted JPG image to be the source file for the third command (whereas the RAW files are the source files for the other two commands).

RENAMING EXAMPLES
By writing the FileName and Directory tags, files are renamed and/or moved to new directories. This can be particularly useful and powerful for organizing files by date when combined with the -d option. New directories are created as necessary, but existing files will not be overwritten. The format codes %d, %f and %e may be used in the new file name to represent the directory, name and extension of the original file, and %c may be used to add a copy number if the file already exists (see the -w option for details). Note that if used within a date format string, an extra '%' must be added to pass these codes through the date/time parser. (And further note that in a Windows batch file, all '%' characters must also be escaped, so in this extreme case '%%%%f' is necessary to pass a simple '%f' through the two levels of parsing.) See https://exiftool.org/filename.html for additional documentation and examples.

exiftool -filename=new.jpg dir/old.jpg
Rename old.jpg to new.jpg in directory dir.

exiftool -directory=%e dir
Move all files from directory dir into directories named by the original file extensions.

exiftool '-Directory<DateTimeOriginal' -d %Y/%m/%d dir
Move all files in dir into a directory hierarchy based on year, month and day of DateTimeOriginal. eg) This command would move the file dir/image.jpg with a DateTimeOriginal of 2005:10:12 16:05:56 to 2005/10/12/image.jpg.

exiftool -o . '-Directory<DateTimeOriginal' -d %Y/%m/%d dir
Same effect as above except files are copied instead of moved.

exiftool '-filename<%f_${model;}.%e' dir
Rename all files in dir by adding the camera model name to the file name. The semicolon after the tag name inside the braces causes characters which are invalid in Windows file names to be deleted from the tag value (see the "Advanced formatting feature" for an explanation).

exiftool '-FileName<CreateDate' -d %Y%m%d_%H%M%S%%-c.%%e dir
Rename all images in dir according to the CreateDate date and time, adding a copy number with leading '-' if the file already exists (%-c), and preserving the original file extension (%e). Note the extra '%' necessary to escape the filename codes (%c and %e) in the date format string.

exiftool -r '-FileName<CreateDate' -d %Y-%m-%d/%H%M_%%f.%%e dir
Both the directory and the filename may be changed together via the FileName tag if the new FileName contains a '/'. The example above recursively renames all images in a directory by adding a CreateDate timestamp to the start of the filename, then moves them into new directories named by date.

exiftool '-FileName<${CreateDate}_$filenumber.jpg' -d %Y%m%d -ext jpg .
Set the filename of all JPG images in the current directory from the CreateDate and FileNumber tags, in the form "20060507_118-1861.jpg".

GEOTAGGING EXAMPLES
ExifTool implements geotagging from GPS log files via 3 special tags: Geotag (which for convenience is also implemented as an exiftool option), Geosync and Geotime. The examples below highlight some geotagging features. See https://exiftool.org/geotag.html for additional documentation. (Note that geotagging from known GPS coordinates is done by writing the GPS tags directly rather than using the -geotag option.)

exiftool -geotag track.log a.jpg
Geotag an image (a.jpg) from position information in a GPS track log (track.log). Since the Geotime tag is not specified, the value of SubSecDateTimeOriginal (preferentially) or DateTimeOriginal is used for geotagging. Local system time is assumed unless the time contains a timezone.

exiftool -geotag track.log -geolocate=geotag a.jpg
Geotag an image and also write geolocation information of the nearest city (city name, state/province and country). Read here for more details about the Geolocation feature: https://exiftool.org/geolocation.html#Write

exiftool -geotag t.log -geotime='2009:04:02 13:41:12-05:00' a.jpg
Geotag an image with the GPS position for a specific time.

exiftool -geotag log.gpx '-xmp:geotime<createdate' dir
Geotag all images in directory dir with XMP tags instead of EXIF tags, based on the image CreateDate.

exiftool -geotag a.log -geosync=-20 dir
Geotag images in directory dir, accounting for image timestamps which were 20 seconds ahead of GPS.

exiftool -geotag a.log -geosync=1.jpg -geosync=2.jpg dir
Geotag images using time synchronization from two previously geotagged images (1.jpg and 2.jpg), synchronizing the image and GPS times using a linear time drift correction.

exiftool -geotag a.log '-geotime<${createdate}+01:00' dir
Geotag images in dir using CreateDate with the specified timezone. If CreateDate already contained a timezone, then the timezone specified on the command line is ignored.

exiftool -geotag= a.jpg
Delete GPS tags which may have been added by the geotag feature. Note that this does not remove all GPS tags -- to do this instead use -gps:all=.

exiftool -xmp:geotag= a.jpg
Delete XMP GPS tags which were added by the geotag feature.

exiftool -xmp:geotag=track.log a.jpg
Geotag an image with XMP tags, using the time from SubSecDateTimeOriginal or DateTimeOriginal.

exiftool -geotag a.log -geotag b.log -r dir
Combine multiple track logs and geotag an entire directory tree of images.

exiftool -geotag 'tracks/*.log' -r dir
Read all track logs from the tracks directory.

exiftool -p gpx.fmt dir > out.gpx
Generate a GPX track log from all images in directory dir. This example uses the gpx.fmt file included in the full ExifTool distribution package and assumes that the images in dir have all been previously geotagged.

PIPING EXAMPLES
cat a.jpg | exiftool -
Extract information from stdin.

exiftool image.jpg -thumbnailimage -b | exiftool -
Extract information from an embedded thumbnail image.

cat a.jpg | exiftool -iptc:keywords+=fantastic - > b.jpg
Add an IPTC keyword in a pipeline, saving output to a new file.

curl -s http://a.domain.com/bigfile.jpg | exiftool -fast -
Extract information from an image over the internet using the cURL utility. The -fast option prevents exiftool from scanning for trailer information, so only the meta information header is transferred.

---
The Image::ExifTool Perl Library Module
Description
The Image::ExifTool library provides a set of Perl modules to read and write meta information in a wide variety of image, audio, video and document files. This document details the public methods of the ExifTool API.

Methods
All ExifTool features are accessed through the methods of the public interface listed below. Other Image::ExifTool methods and modules should not be accessed directly because their interface may change with future versions.

The ExifTool methods should never die or issue a warning to STDERR if called with the proper arguments (with the exception of SetNewValue which may send an error message to STDERR, but only when called in scalar context). Error and warning messages that occur during processing are stored in the values of the Error and Warning tags, and are accessible via the GetValue method to retrieve a single Error or Warning message, or GetInfo to retrieve any number of them.

The ExifTool methods are not thread safe.

ImageInfo
new
Options
ClearOptions
ExtractInfo
GetInfo
WriteInfo
GetTagList
GetFoundTags
GetRequestedTags
GetValue
SetNewValue
GetNewValue
SetNewValuesFromFile
CountNewValues
SaveNewValues
RestoreNewValues
SetAlternateFile
SetFileModifyDate
SetFileName
SetNewGroups
GetNewGroups
GetTagID
GetDescription
GetGroup
GetGroups
BuildCompositeTags
AvailableOptions
GetTagName
GetShortcuts
GetAllTags
GetWritableTags
GetAllGroups
GetDeleteGroups
GetFileType
CanWrite
CanCreate
AddUserDefinedTags
OrderedKeys
Using ExifTool
The ExifTool module may be used by simply calling the ImageInfo function:

use Image::ExifTool qw(:Public);
my $info = ImageInfo('image.jpg');
or in a more object-oriented fashion, by creating an ExifTool object:

use Image::ExifTool;
my $exifTool = Image::ExifTool->new;
my $info = $exifTool->ImageInfo('image.jpg');
The object-oriented method allows more flexibility, but is slightly more complicated. You choose the method that you prefer.

The $info value returned by ImageInfo in the above examples is a reference to a hash containing the tag/value pairs. Here is a simplified example which prints out this information:

foreach (keys %$info) {
    print "$_ => $$info{$_}\n";
}
See ImageInfo for a more detailed description of the info hash entries.

And the technique for writing meta information is equally simple:

use Image::ExifTool;
my $exifTool = Image::ExifTool->new;
$exifTool->SetNewValue(Author => 'Phil Harvey');
$exifTool->WriteInfo('image.jpg','modified_image.jpg');
Configuration
User-defined tags can be added via the ExifTool configuration file, or by defining the %Image::ExifTool::UserDefined hash before calling any ExifTool functions. See "ExifTool_config" in the ExifTool distribution for more details.

By default ExifTool looks for a configuration file named ".ExifTool_config" first in your home directory, then in the directory of the application script, but a different directory may be specified by setting the EXIFTOOL_HOME environment variable, or a different file may be specified by setting the ExifTool "configFile" variable before using Image::ExifTool. For example:

BEGIN { $Image::ExifTool::configFile = '/Users/phil/myconfig.cfg' }
use Image::ExifTool;
The configuration feature may also be disabled by setting "configFile" to an empty string:

BEGIN { $Image::ExifTool::configFile = '' }
use Image::ExifTool;
ImageInfo
Read image file and return meta information. This is the one-step function for retrieving meta information from an image. Internally, ImageInfo calls ExtractInfo to extract data from the image, GetInfo to generate the information hash, and GetTagList for the returned tag list.

Prototype	ImageInfo($;@)
Inputs	0) [optional] ExifTool object reference
1) File name, file reference or scalar reference
2-N) [optional] list of tag names to find (or tag list reference or options hash reference, see below)
Returns	Reference to hash of tag-key/value pairs
Examples:

Non object-oriented example showing use of options and returning tag list:
use Image::ExifTool qw(ImageInfo);
my @ioTagList;
my $info;

$info = ImageInfo('image.jpg', \@ioTagList, {Sort => 'Group0'});
Object-oriented example to read from a file that is already open:
my $exifTool = Image::ExifTool->new;

$info = $exifTool->ImageInfo(\*FILE_PT, 'Aperture', 'ShutterSpeed', 'ISO');
Extract information from an image in memory:
$info = $exifTool->ImageInfo(\$imageData);
Extract information from an embedded thumbnail image:
$info = ImageInfo('image.jpg', 'thumbnailimage');
my $thumbInfo = ImageInfo($$info{ThumbnailImage});
Using an ExifTool object to set the options before calling ImageInfo:
my $filename = shift || die "Please specify filename\n";
my @ioTagList = qw(filename imagesize xmp:creator exif:* -ifd1:*);

$exifTool->Options(Unknown => 1, DateFormat => '%H:%M:%S %a. %b. %e, %Y');
$info = $exifTool->ImageInfo($filename, \@ioTagList);
Function Arguments:

ImageInfo is very flexible about the arguments passed to it, and interprets them based on their type. It may be called with one or more arguments. The one required argument is either a SCALAR (the image file name), a file reference (a reference to the image file) or a SCALAR reference (a reference to the image in memory). Other arguments are optional. The order of the arguments is not significant, except that the first SCALAR is taken to be the file name unless a file reference or scalar reference comes earlier in the argument list.

Below is a more detailed explanation of how the ImageInfo function arguments are interpreted.

ExifTool ref	ImageInfo may be called with an ExifTool object if desired. Advantages of using the object-oriented form are that options may be set before calling ImageInfo, and the object may be used afterward to access member functions. Must be the first argument if used.
SCALAR	The first scalar argument is taken to be the file name unless an earlier argument specified the image data via a file reference (file ref) or data reference (SCALAR ref). The remaining scalar arguments are names of tags for requested information. All tags are returned if no tags are specified.
 
Tag names are case-insensitive and may be prefixed by optional group names separated by colons. A group name may begin with a family number (eg. '1IPTC:Keywords'), to restrict matches to a specific family. In the tag name, a '?' matches any single character and a '*' matches zero or more characters. Thus 'GROUP:*' represents all tags in a specific group. Wildcards may not be used in group names, with the exception that a group name of '*' may be used to extract all available instances of a tag regardless of the Duplicates setting (eg. '*:WhiteBalance'). Multiple groups may be specified (eg. 'EXIF:Time:*' extracts all EXIF Time tags). And finally, a leading '-' indicates a tag to be excluded (eg. '-IFD1:*'), or a trailing '#' causes the ValueConv value to be returned for this tag.
 
Note that keys in the returned information hash and elements of the returned tag list are not necessarily the same as these tag names because group names are removed, the case may be changed, and an instance number may be added. For this reason it is best to use either the keys of the returned hash or the elements of the returned tag list when accessing the tag values.
 
See the TagNames documentation for a complete list of ExifTool tag names.
File ref	A reference to an open image file. If you use this method (or a SCALAR reference) to access information in an image, the FileName and Directory tags will not be returned. (Also, the FileSize, FileModifyDate, FilePermissions and FileAttributes tags will not be returned unless it is a plain file.) Image processing begins at the current file position, and on return the file position is unspecified. May be either a standard filehandle or a reference to a File::RandomAccess object.
 
[Advanced: To allow a non-rewindable stream (eg. a network socket) to be re-read after processing with ExifTool, first wrap the file reference in a File::RandomAccess object, then pass this object to ImageInfo. The File::RandomAccess object will buffer the file if necessary, and may be used to re-read the file after ImageInfo returns.]
SCALAR ref	A reference to image data in memory.
ARRAY ref	Reference to a list of tag names. On entry, any elements in the list are added to the list of requested tags. On return, this list is updated to contain an ordered list of tag keys for the returned information.
 
There will be 1:1 correspondence between the requested tags and the returned tag keys only if the Duplicates option is 0 and Sort is 'Input'. (With Duplicates enabled, there may be more entries in the returned list of tag keys, and with other Sort settings the entries may not be in the same order as requested.) If a requested tag doesn't exist, a tag key is still generated, but the tag value is undefined.
 
Note: Do not reuse this list in subsequent calls to ImageInfo because it returns tag keys, not names, and the list will grow for each call resulting in increasingly slower performance.
HASH ref	Reference to a hash containing the options settings valid for this call only. See Options documentation below for a list of available options. Options specified as arguments to ImageInfo take precedence over Options settings.
Return Value:

ImageInfo returns a reference to a hash of tag-key/value pairs. The tag keys are identifiers -- essentially case-sensitive tag names with an appended instance number if multiple tags with the same name were extracted from the image. Many of the ExifTool functions require a tag key as an argument. Use GetTagName to get the tag name for a given tag key. Note that the case of the tag names may not be the same as requested.

Values of the returned hash are usually simple scalars, but a scalar reference is used to indicate binary data and an array reference may be used to indicate a list. Also, a hash reference may be returned if the Struct option is used (see the OrderedKeys option to obtain the hash keys). Lists of values are joined by commas into a single string only if the PrintConv option is enabled and the ListJoin option is enabled (which are the defaults). Note that binary values are not necessarily extracted unless specifically requested, or the Binary option is enabled and the tag is not specifically excluded. If not extracted the value is a reference to a string of the form "Binary data ##### bytes".

Here is a simple example to print out the information returned by ImageInfo:

foreach (keys %$info) {
    my $val = $$info{$_};
    if (ref $val eq 'ARRAY') {
        $val = join(', ', @$val);
    } elsif (ref $val eq 'SCALAR') {
        $val = '(Binary data)';
    }
    printf("%-24s : %s\n", $_, $val);
}
which gives output like this (PrintConv enabled):

WhiteBalance             : Auto
FNumber                  : 3.5
InteroperabilityOffset   : 936
XResolution              : 72
ISO                      : 100
ThumbnailImage           : (Binary data)
FlashOn                  : On
Make                     : FUJIFILM
ShutterSpeedValue        : 1/64
ExposureCompensation     : 0
Sharpness                : Soft
ResolutionUnit           : inches
Notes:

ExifTool returns all values as byte strings of encoded characters. Perl wide characters are not used. See FAQ number 10 for details about the encodings. By default, most returned strings are encoded in UTF-8. For these, Encode::decode_utf8() may be used to convert to a sequence of logical Perl characters.

As well as tags representing information extracted from the image, the following Extra tags generated by ExifTool may be returned:

ExifToolVersion	The ExifTool version number
Error	An error message if the image could not be processed
Warning	A warning message if problems were encountered while processing the image
new
Create a new ExifTool object.

Example:

my $exifTool = Image::ExifTool->new;
One ExifTool object may be used to process many files, so creating multiple ExifTool objects usually is not necessary.

Note that ExifTool uses AUTOLOAD to load non-member methods, so any class using Image::ExifTool as a base class must define an AUTOLOAD which calls Image::ExifTool::DoAutoLoad(). ie)

sub AUTOLOAD
{
    Image::ExifTool::DoAutoLoad($AUTOLOAD, @_);
}
The following functions require an ExifTool object as the first argument
Options
Get/set ExifTool options. This function can be called to set the default options for an ExifTool object. Options set this way are in effect for all function calls but may be overridden by options passed as arguments to some functions. Option names are not case sensitive, but option values are.

The default option values may be changed by defining a %Image::ExifTool::UserDefined::Options hash. See the ExifTool_config file in the full ExifTool distribution for examples. Unless otherwise noted, a default of undef has the same effect as a value of 0 for options with numerical values.

Prototype	Options($$;@)
Inputs	0) ExifTool object reference
1) Parameter name (case-insensitive, see table below)
2) [optional] Option value if specified (may be undef to clear option)
3-N) [optional] Additional parameter/value pairs
Returns	Previous value of last specified parameter
Available options:

Note that these API options may be also be used in the exiftool application via the command-line -api option.

ExifTool Options
Option	Description	Values	Default
Binary	Flag to extract the value data for all binary tags. Tag values representing large binary data blocks (eg. ThumbnailImage) are not necessarily extracted unless this option is set or the tag is specifically requested by name.	0 or 1	undef
ByteUnit	Units for print conversion of FileSize and other byte values.	
SI =	SI units (1000 bytes = 1 kB)
Binary =	Binary units (1024 bytes = 1 KiB)
'SI'
BlockExtract	Flag to extract some directories (mentioned in the Tag Name documentation) as a block.	
0 =	Extract as block only if tag specified by name
1 =	Extract as block, and extract contained tags
2 =	Extract as block without contained tags
undef
ByteOrder	The byte order for newly created EXIF segments when writing. Note that if EXIF information already exists, the existing order is maintained. If ByteOrder is not defined, then the order of the maker notes is used (if they are being copied), otherwise big-endian ('MM') order is assumed. This can also be set via the ExifByteOrder tag, but the ByteOrder option takes precedence if both are set.	'MM','II' or undef	undef
Charset	Character set for encoding character strings passed to/from ExifTool containing code points above U+007F. Note that this option affects some types of information when reading/writing the file and other types when getting/setting tag values, so it must be defined for both types of access. Charset values listed to the right have aliases which are given in brackets. Case is not significant. See FAQ #10 for more information about character sets.	
UTF8	(cp65001, UTF-8)
Latin	(cp1252, Latin1)
Latin2	(cp1250)
Cyrillic	(cp1251, Russian)
Greek	(cp1253)
Turkish	(cp1254)
Hebrew	(cp1255)
Arabic	(cp1256)
Baltic	(cp1257)
Vietnam	(cp1258)
Thai	(cp874)
DOSLatinUS	(cp437)
DOSLatin1	(cp850)
DOSCyrillic	(cp866)
MacRoman	(cp10000, Mac, Roman)
MacLatin2	(cp10029)
MacCyrillic	(cp10007)
MacGreek	(cp10006)
MacTurkish	(cp10081)
MacRomanian	(cp10010)
MacIceland	(cp10079)
MacCroatian	(cp10082)
'UTF8'
CharsetEXIF	Internal encoding to use for stored EXIF "ASCII" string values. May also be set to undef to pass through EXIF "ASCII" values without recoding. Set to "UTF8" to conform with the MWG recommendation.	(see Charset option)
or undef	undef
CharsetFileName	External character set used for file names passed to ExifTool functions. Default is undef but "UTF8" is assumed in Windows if the file name contains special characters and is valid UTF8. May also be set to an empty string to avoid "encoding must be specified" warnings on Windows. Note that setting the WindowsWideFile or WindowsLongPath option causes CharsetFileName to default to 'UTF8' in Windows if not defined, and that WindowsLongPath is set by default in ExifTool 13.07 and later.	(see Charset option)
or undef	undef
CharsetID3	Internal encoding to assume for ID3v1 strings. By the specification ID3v1 strings should be encoded in ISO 8859-1 (essentially 'Latin'), but some applications may use local encoding instead. This option allows different encodings to be specified.	(see Charset option)	'Latin'
CharsetIPTC	Fallback internal IPTC character set to assume if IPTC information contains no CodedCharacterSet tag.	(see Charset option)	'Latin'
CharsetPhotoshop	Internal encoding to assume for Photoshop IRB resource names.	(see Charset option)	'Latin'
CharsetQuickTime	Internal encoding to assume for QuickTime strings stored with an unspecified encoding.	(see Charset option)	'MacRoman'
CharsetRIFF	Internal encoding to assume for strings in RIFF metadata (eg. AVI and WAV files). The default value of 0 assumes 'Latin' encoding unless otherwise specified by the RIFF CSET chunk. Set to undef to pass through strings without recoding.	(see Charset option)
or 0 or undef	0
Compact	Comma-delimited list of settings for writing compact XMP. Note that 'NoPadding' effects only embedded XMP since padding is never written for stand-alone XMP files. Also note that 'OneDesc' is not recommended when writing XMP larger than 64 KiB to a JPG file because it interferes with ExifTool's technique of splitting off large rdf:Description elements into the extended XMP. Case is not significant for any of these options. Some options have aliases (shown in brackets).	
NoPadding =	Avoid 2 KiB of recommended padding at end of XMP (NoPad)
NoIndent =	Avoid spaces to indent lines for readability (NoSpace, NoSpaces)
NoNewline =	Avoid unnecessary newlines (NoNewlines)
Shorthand =	Use XMP Shorthand format
OneDesc =	Combine XMP properties into a single rdf:Description (OneDescr)
AllSpace =	'NoPadding,NoIndent,NoNewline'
AllFormat =	'Shorthand,OneDesc'
All =	'AllSpace,AllFormat'
undef
Composite	Flag to generate Composite tags when extracting information.	0 or 1	1
Compress	Flag to write new values in compressed format if possible. Has no effect unless the relevant compression library is available. Valid when writing metadata to PNG, JXL, HEIC or MIE images. Setting this to zero causes JXL metadata to be rewritten as uncompressed when edited.	0, 1 or undef	undef
CoordFormat	Specify output format for GPS coordinates.	A printf-style format string with specifiers for degrees, minutes and seconds in that order, however minutes and seconds may be omitted. If the hemisphere is known, a reference direction (N, S, E or W) is appended to each printed coordinate, but adding a '+' or '-' to the first format specifier (eg. '%+.6f' or '%-.6f') prints a signed coordinate instead ('+' also adds a leading plus sign to positive coordinates, while '-' does not). The default for reading is equivalent to a format string of q{%d deg %d' %.2f"}, but to avoid a loss of precision the default for copying tags with SetNewValuesFromFile is q{%d %d %.8f}.	undef
DateFormat	Output format for date/time values. If date can not be converted, value is left unchanged unless the StrictDate option is set. The inversion conversion (ie. when calling SetNewValue) is performed only if POSIX::strptime or Time::Piece is installed.	See strftime manpage for details, and this page for common date/time formatting codes and additional ExifTool codes. The default setting of undef causes date/time values to remain in standard EXIF format (similar to a DateFormat of "%Y:%m:%d %H:%M:%S").	undef
Duplicates	Flag to return values from tags with duplicate names when extracting information. Forced to 1 when copying tags with SetNewValuesFromFile.	0 or 1	1
Escape	Escape special characters in extracted values for HTML or XML. Also unescapes HTML or XML character entities in input values passed to SetNewValue.	HTML, XML or undef	undef
Exclude	Exclude specified tags when extracting information. Note that this option is applied after all of the tags have already been loaded into memory (so different tags may be excluded in subsequent calls to GetInfo). See the IgnoreTags option to save memory by not loading the tags in the first place.	Tag name or reference to a list of tag names to exclude. Case is not significant. Tags may also be excluded by preceding their name with a '-' in the arguments to ImageInfo.	undef
ExtendedXMP	This setting affects the reading and editing of extended XMP in JPEG images. According to the XMP specification, extended XMP is only valid if it has the GUID specified by the HasExtendedXMP tag. ExifTool 9.95 and earlier would read extended XMP regardless of GUID, but with the addition of this option in version 9.96 the default behaviour was changed to conform with the XMP specification (to read only extended XMP with the proper GUID). This option should be set to 2 to emulate pre-9.96 behaviour and read all extended XMP. It may also be set to a GUID to read a specific extended XMP, or 0 to ignore extended XMP entirely.	
0 =	Ignore extended XMP
1 =	Valid GUID only
2 =	Any GUID
guid =	Specific GUID
1
ExtractEmbedded	Flag to extract information from embedded documents in EPS files, embedded EPS information and JPEG and Jpeg2000 images in PDF files, embedded MPF images in JPEG and MPO files, metadata after the first Cluster in MKV files, timed metadata in videos, all frames of a multipart EXR image, and the resource fork of Mac OS files. A setting of 2 also causes the H264 video stream in MP4 files to be parsed until the first SEI message is decoded, or 3 to parse the entire H264 stream in MP4 videos and the entire M2TS file to look for any unlisted program containing GPS metadata.	0, 1, 2 or 3	undef
FastScan	Flag to increase speed when reading files by avoiding extraction of some types of metadata. With this option set to 1, ExifTool will not scan to the end of a JPEG image to check for an AFCP, CanonVRD, FotoStation, PhotoMechanic, MIE or PreviewImage trailer. This also stops the parsing after the first comment in GIF images, and at the audio/video data of RIFF-format files (AVI, WAV, etc), so any trailing metadata (eg. XMP written by some utilities) may be missed. Also disables input buffering for some types of files to reduce memory usage when reading from a non-seekable stream, and bypasses CRC validation for speed when writing PNG files. When combined with the ScanForXMP option, prevents scanning for XMP in recognized file types. With a value of 2, ExifTool will also avoid extracting any EXIF MakerNote information, and will stop processing at the IDAT chunk of PNG images and the mdat atom in QuickTime-format files. (By the PNG specification, metadata is allowed after IDAT, but ExifTool always writes it before because some utilities will ignore it otherwise.) When set to 3 or higher, only pseudo system tags and FileType are generated. For 3, the file header is read to provide an educated guess at FileType. For 4, the file is not read at all and FileType is determined based on the file's extension. For 5, generation of Composite tags is also disabled (like setting Composite to 0).	0, 1, 2, 3, 4 or 5	undef
Filter	Perl expression used to filter all returned tag values. Applies to PrintConv values only. List items are filtered individually.	Expression to act on the value of the Perl default variable ($_), changing the value of this variable as required. The current ExifTool object may be accessed through $self. The value is not changed if $_ is set to undef.	undef
FilterW	Perl expression used to filter PrintConv values when writing.	Expression to act on the value of the Perl default variable ($_), changing the value of this variable as required. The current ExifTool object may be accessed through $self. The tag is not written if $_ is set to undef.	undef
FixBase	Fix maker notes base offset. Allows values to be extracted from maker notes which have been corrupted by editing with 3rd party software.	An integer specifying a value to be added to the maker notes base offset, or the empty string ('') for ExifTool to take its best guess at the correct base.	undef
GeoDir	[Not a real option] Provided as a convenience to allow $Image::ExifTool::geoDir to be set at runtime. This variable specifies the directory for the Geolocation databases, and is used only once when these databases are loaded.	-	-
Geolocation	Flag to generate geolocation tags based on the GPSLatitude/GPSLongitude or City/State/Province/Country information read from a file. This feature uses an included database with cities over a population of 2000 from geonames.org. May be set to a string of the form "Lat,Lon" (eg. "44.56,-72.33") or city with optional region, subregion, country and/or country code (eg. "Paris,France") to act as a default for files not containing GPS or geolocation information, or include tag names with leading dollar signs separated by commas to specify the tags to use for the geolocation input. When "Lat,Lon" is specified, "num=##" may be added to return the specified number of nearby cities (the Duplicates option must also be used for the duplicate tags to be returned). May include regular expressions for more flexible matching of city names. See Reading Geolocation information for more details.	0, 1, or comma-separated string with default location and/or tag names to use as input to the geolocation determination. See here for details.	undef
GeolocAltNames	Flag to search alternate Geolocation city names if available.	0 or 1	1
GeolocFeature	Feature codes to include or exclude in city search. Valid feature codes are PPL, PPLA, PPLA2, PPLA3, PPLA4, PPLA5, PPLC, PPLCH, PPLF, PPLG, PPLH, PPLL, PPLQ, PPLR, PPLS, PPLW, PPLX, STLMT and Other, plus possible user-included codes if an alternate database is used. Read here for a description of these codes.	Comma-separated list of feature codes, with leading dash (-) to exclude these features	undef
GeolocMaxDist	Maximum distance in km to the Geolocation city. The Geolocation tags are not generated if the distance is greater than this.	Any number	undef
GeolocMinPop	Minimum population for the Geolocation city. Cities smaller than this are ignored.	Any integer	undef
GeoMaxIntSecs	Maximum interpolation time in seconds for geotagging. Geotagging is treated as an extrapolation if the Geotime value lies between two fixes in the same track which are separated by a number of seconds greater than this. Otherwise, the coordinates are calculated as a linear interpolation between the nearest fixes on either side of the Geotime value. Set to 0 to disable interpolation and use the coordinates of the nearest fix instead (provided it is within GeoMaxExtSecs, otherwise geotagging fails).	A floating point number	1800
GeoMaxExtSecs	Maximum extrapolation time in seconds for geotagging. Geotagging fails if the Geotime value lies outside a GPS track by a number of seconds greater than this. Otherwise, for an extrapolation the coordinates of the nearest fix are taken (ie. it is assumed that you weren't moving during this period).	A floating point number	1800
GeoMaxHDOP	Maximum Horizontal (2D) Dilution Of Precision for geotagging. GPS fixes are ignored if the HDOP is greater than this.	A floating point number, or undef	undef
GeoMaxPDOP	Maximum Position (3D) Dilution Of Precision for geotagging. GPS fixes are ignored if the PDOP is greater than this.	A floating point number, or undef	undef
GeoMinSats	Minimum number of satellites for geotagging. GPS fixes are ignored if the number of acquired satellites is less than this.	A positive integer, or undef	undef
GeoSpeedRef	Reference units for writing GPSSpeed when geotagging.	
K, k or km/h	= km/h
M, m or mph	= mph
(anything else)	= knots
undef
GlobalTimeShift	Time shift to apply to all extracted date/time PrintConv values. Does not affect ValueConv values. When specifying a number of months and/or years to shift, the tag for the starting date should be specified so the number of days can be determined unambiguously. If not specified, or the specified tag isn't available, the shift is calculated based on the first shifted tag.	Date/time shift string with leading '-' for negative shifts (see Image::ExifTool::Shift.pl), or tag name with optional group prefix followed by '+' or '-' then shift string. eg)
'createdate-1:0:0 0:0:0' - shift back by the length of the year before the CreateDate value
'xmp:createdate+0:2:0 0' - shift forward by the length of the 2 months after XMP:CreateDate	undef
GPSQuadrant	This option is used to specify the GPS quadrant in the case where a warning was issued because the GPS quadrant couldn't be determined.	2-character quadrant code where the first character is 'N' or 'S' and the second is 'E' or 'W' (case insensitive). If this option is not set and the quadrant is unknown, a warning is issued and the quadrant is assumed to be 'NE'.	undef
Group#	Extract tags only for specified groups in family # (Group0 assumed if # not given).	Group name or reference to list of group names. Group name may begin with '-' to exclude a group. Case IS significant. See GetGroup for a description of group families, and GetAllGroups for a list of available groups.	undef
HexTagIDs	Use hexadecimal instead of decimal for the family 7 group names of tags with numerical ID's.	0 or 1	undef
HtmlDump	Dump information in hex to a dynamic HTML web page. Option value sets a limit on the maximum block size. Output file is specified by the TextOut option.	
0 =	No HTML dump
1 =	1 KB size limit
2 =	16 KB size limit
3 =	Full dump
0
HtmlDumpBase	Base for HTML dump offsets. If not defined, the EXIF/TIFF base offset is used.	
0 =	Absolute offsets
non‑zero =	Relative offsets
undef =	EXIF/TIFF offsets
undef
IgnoreGroups	List of group names to ignore when reading. The group names are case insensitive and may be preceded by a family number.	List reference, delimited string of names (any delimiter is allowed), or undef to clear the previous IgnoreGroups list.	undef
IgnoreMinorErrors	Flag to ignore minor errors. Causes minor errors to be downgraded to warnings, and minor warnings to be ignored. This option is provided mainly to allow writing of files when minor errors occur, but by ignoring some minor warnings the behaviour of ExifTool may be changed to allow some questionable operations to proceed (such as extracting thumbnail and preview images even if they don't have a recognizable header). Minor errors/warnings are denoted by "[minor]" at the start of the message, or "[Minor]" (with a capital "M") for warnings that affect processing when ignored.	0 or 1	undef
IgnoreTags	List of tag names to ignore when reading. This may help in situations where memory is limited because the ignored tag values are not stored in memory. The tag names are case insensitive and group names and wildcards are not allowed. A special tag name of "All" may be used to ignore all tags except those specified by the RequestTags option.	List reference, delimited string of names (any delimiter is allowed), or undef to clear the previous IgnoreTags list.	undef
ImageHashType	Sets type of hash algorithm used for the ImageDataHash tag calculation.	'MD5', 'SHA256' or 'SHA512'	'MD5'
KeepUTCTime	Flag to keep UTC times in Zulu time zone instead of converting to local time. Affects only times which are stored as seconds since the UTC epoch.	0 or 1	undef
Lang	Localized language for ExifTool tag descriptions, etc. If the specified language isn't available, the option is not changed. May be set to undef to select the built-in default language.	Image::ExifTool::Lang module name (eg. 'fr', 'zh_cn'), or 'en' or undef for the default language.	'en'
LargeFileSupport	Flag to indicate that 64-bit file offsets are supported on this system. If not set, processing is aborted if a chunk larger than 2 GB is encountered. Set to 1 to process large chunks, or 2 to process with a warning.	0, 1 or 2	1
LimitLongValues	When extracting some values for some specific tags (usually Unknown tags), the PrintConv values are length-limited and the value is truncated with an ellipsis ("[...]") if it exceeds a specified length. This option specifies the length limit for these tags. A setting of 4 or less disables the limit (because the ellipsis string is longer than this).	Any integer	60
ListItem	Return only a specific item from list-type values. A value of 0 returns the first item in each list, 1 returns the second item, etc. Negative indices may also be used, with -1 representing the last item in the list. Applies only to the top-level list of nested lists.	An integer, or undef	undef
ListJoin	Separator used to join the PrintConv value of multi-item List-type tags into a single string. If not defined, multi-item lists are returned as a list reference. Does not affect ValueConv values.	Any string, or undef	', '
ListSplit	Regular expression used to split values of list-type tags into individual items when writing. (eg. Use ',\\s*' to split a comma-separated list.) Split when writing either PrintConv or ValueConv values.	A regular expression pattern, or undef	undef
MakerNotes	Option to extract MakerNotes and other writable subdirectories (such as PrintIM) as a data block. Normally when the MakerNotes are extracted they are rebuilt to include data outside the boundaries of the original maker note data block, but a value of 2 disables this feature.	
0 =	Don't extract writable subdirectories
1 =	Extract and rebuild makernotes into self-contained block
2 =	Extract without rebuilding makernotes
undef
MDItemTags	Flag to extract the OS X metadata item tags (see the "mdls" man page and the MacOS MDItem Tags documentation for more information).	0 or 1	undef
MissingTagValue	Value for missing tags interpolated in tag name expressions (or tags where the advanced formatting expression returns undef). If not set, a minor error is issued for missing values, or the value is set to '' if IgnoreMinorErrors is set.	Any string, or undef	undef
NoDups	Flag to remove duplicate items from queued values for List-type tags when writing. This applies only to queued values, and doesn't resolve duplicates with existing values in the file when adding to an existing list.	0 or 1	undef
NoMandatory	Flag to bypass writing of mandatory EXIF tags.	0 or 1	undef
NoMultiExif	Raise error when attempting to write multi-segment EXIF in a JPEG image.	0 or 1	undef
NoPDFList	Flag to avoid splitting PDF list-type tag values into separate items.	0 or 1	undef
NoWarning[+]	Regular expression to suppress matching warning messages. For example, a value of "^Ignored" suppresses all warnings that begin with the word "Ignored". Has no other effect on processing, unlike IgnoreMinorErrors for some warnings. Start the expression with "(?i)" for case-insensitive matching. Use NoWarning+ to add to existing expressions.	A regular expression pattern, or undef	undef
Password	Password for reading/writing password-protected PDF documents. Ignored if a password is not required. Character encoding of the password is determined by the value of the Charset option at processing time.	Any string	undef
Plot	Settings for SVG plot feature as a comma-delimited string. Commas in the values must be escaped as "&#44;". Valid settings and their default values are:
"Type=Line"	-	type of plot (Line, Scatter or Histogram)
"Style=Line"	-	data style (Line, Marker and/or Fill)
"NBins=20"	-	number of histogram bins
"Size=800 600"	-	width,height of output image
"Margin=60 15 15 30"	-	left,top,right,bottom margins around plot area
"Legend=0 0"	-	x,y offset to shift plot legend
"TxtPad=10 10"	-	padding between text and x,y scale
"LineSpacing=20"	-	spacing between text lines
"Stroke=1"	-	plot stroke width and marker-size scaling
Title, XLabel, YLabel	-	plot title and x/y axis labels (no default)
XMin, XMax	-	x axis minimum/maximum (auto scaling if not set)
YMin, YMax	-	y axis minimum/maximum
"Multi="	-	flag to draw multiple plots, one for each dataset
"Split="	-	flag to split strings of numbers into lists (>1 to split into lists of N items)
"Grid=darkgray"	-	grid color
"Text=black"	-	text and border color
"Bkg="	-	background color (default transparent)
"Cols=red green blue black orange gray fuchsia brown turquoise gold" - colors for plot data
"Marks=circle square triangle diamond star plus pentagon left down right" - marker-shape names for each dataset
Comma-delimited string of settings to override default values, or undef to revert to default settings. Settings are accumulated if this option is set multiple times.

See The ExifTool Plot Feature for more details and examples.	undef
PrintConv	Flag to enable print conversion. Also enables inverse print conversion for writing.	0 or 1	1
PrintCSV	Flag to directly print CSV-format output rather than extracting tags normally. Currently, this feature this applies only to GM PDR data. Setting this option automatically sets IgnoreTags to "all", and ExtractEmbedded to 1.	0 or 1	undef
QuickTimeHandler	Flag set to add an 'mdir' Handler to a newly created Meta box when adding QuickTime ItemList tags. Adobe Bridge does not add this Handler, but it is commonly found in samples from other software, and it has been reported that Apple QuickTime Player and Photos.apps will ignore ItemList tags if this is missing.	0 or 1	1
QuickTimePad	Flag to preserve the padding of some QuickTime atoms when writing. QuickTime-based Canon CR3 files pad the values of container atoms with null bytes. This padding is removed by default when the file is rewritten, but setting this option to 1 adds padding to preserve the original atom size if the new atom would be smaller than the original.	0 or 1	undef
QuickTimeUTC	Flag set to assume that integer-valued QuickTime date/time values are stored as UTC, causing conversion to local time when they are extracted and from local time when written. According to the QuickTime specification these date/time values should be UTC, but many digital cameras store local time instead (presumably because they don't know the time zone), so the default is to not convert these times (except for Canon CR3 files, which always use UTC times). This option also disables the auto-detection of incorrect time-zero offsets in these date/time values, and enforces a time zero of 1904 as per the QuickTime specification.	0 or 1	undef
RequestAll	Flag to request all tags to be extracted. This causes some tags to be generated which normally would not be unless specifically requested (by passing the tag name to ImageInfo or ExtractInfo). May be set to 2 or 3 to enable generation of some additional tags as mentioned in the Tag Name documentation.	0, 1, 2 or 3	undef
RequestTags	List of additional tag and/or group names to request in the next call to ExtractInfo. This option is useful only for tags/groups which aren't extracted unless specifically requested. Groups are requested by adding a colon after the name (eg. "MacOS:"). Names are converted to lower case as they are added to the list.	List reference, delimited string of names (any delimiter is allowed), or undef to clear the previous RequestTags list.	undef
SaveBin	Flag to save binary values of tags, accessible through calls to GetValue with a value type of "Bin".	0 or 1	undef
SaveFormat	Flag to save EXIF/TIFF format type as the family 6 group name when extracting information. Without this option set, the family 6 group names are not generated. See GetGroup for more details.	0 or 1	undef
SavePath	Flag to save the metadata path as the family 5 group name when extracting information. Without this option set, the family 5 group names are not generated. See GetGroup for more details.	0 or 1	undef
ScanForXMP	Flag to scan all files (even unrecognized formats) for XMP information unless XMP was already found in the file. When combined with the FastScan option, only unrecognized file types are scanned for XMP.	0 or 1	undef
Sort	Specifies order to sort tags in the returned tag list.	
Input =	Sort in same order as input tag arguments
File =	Sort in order that tags were found in the file
Tag =	Sort alphabetically by tag name
Descr =	Sort by tag description (with current Lang setting)
Group# =	Sort by tag group, where # is zero or more family numbers separated by colons. If # is not specified, Group0 is assumed. See GetGroup for a description of group families.
'Input'
Sort2	Secondary sort order used for tags within each group when Sort is 'Group'.	
File =	Sort in order that tags were found in the file
Tag =	Sort alphabetically by tag name
Descr =	Sort by tag description (with current Lang setting)
'File'
StrictDate	Flag to return undefined value for any date which can't be converted when the DateFormat option is used. When set to 1 while writing a PrintConv date/time value with the DateFormat option set, the value is written only if POSIX::strptime or Time::Piece is available and can successfully convert the value. For PNG CreationTime, a setting of 1 has the additional effect of causing the date/time to be reformatted according to PNG 1.2 recommendation (RFC-1123) when writing, and a warning to be issued for any non-standard value when reading (but note that Windows may not recognize PNG date/time values in standard format).	
undef =	Same as 0 for reading/writing or 1 for copying
0 =	Return bad date/time values unchanged
1 =	Return undef if date/time value can't be converted
undef
Struct	Flag to return XMP structures as HASH references instead of flattening into individual tags. This setting has no effect when writing since both flattened and structured tags may always be written. See the Structured Information documentation for more details about structured information. A special "_ordered_keys_" element containing a list of ordered keys may exist if the structure elements are ordered (see the OrderedKeys method).	
undef =	Same as 0 for reading and 2 for copying
0 =	Read/copy flattened tags
1 =	Read/copy structures
2 =	Read/copy both flattened and structured tags, but flag flattened tags as "unsafe" for copying
undef
StructFormat	Format for serialized structures when reading/writing. Read here for more details about structured information. Note that the JSONQ setting causes all values in the exiftool application -json output to be quoted, regardless of whether or not they are in a structure.	
undef =	ExifTool format
JSON =	JSON format
JSONQ =	JSON with quoted numbers
undef
SystemTags	Flag to extract the following additional File System tags: FileAttributes, FileDeviceNumber, FileInodeNumber, FileHardLinks, FileUserID, FileGroupID, FileDeviceID, FileBlockSize and FileBlockCount.	0 or 1	undef
TextOut	Output file for Verbose and HtmlDump options.	File reference	\*STDOUT
TimeZone	Set the time zone for local date/time values. The value is a time zone offset like "+05:00" (but note that the offset is to UTC, not from UTC, so it is positive for western time zones), or a time zone name like "EST5EDT". For Unix-based systems, the value may also be a time zone ID like "America/New_York". Requires Time::Piece on Windows, or POSIX::tzset on other systems.	Time zone offset or ID, or undef to use the system time zone	undef
UndefTags	Flag to maintain undefined tag values in the application -if expression when the -f or -m option is also used.	0 or 1	undef
Unknown	Control extraction of unknown tags.	
0 =	Unknown tags not extracted
1 =	Unknown tags are extracted from EXIF (and other tagged-format) directories
2 =	Unknown tags also extracted from binary data blocks
0
UserParam	Special option to set/get user-defined parameters. Useful to allow external input into tag name expressions and ValueConv logic. PARAM is the user-defined parameter name (case insensitive). These parameters may be accessed in tag name expressions by prefixing the parameter name with a dollar sign just like normal tags, or via the API by calling Options('UserParam','PARAM'). Appending a hash tag (#) to the parameter name also causes the parameter to be extracted as a normal tag (in the UserParam group). If called without additional arguments, Options('UserParam') returns a reference to the hash of all user parameters (with lower-case names).	
PARAM	-	Get parameter
PARAM=	-	Clear parameter
PARAM^=	-	Set parameter to empty string
PARAM=VALUE	-	Set parameter
hash ref	-	Set UserParam hash
undef	-	Clear UserParam hash
{ }
Validate	Flag to perform extra metadata validation checks when reading, causing extra warnings to be generated if problems are found.	0 or 1	undef
Verbose	Print verbose messages to file specified by TextOut option. Click here for example outputs.	
0 =	No verbose messages
1 =	Print tag names and raw values
2 =	Add additional tag details
3 =	Add hex dump of tag data (with length limits)
4 =	Remove length limit on dump of tag values
5 =	Remove length limit on dump of JPEG segments
0
WindowsLongPath	Support long path names in Windows. Enabling this option automatically enables the WindowsWideFile feature.	0 or 1	1
WindowsWideFile	Force the use of wide-character Windows I/O functions. This may be necessary when files are on a network drive and the current directory name contains Unicode characters. Without this option the wide-character functions are used only if the specified file path contains Unicode characters.	0 or 1	undef
WriteMode	Set tag write/create mode. The level of the group differs for different types of metadata. For XMP or IPTC this is the full XMP/IPTC block (the family 0 group), but for EXIF this is the individual IFD (the family 1 group). The 'w' and 'c' modes are tested only when SetNewValue is called, but the 'g' mode is also tested in WriteInfo.	A string with one or more of these characters:
w =	Write existing tags
c =	Create new tags
g =	Create new groups †
'wcg'
XAttrTags	Flag to extract the OS X extended attribute tags (see the "xattr" man page and the MacOS XAttr Tags documentation for more information).	0 or 1	undef
XMPAutoConv	Flag to enable automatic conversion when reading unknown XMP tags with values that look like rational numbers or dates.	0 or 1	1
†	The level of the group differs for different types of metadata. For XMP or IPTC this is the full XMP/IPTC block (the family 0 group), but for EXIF this is the individual IFD (the family 1 group).
Examples:

# exclude the 'OwnerName' tag from returned information
$exifTool->Options(Exclude => 'OwnerName');
# only get information in EXIF or MakerNotes groups
$exifTool->Options(Group0 => ['EXIF', 'MakerNotes']);
# ignore information from IFD1
$exifTool->Options(Group1 => '-IFD1');
# sort by groups in family 2, and extract unknown tags
$exifTool->Options(Sort => 'Group2', Unknown => 1);
# reset DateFormat option
$exifTool->Options(DateFormat => undef);
# do not extract duplicate tag names
$oldSetting = $exifTool->Options(Duplicates => 0);
# get current Verbose setting
$isVerbose = $exifTool->Options('Verbose');
# set a user parameter
$exifTool->Options(UserParam => 'MyParam=some value');
ClearOptions
Reset all options to their default values. Loads user-defined default option values from the %Image::ExifTool::UserDefined::Options hash in the .ExifTool_config file if it exists.

Prototype	ClearOptions()
Inputs	0) ExifTool object reference
ExtractInfo
Extract all meta information from an image.

Prototype	ExtractInfo($;@)
Inputs	0) ExifTool object reference
1-N) Same as ImageInfo except that a list of tag keys is not returned if an ARRAY reference is given.
Returns	1 if this was a recognized file format, 0 otherwise
Example:

$success = $exifTool->ExtractInfo('image.jpg', \%options);
GetInfo
GetInfo is called to return meta information after it has been extracted from the image by a previous call to ExtractInfo or ImageInfo. This function may be called repeatedly after a single call to ExtractInfo or ImageInfo.

Prototype	GetInfo($;@)
Inputs	0) ExifTool object reference
1-N) Same as ImageInfo except that an image can not be specified
Returns	Reference to information hash, the same as with ImageInfo
Examples:

# get image width and height only
$info = $exifTool->GetInfo('ImageWidth', 'ImageHeight');
# get all Error and Warning messages
$info = $exifTool->GetInfo('Error', 'Warning');
# get information for all tags in list (list updated with tags found)
$info = $exifTool->GetInfo(\@ioTagList);
# get all information in Author or Location groups
$info = $exifTool->GetInfo({Group2 => ['Author', 'Location']});
WriteInfo
Write meta information to a file. The specified source file is rewritten to the same-type destination file with new information as specified by previous calls to SetNewValue. The necessary segments and/or directories are created in the destination file as required to store the specified information. May be called repeatedly to write the same information to additional files without the need to call SetNewValue again.

ExifTool queues all new values that are assigned via calls to SetNewValue, then applies them to any number of files through one or more calls to WriteInfo. These queued values may be accessed through GetNewValue, and are completely separate from metadata extracted from files via ExtractInfo or ImageInfo and accessed through GetInfo or GetValue.

To be clear, it is NOT necessary to call ExtractInfo or ImageInfo before WriteInfo. WriteInfo changes only metadata specified by previous calls to SetNewValue.

Prototype	WriteInfo($$;$$)
Inputs	0) ExifTool object reference
1) Source file name, file reference, scalar reference, or undef to create a file from scratch. A reference to a File::RandomAccess object is also allowed as a source, but in this case the destination is not optional.
2) [optional] Destination file name, file reference, scalar reference to write to memory, or undef to overwrite the original file. May be '-' to write to stdout.
3) [optional] Destination file type. Ignored if a source is defined.
Returns	1 if file was written OK, 2 if file was written but no changes made, 0 on file write error.
The source file name may be undefined to create a file from scratch (currently only XMP, MIE, ICC, VRD, DR4, EXV and EXIF files can be created in this way -- see CanCreate for details). If undefined, the destination file type is required unless the type can be determined from the extension of the destination file name.

If a destination file name is given, the specified file must not exist because an existing destination file will not be overwritten. Any new values for FileName, Directory or HardLink are ignored when a destination file name is specified.

The destination file name may be undefined to overwrite the original file (make sure you have backups!). In this case, if a source file name is provided, a temporary file is created and renamed to replace the source file if no errors occurred while writing. Otherwise, if a source file reference or scalar reference is used, the image is first written to memory then copied back to replace the original if there were no errors.

On Mac OS systems, the file resource fork is preserved if this routine is called with a source file name.

Examples:

# add information to a source file, writing output to new file
my $result = $exifTool->WriteInfo($srcfile, $dstfile);
# create XMP data file from scratch
$exifTool->WriteInfo(undef, $dstfile, 'XMP');
# overwrite file (you do have backups, right?)
$exifTool->WriteInfo($srcfile);
# retrieve error and warning messages
$errorMessage = $exifTool->GetValue('Error');
$warningMessage = $exifTool->GetValue('Warning');
If an error code is returned, an Error tag is set and GetValue('Error') can be called to obtain the error description. A Warning tag may be set even if this routine is successful. Calling WriteInfo clears any pre-existing Error and Warning tags.

GetTagList
Get a sorted list of tags from the specified information hash or tag list.

Prototype	GetTagList($;$$$)
Inputs	0) ExifTool object reference
1) [optional] Reference to info hash or tag list
2) [optional] Sort order ('Input', 'File', 'Tag', 'Descr' or 'Group#')
3) [optional] Secondary sort order ('File', 'Tag' or 'Descr')
Returns	List of tag keys in specified order
Example:

@tags = $exifTool->GetTagList($info, 'Group0');
If the information hash or tag list reference is not provided, then the list of found tags from the last call to ImageInfo, ExtractInfo or GetInfo is used instead, and the result is the same as if GetFoundTags was called. If sort order is not specified, the sort order is taken from the current options settings.

GetFoundTags
Get list of found tags in specified sort order. The found tags are the tags for the information obtained from the most recent call to ImageInfo, ExtractInfo or GetInfo for this object.

Prototype	GetFoundTags($;$$)
Inputs	0) ExifTool object reference
1) [optional] Sort order ('Input', 'File', 'Tag', 'Descr' or 'Group#')
2) [optional] Secondary sort order ('File', 'Tag' or 'Descr')
Returns	List of tag keys in the specified order
Example:

my @tags = $exifTool->GetFoundTags('File');
GetRequestedTags
Get list of requested tags. These are the tags that were specified in the arguments of the most recent call to ImageInfo, ExtractInfo or GetInfo, including tags specified via a tag list reference. They are returned in the same order that they were specified. Shortcut tags are expanded in the list.

Prototype	GetRequestedTags($)
Inputs	0) ExifTool object reference
Returns	List of tag keys for requested tags (empty if no tags specifically requested)
Example:

my @requestedTags = $exifTool->GetRequestedTags();
GetValue
Get the value of a specified tag. The returned value is either the human-readable (PrintConv) value, the converted machine-readable (ValueConv) value, the original raw (Raw) value, or the original rational (Rational) value for rational formats. If the value type is not specified, the PrintConv value is returned if the PrintConv option is set, otherwise the ValueConv value is returned. The PrintConv values are the same as the values returned by ImageInfo and GetInfo in the tag/value hash unless the PrintConv option is disabled.

Tags which represent lists of multiple values (as may happen with 'Keywords' for example) are handled specially. In scalar context, the returned PrintConv value for these tags is either a string of values or a list reference (depending on the ListJoin option setting), and the ValueConv value is always a list reference. But in list context, GetValue always returns the list itself.

Note that GetValue requires a case-sensitive tag key as an argument. To retrieve tag information based on a case-insensitive tag name (with an optional group specifier), use GetInfo instead.

Prototype	GetValue($$;$)
Inputs	0) ExifTool object reference
1) Tag key, or case-sensitive tag name with optional group prefix(es)
2) [optional] Value type, 'PrintConv', 'ValueConv', 'Both', 'Raw', 'Bin' or 'Rational'
 
The default value type is 'PrintConv' if the PrintConv option is set, otherwise the default is 'ValueConv'. A value type of 'Both' returns both ValueConv and PrintConv values as a list. 'Raw' returns the raw decoded tag value. 'Bin' returns the original binary data for EXIF tags if the SaveBin option was set. 'Rational' returns the raw rational value as a string fraction for rational types, or undef for other types.
Returns	The value of the specified tag. If the tag represents a list of multiple values and the ListJoin option is enabled then PrintConv returns a string of values, otherwise a reference to the list is returned in scalar context. The list itself is returned in list context. (Unless 'Both' values are requested, in which case two list references are returned, regardless of context.) Values may also be scalar references to binary data, or hash references if the Struct option is set.
 
Note: It is possible for GetValue to return an undefined ValueConv or PrintConv value (or an empty list in list context) even if the tag exists, since it is possible for these conversions to yield undefined values. And the Rational value will be undefined for any non-rational tag. The Raw value should always exist if the tag exists.
Examples:

# PrintConv example
my $val = $exifTool->GetValue($tag);
if (ref $val eq 'SCALAR') {
    print "$tag = (unprintable value)\n";
} else {
    print "$tag = $val\n";
}
# ValueConv example
my $val = $exifTool->GetValue($tag, 'ValueConv');
if (ref $val eq 'ARRAY') {
    print "$tag is a list of values\n";
} elsif (ref $val eq 'SCALAR') {
    print "$tag represents binary data\n";
} else {
    print "$tag is a simple scalar\n";
}
# list example
my @keywords = $exifTool->GetValue('Keywords', 'ValueConv');
SetNewValue
Set the new value for a tag. The routine may be called multiple times to set the values of many tags before using WriteInfo to write the new values to an image. These values remain queued for writing to subsequent files until SetNewValue is called without arguments to reset the queued values.

For list-type tags (like Keywords), either call repeatedly with the same tag name for each value, or call with a reference to the list of values.

Prototype	SetNewValue($;$$%)
Inputs	0) ExifTool object reference
1) [optional] Tag key or tag name, or undef to clear all new values. The tag name may be prefixed one or more family 0, 1 or 2 group names with optional leading family numbers, separated by colons (eg. 'EXIF:Artist', 'XMP:Time:*'), which is equivalent to using a Group option argument. Also, a '#' may be appended to the tag name (eg. 'EXIF:Orientation#'), with the same effect as setting Type to 'ValueConv'. Wildcards ('*' and '?') may be used in the tag name to assign or delete multiple tags simultaneously. A tag name of '*' is special when deleting information, and will delete an entire group even if some individual tags in the group are not writable, but only if a single family 0 or 1 group name is specified (otherwise, the tags are deleted individually). Use GetDeleteGroups to get a list of deletable group names, and see the TagNames documentation for a complete list of ExifTool tag names.
2) [optional] New value for tag. Undefined to delete tag from file. May be a scalar, scalar reference, list reference to set a list of values, or hash reference for a structure. Integer values may be specified as a hexadecimal string (with a leading '0x'), and simple rational values may be specified in fractional form (eg. '4/10'). Structure tags may be specified either as a hash reference or a serialized string (see the last two examples below).
3-N) [optional] SetNewValue option/value pairs (see below).
Returns	Scalar context: The number of tags set, and errors are printed to STDERR.
List context: The number of tags set, and the error string (undefined if no error).
SetNewValue Options
Option	Description	Values	Default
AddValue	Add value to existing list in a file rather than overwriting the existing values	
0 =	Overwrite existing value(s)
1 =	Add to existing list, or warn for non-list tags
2 =	Add to existing list, or overwrite non-list tags
0
DelValue	Delete existing tag from a file if it has the specified value. For list-type tags this deletes a specified item from the list. For non-list tags this may be used to conditionally replace a tag by providing a new value in a separate call to SetNewValue (see examples below). For structured tags, the entire structure is deleted/replaced only if all of the specified fields match the existing structure.	0 or 1	0
EditGroup	Create tags in existing groups only. Don't create new group. Effectively removes the 'g' from the ExifTool WriteMode option for this tag only.	0 or 1	0
EditOnly	Edit tag only if it already exists. Don't create new tag. Effectively removes the 'c' from the ExifTool WriteMode option for this tag only.	0 or 1	0
Group	Specifies group name where tag should be written. This option is superseded by any group specified in the tag name. If not specified, tag is written to highest priority group as specified by SetNewGroups. Case is not significant	One or more family 0, 1 or 2 groups with optional leading family number, separated by colons	undef
NoFlat	Treat flattened tags as 'unsafe'	0 or 1	0
NoShortcut	Disables default behaviour of looking up tag in shortcuts if not found otherwise.	0 or 1	0
Protected	Allow unsafe and protected tags to be written	Bitmask of tag protection levels to write:
0x01 =	Write 'unsafe' tags (ie. tags not copied automatically via SetNewValuesFromFile)
0x02 =	Write 'protected' tags (internal use only)
0
ProtectSaved	Avoid setting new values which were saved after the Nth call to SaveNewValues. Has no effect on unsaved values, or values saved before the Nth call.	N	undef
Replace	Replace previous new values for this tag (ie. replace the values set in previous calls to SetNewValue). This option is most commonly used to replace previously-set new values for list-type tags.	
0 =	Set new value normally (adds to new values for list-type tags)
1 =	Reset any previous new values before setting new value
2 =	Reset previous new values only (new value argument is ignored)
0
Shift	Shift the tag by the specified value. Currently only date/time tags and tags with numerical values may be shifted. Value is added if Shift is 1, or subtracted if Shift is -1. See Image::ExifTool::Shift.pl for details time shift formats.	
undef = No shift
0 =	Shift if shiftable:
Positive if AddValue set, or
Negative if DelValue set and
tag is date/time
1 =	Positive shift
-1 =	Negative shift
undef
Type	The type of value being set	PrintConv, ValueConv or Raw (default depends on PrintConv Option)	PrintConv or ValueConv
Examples:

# set a new value for a tag (errors go to STDERR)
$success = $exifTool->SetNewValue($tag, $value);
# set a new value and capture any error message
($success, $errStr) = $exifTool->SetNewValue($tag, $value);
# delete information for specified tag if it exists in image
# (also resets AddValue and DelValue options for this tag)
$exifTool->SetNewValue($tag);
# reset all values from previous calls to SetNewValue()
$exifTool->SetNewValue();
# delete a specific keyword
$exifTool->SetNewValue('Keywords', $word, DelValue => 1);
# set keywords (a list-type tag) with two new values
$exifTool->SetNewValue(Keywords => 'word1');
$exifTool->SetNewValue(Keywords => 'word2');
# equivalent, but set both in one call using an array reference
$exifTool->SetNewValue(Keywords => ['word1','word2']);
# add a keyword without replacing existing keywords in the file
$exifTool->SetNewValue(Keywords => $word, AddValue => 1);
# conditionally add or replace a tag if it didn't exist before
# or had a specified value ("old value")
$exifTool->SetNewValue(Description => '', DelValue => 1);
$exifTool->SetNewValue(Description => 'old value', DelValue => 1);
$exifTool->SetNewValue(Description => 'new value');
# set a tag in a specific group
$exifTool->SetNewValue(Headline => $val, Group => 'XMP');
$exifTool->SetNewValue('XMP:Headline' => $val);  # (equivalent)
# shift original date/time back by 2.5 hours
$exifTool->SetNewValue(DateTimeOriginal => '2:30', Shift => -1);
# write a tag only if it had a specific value
# (the order of the following calls is not significant)
$exifTool->SetNewValue(Title => $oldVal, DelValue => 1);
$exifTool->SetNewValue(Title => $newVal);
# write tag by numerical value
$exifTool->SetNewValue(Orientation => 6, Type => 'ValueConv');
$exifTool->SetNewValue('Orientation#' => 6);  # (equivalent)
# delete all but EXIF tags
$exifTool->SetNewValue('*');  # delete all...
$exifTool->SetNewValue('EXIF:*', undef, Replace => 2); # ...but EXIF
# write structured information as a HASH reference
$exifTool->SetNewValue('XMP:Flash' => { mode=>'on', fired=>'true', return=>'not' });
# écrire des informations structurées sous forme de chaîne sérialisée 
$exifTool-> SetNewValue ('XMP:Flash' => '{mode=on,fired=true,return=not}');
(voir struct.html pour une description de la technique de sérialisation de structure)
Remarques :

Lors de la suppression de groupes de balises, l'option Remplacer permet d'exclure des groupes spécifiques d'une suppression massive. Cependant, cette technique ne permet pas d'exclure des balises individuelles d'une suppression groupée (sauf si un groupe de la famille 2 a été spécifié lors de la suppression). Utilisez plutôt SetNewValuesFromFile pour récupérer les valeurs de chaque balise après la suppression d'un groupe.

Lors de la suppression de toutes les balises d'une image JPEG, les informations « Adobe » APP14 ne sont pas supprimées par défaut, car cela pourrait affecter l'apparence de l'image. Cependant, ces informations peuvent être supprimées en les spécifiant explicitement, soit par groupe (avec «Adobe:* »), soit par bloc (avec «Adobe »).

Obtenir une nouvelle valeur
Obtenir la nouvelle valeur brute d'une balise. Il s'agit de la valeur définie par SetNewValue et mise en file d'attente pour écriture dans le fichier. Les balises de type liste peuvent renvoyer plusieurs valeurs dans un contexte de liste.

Prototype	Obtenir une nouvelle valeur ($$)
Entrées	0) Référence d'objet ExifTool
1) Nom de balise (sensible à la casse, peut être préfixé par les noms de groupe de la famille 0, 1 ou 7, séparés par des deux-points)
Retours	Liste des nouvelles valeurs de balises brutes, ou première valeur de la liste lorsqu'elle est appelée dans un contexte scalaire. La liste peut être vide si la balise n'est pas en cours d'écriture ou si elle est en cours de suppression (par exemple, si SetNewValue a été appelé sans valeur).
Exemples :

mon $rawVal = $exifTool-> GetNewValue ($tag);
mon @rawVals = $exifTool-> GetNewValue ($tag);
Remarques :

L'option API NoDups s'applique lorsque cette routine est appelée et supprime les éléments en double des valeurs renvoyées pour les balises de type Liste.

Définir de nouvelles valeurs à partir du fichier
Une routine très puissante qui définit de nouvelles valeurs pour les balises à partir des informations trouvées dans un fichier spécifié.

Prototype	Définir de nouvelles valeurs à partir du fichier ($$;@)
Entrées	0) Référence d'objet ExifTool
1) Nom de fichier, référence de fichier ou référence scalaire
2-N) [ facultatif ] Liste des noms de balises à définir ou références de hachage d'options. Toutes les balises accessibles en écriture sont définies si aucune n'est spécifiée. Les noms de balises ne sont pas sensibles à la casse et peuvent être préfixés par un ou plusieurs noms de groupe de famille 0, 1, 2 ou 7 avec des numéros de famille facultatifs au début, séparés par deux points (par exemple, ' exif:iso'). Un ' -' au début indique les balises à exclure (par exemple, ' -comment'), ou un ' #' à la fin entraîne la copie de la valeur ValueConv (identique à la définition de l'option Type sur 'ValueConv' pour cette balise uniquement). Un ' +' au début définit l'option Remplacer sur 0 pour chaque balise (voir Options ci-dessous). Des caractères génériques (' *' et ' ?') peuvent être utilisés dans le nom de balise. Un nom de balise de ' *' est généralement utilisé lorsqu'un groupe est spécifié pour copier toutes les balises du groupe (par exemple, ' XMP:*').
 
Une fonctionnalité spéciale permet de spécifier des noms de balises de la forme «DSTTAG<SRCTAG » (ou « ») pour copier des informations vers une balise portant un nom différent ou un groupe spécifié. « » et « » peuvent contenir des caractères génériques et/ou être préfixés par un nom de groupe (par exemple, « » ou « »), et/ou suffixés par un « » pour désactiver la conversion d'impression. Les balises copiées peuvent également être ajoutées ou supprimées d'une liste avec des arguments de la forme « » ou « ». Les balises étant évaluées dans l'ordre, les exclusions ne s'appliquent qu'aux balises incluses en amont dans la liste. Une extension de cette fonctionnalité permet de définir la valeur de la balise à partir d'une chaîne contenant des noms de balises précédés du symbole « » (par exemple, « »). Des accolades « » peuvent être utilisées autour d'un nom de balise pour le séparer du texte suivant, et un « » est utilisé pour représenter un symbole « ». Le comportement des balises manquantes dans les expressions est défini par l' option MissingTagValue . La valeur de la balise peut être modifiée en modifiant la variable d'entrée par défaut ( ) dans une expression Perl placée entre accolades et après un point-virgule suivant le nom de la balise (voir le dernier exemple ci-dessous). Un peut être ajouté après le nom de la balise (avant le point-virgule) pour que l'expression agisse sur des éléments de liste individuels plutôt que sur la chaîne concaténée pour les balises de type liste. L'expression a accès à l'API ExifTool complète via l'objet ExifTool courant ( ) et la clé de balise ( ). Les accolades dans l'expression doivent être équilibrées. Plusieurs références de hachage d'options peuvent être passées pour définir des options différentes pour différentes balises. Les options s'appliquent aux balises suivantes dans la liste d'arguments. SRCTAG>DSTTAGSRCTAGDSTTAGfileModifyDate<modifyDatexmp:*<*#DSTTAG+<SRCTAGDSTTAG-<SRCTAG$Comment<the file is $filename{}$$$$_@$self$tag
 
Retours	Un hachage d'informations correctement défini. Peut inclure des entrées d'avertissement ou d'erreur en cas de problème de lecture du fichier d'entrée.
Par défaut, cette routine commute les informations entre les balises de même nom appartenant à des groupes différents, permettant ainsi la traduction des informations entre des images de formats différents. Ce comportement peut être modifié en spécifiant un nom de groupe pour les balises extraites (même si «* » est utilisé comme nom de groupe). Dans ce cas, les informations sont écrites dans le groupe d'origine, sauf si elles sont redirigées vers un autre groupe. Lorsque «* » est utilisé comme nom de groupe, par défaut, le groupe de la famille 1 de la balise d'origine est conservé, mais une autre famille peut être spécifiée avec un numéro de famille initial. (Par exemple, spécifier «*:* » copie toutes les informations tout en préservant les groupes de la famille 1 d'origine, tandis que «0*:* » préserve le groupe de la famille 0.)

Options de définition de nouvelles valeurs à partir du fichier :

Les options sont les mêmes que pour SetNewValue et sont transmises directement à SetNewValue en interne, à quelques exceptions près :

L'option Remplacer est définie par défaut sur 1 au lieu de 0 comme avec SetNewValue , cependant l'argument du nom de la balise peut être préfixé par '+' pour définir l'option Remplacer sur 0 pour cet argument uniquement.
L'option AddValue ou DelValue est définie pour les balises individuelles si '+>' ou '->' (ou '+<' ou '-<') sont utilisés.
L'option Groupe est définie pour les balises où un nom de groupe est donné.
L'indicateur Protégé est défini sur 1 pour les balises spécifiées individuellement.
L'option Type s'applique également aux balises extraites.
Exemples :

# définir de nouvelles valeurs à partir de toutes les informations d'un fichier... 
my $info = $exifTool-> SetNewValuesFromFile ($srcFile);
 # ...puis écrire ces valeurs dans une autre image 
my $result = $exifTool-> WriteInfo ($file2, $outFile);
# définir toutes les nouvelles valeurs, en préservant les groupes d'origine 
$exifTool-> SetNewValuesFromFile ($srcFile, '*:*');
# définir des informations spécifiques 
$exifTool-> SetNewValuesFromFile ($srcFile, $tag1, $tag2...);
# définir une nouvelle valeur à partir d'une balise différente dans un groupe spécifique 
$exifTool-> SetNewValuesFromFile ($src, 'XMP-dc:Subject<IPTC:Keywords');
# ajouter tous les mots-clés IPTC à la liste des sujets XMP 
$exifTool-> SetNewValuesFromFile ($src, 'XMP-dc:Subject+<IPTC:Keywords');
# définir une nouvelle valeur à partir d'une chaîne impliquant d'autres balises 
$exifTool-> SetNewValuesFromFile ($file,
    'Commentaire<ISO=$ISO Aperture=$aperture Exposure=$shutterSpeed');
# définir la liste des mots-clés à partir des valeurs de plusieurs balises 
$exifTool-> SetNewValuesFromFile ($file, { Replace => 0 },
    'mots-clés<xmp:sujet', 'mots-clés<nom de fichier');
# copier toutes les informations EXIF, en préservant l'IFD d'origine
# (sans les balises '*.*<' seraient copiées dans l'IFD EXIF ​​préféré) 
$exifTool-> SetNewValuesFromFile ($file, '*:*<EXIF:*');
# copier toutes les balises dont les noms commencent par « gps » (remarque : ceci est
# différent de "gps:*" car il copiera également les balises GPS XMP) 
$exifTool-> SetNewValuesFromFile ($file, 'gps*');
# définir le nom de fichier à partir du modèle, en traduisant les caractères douteux en soulignements 
$exifTool-> SetNewValuesFromFile ($file, 'filename<${model;tr(/\\\\?*:|"<>)(_)}.jpg');
Remarques :

L'option PrintConv s'applique à cette routine, mais elle doit normalement être laissée activée pour assurer un transfert d'informations plus fiable entre les groupes.

Si une image d'aperçu existe, elle n'est pas copiée. Elle doit être transférée séparément, si nécessaire, via un appel distinct à WriteInfo.

Lors de la simple copie de toutes les informations entre des fichiers du même type, il est généralement souhaitable de conserver les groupes d'origine en spécifiant «*:* » pour les balises à définir.

L' option Duplicatas est toujours en vigueur pour les balises extraites du fichier source à l'aide de cette routine.

L' option Struct est activée par défaut pour les balises extraites par cette routine. Cela permet de préserver la hiérarchie des structures complexes lors de la copie. Cependant, l'option Struct peut être définie sur 0 pour contourner ce comportement et copier les balises sous forme de balises aplaties.

Compter les nouvelles valeurs
Renvoie le nombre total de nouvelles valeurs définies.

Prototype	CountNewValues($)
Entrées	0) Référence d'objet ExifTool
Retours	Dans un contexte scalaire, renvoie le nombre total de balises avec de nouvelles valeurs définies. Dans un contexte de liste, renvoie également le nombre de pseudo-balises définies. Les pseudo-balises sont des balises telles que FileName et FileModifyDate, qui ne sont pas contenues dans le fichier et peuvent être modifiées sans réécriture.
Exemples :

mon $numSet = $exifTool-> CountNewValues ​​();
mon ($numSet, $numPseudo) = $exifTool-> CountNewValues ​​();
Enregistrer de nouvelles valeurs
Enregistrez l'état des nouvelles valeurs pour qu'elles soient restaurées ultérieurement par RestoreNewValues ​​.

Prototype	EnregistrerNouvellesValeurs($)
Entrées	0) Référence d'objet ExifTool
Retours	Compte du nombre de fois où cette routine a été appelée (N) depuis la dernière fois que les nouvelles valeurs ont été réinitialisées.
Exemple:

$exifTool->SaveNewValues();         # save state of new values
$exifTool->SetNewValue(ISO => 100); # set new value for ISO
$exifTool->WriteInfo($src, $dst1);  # write ISO plus any previous new values
$exifTool->RestoreNewValues();      # restore previous new values
$exifTool->WriteInfo($src, $dst2);  # write previous new values only
RestoreNewValues
Restore new values to the settings that existed when SaveNewValues was last called. May be called repeatedly after a single call to SaveNewValues. See SaveNewValues above for an example.

Prototype	RestoreNewValues($)
Inputs	0) ExifTool object reference
SetAlternateFile
Specify alternate file from which to read metadata. Tags from the alternate file are available after ExtractInfo is called or during a call to SetNewValuesFromFile by using a family 8 group name (eg. 'File1' in the example below).

Prototype	SetAlternateFile($$$)
Inputs	0) ExifTool object reference
1) Case insensitive family 8 group name ('File1', 'File2' or 'File3', etc)
2) Name of alternate input file, or undef to reset
Returns	1 on success, or 0 if the group name is invalid.
Example:

$exifTool->SetAlternateFile(File1 => 'images/test1.jpg');
SetFileModifyDate
Write the filesystem modification or creation time from the new value of the FileModifyDate or FileCreateDate tag.

Prototype	SetFileModifyDate($$;$$)
Inputs	0) ExifTool object reference
1) File name
2) [optional] Base time if applying shift (in days before $^T)
3) [optional] Tag to write: 'FileModifyDate' (default), or 'FileCreateDate'
Returns	1 if the time was changed, 0 if nothing was done, or -1 if there was an error setting the time.
Example:

$exifTool->SetNewValue(FileModifyDate => '2000:01:02 03:04:05', Protected => 1);
my $result = $exifTool->SetFileModifyDate($file);
Notes:

Equivalent to, but more efficient than calling WriteInfo when only the FileModifyDate or FileCreateDate tag has been set. If a timezone is not specified, local time is assumed. When shifting, the time of the original file is used unless the optional base time is specified.

The ability to write FileCreateDate is currently restricted to Windows systems only.

SetFileName
Set the file name and directory, or create a hard link to the file. If not specified, the new file name is derived from the new values of the FileName and Directory tags, or from the HardLink or SymLink tag if creating a link. If the FileName tag contains a '/', then the file is renamed into a new directory. If FileName ends with '/', then it is taken as a directory name and the file is moved into the new directory. The new value for the Directory tag takes precedence over any directory specified in FileName.

Prototype	SetFileName($$;$$)
Inputs	0) ExifTool object reference
1) Current file name
2) [optional] New file name
3) [optional] 'HardLink' or 'SymLink' to create a hard or symbolic link instead of renaming the file, or 'Test' to test renaming feature by printing the old and new names instead of changing anything.
Returns	1 on success, 0 if nothing was done, or -1 if there was an error renaming the file or creating the link.
Examples:

my $result = $exifTool->SetFileName($file);
my $result = $exifTool->SetFileName($file, $newName);
Notes:

Will not overwrite existing files. New directories are created as necessary. If the file is successfully renamed, the new file name may be accessed via $$exifTool{NewName}.

SetNewGroups
Set the order of the preferred groups when adding new information. In subsequent calls to SetNewValue, new information will be created in the first valid group of this list. This has an impact only if the group is not specified when calling SetNewValue, and if the tag name exists in more than one group. The default order is EXIF, IPTC, XMP, MakerNotes, QuickTime, Photoshop, ICC_Profile, CanonVRD, Adobe. Any family 0 group name may be used. Case is not significant.

Prototype	SetNewGroups($;@)
Inputs	0) ExifTool object reference
1-N) Groups in order of priority. If no groups are specified, the priorities are reset to the defaults.
Example:

$exifTool->SetNewGroups('XMP','EXIF','IPTC');
GetNewGroups
Get current group priority list.

Prototype	GetNewGroups($)
Inputs	0) ExifTool object reference
Returns	List of group names in order of write priority. Highest priority first.
Example:

@groups = $exifTool->GetNewGroups();
GetTagID
Get the ID for the specified tag. The ID is the IFD tag number in EXIF information, the property name in XMP information, or the data offset in a binary data block. For some tags, such as Composite tags where there is no ID, an empty string is returned. In list context, also returns a language code for the tag if available and different from the default language (eg. with alternate language entries for XMP "lang-alt" tags).

Prototype	GetTagID($$)
Inputs	0) ExifTool object reference
1) Tag key
Returns	In scalar context, returns the tag ID or '' if there is no ID for this tag.
In list context, returns the tag ID (or '') and the language code (or undef).
Examples:

my $id = $exifTool->GetTagID($tag);
my ($id, $lang) = $exifTool->GetTagID($tag);
GetDescription
Get description for specified tag. This function will always return a defined value. In the case where the description doesn't exist, one is generated from the tag name.

Prototype	GetDescription($$)
Inputs	0) ExifTool object reference
1) Tag key
Returns	Tag description
GetGroup
Get group name(s) for a specified tag.

Prototype	GetGroup($$;$)
Inputs	0) ExifTool object reference
1) Tag key
2) [optional] Group family number, or string of numbers separated by colons
Returns	Group name (or '' if tag has no group). If no group family is specified, returns the name of group in family 0 when called in scalar context, or the names of groups for all families in list context. Returns a string of group names separated by colons if the input group family contains a colon. The string is simplified to remove a leading 'Main:' and adjacent identical group names unless the family string begins with a colon.
The following families of groups are available:

Family	Description	Examples
0	Information Type	EXIF, XMP, IPTC
1	Specific Location	IFD0, XMP-dc
2	Category	Author, Time
3	Document Number	Main, Doc1, Doc3-2
4	Instance Number	Copy1, Copy2, Copy3...
5	Metadata Path	eg. JPEG-APP1-IFD0-ExifIFD
6	EXIF/TIFF Format	int8u, int32u, undef, string
7	Tag ID	ID-271, ID-rights, ID-a9aut
8	Alternate File	File1, File2, File3...
Families 0 and 1 are based on the file structure, and are similar except that family 1 is more specific and sub-divides some groups to give more detail about the specific location where the information was found. For example, the EXIF group is split up based on the specific IFD (Image File Directory), the MakerNotes group is divided into groups for each manufacturer, and the XMP group is separated based on the XMP namespace prefix. Note that only common XMP namespaces are listed in the GetAllGroups documentation, but additional namespaces may be present in some XMP data. Also note that the 'XMP-xmp...' group names may appear in the older form 'XMP-xap...' since these names evolved as the XMP standard was developed. The ICC_Profile group is broken down to give information about the specific ICC_Profile tag from which multiple values were extracted. As well, information extracted from the ICC_Profile header is separated into the ICC-header group.

Family 2 classifies information based on the logical category to which the information refers.

Family 3 gives the document number for tags extracted from embedded documents, or 'Main' for tags from the main document. (See the ExtractEmbedded option for extracting tags from embedded documents.) Nested sub-documents (if they exist) are indicated by numbers separated with dashes in the group name, to an arbitrary depth. (eg. 'Doc2-3-1' is the 1st sub-sub-document of the 3rd sub-document of the 2nd embedded document of the main file.) Document numbers are also used to differentiate samples for timed metadata in videos.

Family 4 provides a method for differentiating tags when multiple tags exist with the same name in the same location. The primary instance of a tag (the tag extracted when the Duplicates option is disabled and no group is specified) has no family 4 group name, but additional instances have family 4 group names of 'Copy1', 'Copy2', 'Copy3', etc. For convenience, the primary tag may also be accessed using a group name of 'Copy0'.

Family 5 and gives the complete path for the metadata in the file. Generated only if the SavePath option is used when extracting.

Family 6 is currently used only for EXIF/TIFF metadata, and gives the format type of the extracted value. Generated only if the SaveFormat option is used when extracting.

Family 7 is used for tag ID's. The group names are the actual tag ID's with a leading "ID-" string. Non-numerical tag ID's have characters other than [-_A-Za-z0-9] converted to hex. Numerical tag ID's are returned in hex if the HexTagIDs option is set, otherwise decimal is used. When specifying a family 7 group name, numerical ID's may be in hex (with leading "0x") or decimal, and non-numerical ID's may or may not have characters other than [-_A-Za-z0-9] converted to hex. Note that unlike other group names, the tag ID's in family 7 group names are case sensitive (but the leading "ID-" is not).

Family 8 is used to specify tags loaded from alternate input files defined in calls to SetAlternateFile.

See GetAllGroups for lists of group names.

Examples:

# return family 0 group name (eg. 'EXIF')
$group = $exifTool->GetGroup($tag, 0);
# return all groups (eg. qw{EXIF IFD0 Author Main})
@groups = $exifTool->GetGroup($tag);
# return groups as a string (eg. 'Main:IFD0:Author')
$group = $exifTool->GetGroup($tag, ':3:1:2');
# return groups as a simplified string (eg. 'IFD0:Author')
$group = $exifTool->GetGroup($tag, '3:1:2');
GetGroups
Get list of group names for all tags in specified information hash.

Prototype	GetGroups($;$$)
Inputs	0) ExifTool object reference
1) [optional] Information hash reference (default is all extracted info)
2) [optional] Group family number (default 0)
Returns	List of group names in alphabetical order. If information hash is not specified, the group names are returned for all extracted information. See GetAllGroups for a list of groups in each family.
Examples:

my @groups = $exifTool->GetGroups($info, $family);
Example of one way to print information organized by group
my $exifTool = Image::ExifTool->new;
$exifTool->ExtractInfo('t/images/ExifTool.jpg');

my $family = 1;
my @groups = $exifTool->GetGroups($family);
my $group;
foreach $group (@groups) {
    print "---- $group ----\n";
    my $info = $exifTool->GetInfo({"Group$family" => $group});
    foreach ($exifTool->GetTagList($info)) {
        print "$_ : $$info{$_}\n";
    }
}
BuildCompositeTags
Builds composite tags from required tags. The composite tags are convenience tags which are derived from the values of other tags. This routine is called automatically by ImageInfo if the Composite option is set.

Prototype	BuildCompositeTags($)
Inputs	0) ExifTool object reference
Returns	(none)
Notes:

Tag values are calculated in alphabetical order unless a tag Require's or Desire's another composite tag, in which case the calculation is deferred until after the other tag is calculated.
Composite tags may need to read data from the image for their value to be determined, and for these BuildCompositeTags must be called while the image is available. This is only a problem if ImageInfo is called with a filename (as opposed to a file reference or scalar reference) since in this case the file is closed before ImageInfo returns. Here the Composite option may be used so that BuildCompositeTags is called from within ImageInfo, before the file is closed.
The following functions access only static data and are not called with an ExifTool object
The names of all the following functions, plus ImageInfo, may be imported into the current namespace with the "Public" tag. When this is done, the functions can be accessed without the need to prefix the function name with "Image::ExifTool::". For example:

use Image::ExifTool ':Public';
$tagName = GetTagName($tag);
AvailableOptions
Get a list of available API options. (See Options method for option details.)

Prototype	AvailableOptions()
Inputs	(none)
Returns	Reference to list of available options. Each entry in the list is a list reference with 3 items: 0=Option name, 1=Default value, 2=Description, 3=flag set if option is undocumented
Example:

my $opts = Image::ExifTool::AvailableOptions();
foreach (@$opts) {
    my ($optionName, $defaultValue, $description) = @$_;
    ...
}
GetTagName
Get name of tag from tag identifier. This is a convenience function that strips the embedded instance number, if it exists, from the tag key.

Prototype	GetTagName($)
Inputs	0) Tag key
Returns	Tag name
Example:

$tagName = Image::ExifTool::GetTagName($tag);
GetShortcuts
Get list of tag shortcut names.

Prototype	GetShortcuts()
Inputs	(none)
Returns	List of shortcuts
GetAllTags
Get list of all available tag names.

Prototype	GetAllTags(;$)
Inputs	0) [optional] Group name, or string of group names separated by colons
Returns	A list of all available tags in alphabetical order, or all tags in a specified group or intersection of groups. The group name is case insensitive, and any group in families 0-2 may be used except for EXIF family 1 groups (ie. the specific IFD).
GetWritableTags
Get list of all writable tag names.

Prototype	GetWritableTags(;$)
Inputs	0) [optional] Group name, or string of group names separated by colons
Returns	A list of all writable tags in alphabetical order. These are the tags for which values may be set through SetNewValue. If a group name is given, returns only writable tags in specified group(s). The group name is case insensitive, and any group in families 0-2 may be used except for EXIF family 1 groups (ie. the specific IFD).
GetAllGroups
Get list of all group names in specified family.

Prototype	GetAllGroups($)
Inputs	0) Group family number (0-7)
Returns	A list of all groups in the specified family in alphabetical order
Here is a complete list of groups for each family:

Family	Group Names
0 (Information Type)	AAC, AFCP, AIFF, APE, APP0, APP1, APP10, APP11, APP12, APP13, APP14, APP15, APP2, APP3, APP4, APP5, APP6, APP7, APP8, APP9, ASF, Audible, Canon, CanonVRD, Composite, DICOM, DjVu, DNG, Ducky, DV, EXE, EXIF, ExifTool, File, FITS, FLAC, Flash, FlashPix, FLIR, Font, FotoStation, GeoTiff, GIF, GIMP, GM, GoPro, H264, HTML, ICC_Profile, ID3, IPTC, ISO, ITC, JFIF, JPEG, Jpeg2000, JSON, JUMBF, Leaf, LNK, Lytro, M2TS, MakerNotes, Matroska, Meta, MIE, MIFF, MISB, MNG, MOI, MPC, MPEG, MPF, MXF, Ogg, OpenEXR, Opus, Palm, PanasonicRaw, Parrot, PDF, PhotoCD, PhotoMechanic, Photoshop, PICT, PLIST, PNG, PostScript, PrintIM, Protobuf, PSP, QuickTime, Radiance, RAF, Rawzor, Real, Red, RIFF, RSRC, RTF, SigmaRaw, Sony, Stim, SVG, Theora, Torrent, Trailer, VCard, Vorbis, WTV, XML, XMP, ZIP
1 (Specific Location)	AAC, AC3, Adobe, AdobeCM, AdobeDNG, AFCP, AIFF, APE, APP10, APP2, Apple, ASF, Audible, AudioItemList, AudioKeys, AudioUserData, AVI1, CameraIFD, Canon, CanonCustom, CanonDR4, CanonRaw, CanonVRD, Casio, CBOR, Chapter#, CIFF, Composite, DICOM, DJI, DjVu, DjVu-Meta, DNG, Ducky, DV, EPPIM, EXE, EXIF, ExifIFD, ExifTool, File, FITS, FLAC, Flash, FlashPix, FLIR, Font, FotoStation, FujiFilm, FujiIFD, Garmin, GE, GeoTiff, GIF, GIMP, GlobParamIFD, GM, Google, GoPro, GPS, GraphConv, GSpherical, H264, HP, HTC, HTML, HTML-dc, HTML-ncc, HTML-office, HTML-prod, HTML-vw96, HTTP-equiv, ICC-chrm, ICC-cicp, ICC-clrt, ICC-header, ICC-meas, ICC-meta, ICC-view, ICC_Profile, ICC_Profile#, ID3, ID3v1, ID3v1_Enh, ID3v2_2, ID3v2_3, ID3v2_4, IFD0, IFD1, InfiRay, Insta360, InteropIFD, IPTC, IPTC#, ISO, ITC, ItemList, iTunes, JFIF, JFXX, JPEG, JPEG-HDR, Jpeg2000, JPS, JSON, JUMBF, JVC, KDC_IFD, Keys, Kodak, KodakBordersIFD, KodakEffectsIFD, KodakIFD, KyoceraRaw, Leaf, LeafSubIFD, Leica, LNK, Lyrics3, Lytro, M-RAW, M2TS, MAC, MacOS, MakerNotes, MakerUnknown, Matroska, MediaJukebox, Meta, MetaIFD, Microsoft, MIE-Audio, MIE-Camera, MIE-Canon, MIE-Doc, MIE-Extender, MIE-Flash, MIE-Geo, MIE-GPS, MIE-Image, MIE-Lens, MIE-Main, MIE-MakerNotes, MIE-Meta, MIE-Orient, MIE-Preview, MIE-Thumbnail, MIE-Unknown, MIE-UTM, MIE-Video, MIFF, Minolta, MinoltaRaw, MISB, MNG, MOBI, MOI, Motorola, MPC, MPEG, MPF0, MPImage, MS-DOC, MXF, Nextbase, Nikon, NikonCapture, NikonCustom, NikonScan, NikonSettings, NineEdits, Nintendo, NITF, Ocad, Ogg, Olympus, OnePlus, OpenEXR, Opus, Palm, Panasonic, PanasonicRaw, Parrot, PDF, Pentax, PhaseOne, PhotoCD, PhotoMechanic, Photoshop, PICT, PictureInfo, PNG, PNG-cICP, PNG-pHYs, PostScript, PreviewIFD, PrintIM, ProfileIFD, PSP, Qualcomm, QuickTime, Radiance, RAF, RAF2, Rawzor, Real, Real-CONT, Real-MDPR, Real-PROP, Real-RA3, Real-RA4, Real-RA5, Real-RJMD, Reconyx, Red, Ricoh, RIFF, RMETA, RSRC, RTF, Samsung, Sanyo, Scalado, SEAL, Sigma, SigmaRaw, Sony, SonyIDC, SPIFF, SR2, SR2DataIFD, SR2SubIFD, SRF#, Stim, SubIFD, SVG, System, Theora, Torrent, Track#, Track#ItemList, Track#Keys, Track#UserData, UserData, VCalendar, VCard, Version0, VideoItemList, VideoKeys, VideoUserData, Vivo, VNote, Vorbis, WTV, XML, XMP, XMP-aas, XMP-acdsee, XMP-acdsee-rs, XMP-album, XMP-apdi, XMP-apple-fi, XMP-ast, XMP-aux, XMP-cc, XMP-cell, XMP-crd, XMP-creatorAtom, XMP-crs, XMP-dc, XMP-Device, XMP-dex, XMP-DICOM, XMP-digiKam, XMP-drone-dji, XMP-dwc, XMP-et, XMP-exif, XMP-exifEX, XMP-expressionmedia, XMP-extensis, XMP-fpv, XMP-GAudio, XMP-GCamera, XMP-GContainer, XMP-GCreations, XMP-GDepth, XMP-getty, XMP-GFocus, XMP-GImage, XMP-GPano, XMP-GSpherical, XMP-hdr, XMP-HDRGainMap, XMP-hdrgm, XMP-ics, XMP-iptcCore, XMP-iptcExt, XMP-LImage, XMP-lr, XMP-mediapro, XMP-microsoft, XMP-MP, XMP-MP1, XMP-mwg-coll, XMP-mwg-kw, XMP-mwg-rs, XMP-nine, XMP-panorama, XMP-pdf, XMP-pdfx, XMP-photomech, XMP-photoshop, XMP-PixelLive, XMP-plus, XMP-pmi, XMP-prism, XMP-prl, XMP-prm, XMP-pur, XMP-rdf, XMP-sdc, XMP-seal, XMP-swf, XMP-tiff, XMP-x, XMP-xmp, XMP-xmpBJ, XMP-xmpDM, XMP-xmpDSA, XMP-xmpMM, XMP-xmpNote, XMP-xmpPLUS, XMP-xmpRights, XMP-xmpTPg, ZIP
2 (Category)	Audio, Author, Camera, Device, Document, ExifTool, Image, Location, Other, Preview, Printing, Time, Unknown, Video
3 (Document Number)	Doc#, Main
4 (Instance Number)	Copy#
5 (Metadata Path)	eg. JPEG-APP1-IFD0-ExifIFD
6 (EXIF/TIFF Format)	int8u, string, int16u, int32u, rational64u, int8s, undef, int16s, int32s, rational64s, float, double, ifd, unicode, complex, int64u, int64s, ifd64
7 (Tag ID)	ID-xxx (Where xxx is the tag ID. Numerical ID's are returned in hex with a leading "0x" if the HexTagIDs option is set, or decimal otherwise. Characters in non-numerical ID's which are not valid in a group name are returned as 2 hex digits.)
8 (Alternate File)	File#
Note: This function may also be called as an ExifTool member function to allow the HexTagIDs option to be set when retrieving family 7 group names.

Example:

@groupList = Image::ExifTool::GetAllGroups($family);
GetDeleteGroups
Get list of all deletable group names.

Prototype	GetDelGroups()
Inputs	None
Returns	A list of deletable group names in alphabetical order.
Below is a current list of deletable group names.

Adobe, AFCP, APP0, APP1, APP10, APP11, APP12, APP13, APP14, APP15, APP2, APP3, APP4, APP5, APP6, APP7, APP8, APP9, AROT, Audio, Author, Camera, CanonVRD, CIFF, Document, Ducky, EXIF, ExifIFD, ExifTool, File, FlashPix, FotoStation, GlobParamIFD, GPS, ICC_Profile, IFD0, IFD1, Image, Insta360, InteropIFD, IPTC, ItemList, JFIF, Jpeg2000, Keys, Location, MakerNotes, Meta, MetaIFD, Microsoft, MIE, MPF, NikonCapture, Other, PDF, PDF-update, PhotoMechanic, Photoshop, PNG, PNG-pHYs, Preview, PrintIM, Printing, QuickTime, RMETA, RSRC, SubIFD, Time, Trailer, UserData, Video, XML, XML-*, XMP, XMP-*
To schedule a group for deletion, call SetNewValue with a tag name like 'EXIF:*' and an undefined tag value.

Deleting a family 0 or 1 group will delete the entire corresponding block of metadata, but deleting a family 2 group (eg. Audio, Author, Camera, etc.) deletes the individual tags belonging to that category.

The 'Trailer' group allows all trailers in JPEG and TIFF-format images to be deleted at once, including unknown trailers. Note that the JPEG "APP" groups are special, and are used only to delete application segments which are not associated with another deletable group. For example, deleting 'APP14:*' will delete other APP14 segments, but not the APP14 "Adobe" segment.

Example:

my @delGroups = Image::ExifTool::GetDelGroups();
GetFileType
Get type of file given file name.

Prototype	GetFileType(;$$)
Inputs	0) [optional] File name or extension
1) [optional] Flag to return a description instead of a type. Default is undef. Set to 0 to also return return types of recognized but unsupported files (otherwise undef is returned for unsupported files), or 1 to return file descriptions.
Returns	A string, based on the file extension, which indicates the basic format of the file. Note that some files may be based on other formats (like many RAW image formats are based on TIFF). In list context, may return more than one file type if the file may be based on different formats. Returns undef if files with this extension are not yet supported by ExifTool. Returns a list of extensions for all supported file types if no input extension is specified (or all recognized file types if the description flag is set to 0). Returns a more detailed description of the specific file format when the description flag is set.
Examples:

my $type = Image::ExifTool::GetFileType($filename);
my $desc = Image::ExifTool::GetFileType($filename, 1);
CanWrite
Can the specified file be written?

Prototype	CanWrite($)
Inputs	0) File name or extension
Returns	True if ExifTool supports writing files of this type (based on the file extension).
Example:

my $writable = Image::ExifTool::CanWrite($filename);
CanCreate
Can the specified file be created?

Prototype	CanCreate($)
Inputs	0) File name or extension
Returns	True if ExifTool can create files with this extension from scratch.
Currently, this can only be done with XMP, MIE, ICC, VRD, DR4, EXV and EXIF files.
Example:

my $creatable = Image::ExifTool::CanCreate($filename);
AddUserDefinedTags
Add user-defined tags to an existing tag table at run time. This differs from the usual technique of creating user-defined tags via the %Image::ExifTool::UserDefined hash (see the sample config file), because it allows tags to be added after a tag table has been initialized.

Prototype	AddUserDefinedTags($%)
Inputs	0) Destination tag table name
1-N) Pairs of tag ID / tag information hash references for the new tags
Returns	The number of tags added
Example:

use Image::ExifTool ':Public';
my %tags = (
    TestTagID1 => { Name => 'TestTagName1' },
    TestTagID2 => { Name => 'TestTagName2' },
);
my $num = AddUserDefinedTags('Image::ExifTool::PDF::Info', %tags);
Notes:

Pre-existing tags with the same ID will be replaced in the destination table. See lib/Image/ExifTool/README in the full distribution for full details on the elements of the tag information hash.

OrderedKeys
Return a list of ordered keys of a structured tag (ie. a tag value returned as a HASH reference when the Struct option is used).

Prototype	OrderedKeys($)
Inputs	0) Structure HASH reference
Returns	List of ordered keys, or keys sorted in alphabetical order if not ordered.
Example:

use Image::ExifTool ':Public';
my @keys = OrderedKeys($structRef);
<-- Back to ExifTool home page
---
Reading
Writing
Copying
Deleting
Field Names
Serialization
Examples
User-Defined
Structured Information
ExifTool has the ability to read and write XMP structures through the use of either structured or flattened tags. The ability to write via structured input was added in ExifTool version 8.44; older versions accepted only flattened tags as input.

To illustrate the concept of a flattened tag, the XMP-exif:Flash structure contains Fired and Mode fields (among others). The flattened tags corresponding to these structure fields are XMP-exif:FlashFired and XMP-exif:FlashMode. In the XMP Tags documentation, flattened tags are indicated by an underline (_) after the Writable type.

This page describes various techniques used to read and write XMP structures using both structured and flattened tags.

Reading
When reading, structures are flattened by default, and ExifTool returns one "flattened" tag for each field in the structure:

> exiftool -xmp:all a.xmp
XMP Toolkit                     : Image::ExifTool 8.44
Flash Fired                     : True
Flash Mode                      : On
Flash Return                    : Return not detected
But the -struct option may be used to give structured output. In this mode structures are returned instead of separate "flattened" tags:

> exiftool -struct -xmp:all a.xmp
XMP Toolkit                     : Image::ExifTool 8.44
Flash                           : {Fired=True,Mode=On,Return=Return not detected}
(Note: As illustrated in the example above, structures are serialized for console output by the ExifTool application. However, via the API with the Struct option, they are returned as Perl HASH references.)

The -struct option may also be combined with the JSON (-j), PHP (-php) or XML (-X) output formats to provide a structured format which may be more compatible with other applications.

Writing
When writing, flattened tags and structures may be used interchangeably. For example, the following commands all have the same effect.

exiftool -flashmode=on -flashreturn=not -flashfired=true a.xmp
exiftool -xmp:flash="{mode=on,fired=true}" -flashreturn=not a.xmp
exiftool -xmp:flash="{mode=on,fired=true,return=not}" a.xmp
(Note: Structures must be serialized when writing via the command-line application, in the same format as when reading with the -struct option.)

An advantage of writing in structured form is that it can be easier to achieve the desired hierarchy with complex structures or when there are multiple structures in a list. For example, this command adds a new hierarchical keyword to the XMP-mwg-kw:HierarchicalKeywords list:

exiftool -hierarchicalkeywords+="{keyword=cat,children={keyword=Siamese}}" a.jpg
But the flattened tags may be more convenient for adding or replacing a single field in an existing structure because writing as a structure would require that the entire structure be replaced. For example, the following command adds a new second-level keyword to an existing HierarchicalKeywords structure:

exiftool -hierarchicalkeywords2+="Persian" a.jpg
Tricky: There is one drawback when using this technique to add new fields to existing structures in lists: New fields are added to the first structure which doesn't already contain the corresponding field. So before adding a new field to a arbitrary structure, dummy fields must first be added to all earlier structures in the list which are missing this field. However, the alternative of adding a new field by writing structured information also has its drawbacks. Here, although a specific structure in a list can easily be targeted through any unique combination of field values, the drawback is that the entire structure must be replaced (see Deleting / Replacing below).

The flattened tag names may also be used to write structures at any level in a complex hierarchy. The following example writes a third-level structure inside a HierarchicalKeywords structure:

exiftool -hierarchicalkeywords2Children='{Keyword=Tabby,Applied=true}' a.jpg
(Note: Containing structures are created as necessary. In this case, the HierarchicalKeywords and top-level KeywordInfo structures would be created if they didn't already exist.)

The order of structure fields is not significant, so they may be read in a different order than written, unlike arrays which maintain the same order. To give a predictable output, fields in structured information are sorted in alphabetical order of field name by ExifTool when reading and writing.

If there are errors converting some fields of the input structure, other fields are still written and a warning is issued (but only one warning per structure is reported). This also applies when copying structured information except that the -v3 option must be used to see the warnings when copying.

Programmers: Structured information is written and read as Perl HASH references via the ExifTool API, but it may also be written as a serialized string. The following two techniques are equivalent:

# as a HASH reference
$exifTool->SetNewValue('XMP:Flash' => { mode=>'on', fired=>'true', return=>'not' });

# as a serialized string
$exifTool->SetNewValue('XMP:Flash' => '{mode=on,fired=true,return=not}');
Copying
By default, tags are copied as structures, but flattened tag names may still be copied by specifying them explicitly. (Flattened tags are treated as "unsafe" for copying so they are not copied by default unless the Struct feature is disabled; see below.) Copying as structures allows the hierarchy of complex structures to be preserved.

# this copies all XMP information as structures
# (flattened tags are not copied by default...)
exiftool -tagsfromfile src.jpg -xmp:all dst.jpg

# ... but flattened tags may be copied individually.  Here the
# first level hierarchical keywords are copied to the Subject tag
# (this may be done in the same command as one that copies structures)
exiftool -tagsfromfile src.jpg "-subject<hierarchicalkeywords1" dst.jpg
Note that when copying a specific structure, only the top-level structures may be specified:

# this copies the complete keyword hierarchy
exiftool -tagsfromfile src.jpg -keywordinfo dst.jpg

# WRONG because HierarchicalKeywords is NOT a top-level structure!
exiftool -tagsfromfile src.jpg -hierarchicalkeywords dst.jpg
The copy-as-structure feature may be disabled with --struct on the command line, or by setting the Struct option to 0 via the API. When this is done, only flattened tags are copied, and structures may not be specified. Conversely, if the structure option is enabled (by setting the Struct option to 1 via the API, or with -struct on the command line), only structures are copied, and flattened tags may not be specified.

(Note: ExifTool 8.43 and earlier copied as flattened tags only, but copying as structures has been the default since the ability to write structured information was introduced in version 8.44. An enhancement in version 8.82 allowed flattened tags to be copied explicitly without the need to disable the Struct option.)

Deleting / Replacing
A complete structure is deleted by specifying one or more matching fields. All fields must match for the structure to be deleted. For example, the following command deletes all HierarchicalKeywords structures which have the Keyword "Terrier" at the second level:

exiftool -hierarchicalkeywords-="{Children={Keyword=Terrier}}" a.jpg
Structure fields may also be deleted individually using the flattened tag names. The following command deletes only the matching fields from the second-level of all HierarchicalKeywords structures:

exiftool -hierarchicalkeywords2-="Terrier" a.jpg
Individual structure fields may NOT be deleted by writing a structure with an empty field. Instead, a command like this overwrites the entire structure with a new structure containing an empty field:

exiftool -CreatorContactInfo="{CiAdrCity=}" a.jpg  # WRONG!
When deleting and adding back items in lists in the same command, new items are inserted at the point in the list where the first item was removed, or at the end of the list if no items were deleted. This applies to lists of structures as well as simple lists of string values, and provides a mechanism to replace a specific structure or field.

Field Names
Structure field names use a format very similar to tag names in ExifTool. The following table lists some similarities and differences between tag names and structure field names:

Feature	Example	Tag Names	Field Names
Case Insensitivity	Title, title, TITLE	Yes	Yes
Alternate Language Suffix	Title-de	Yes	Yes
Numerical Value Suffix	Mode#	Yes	Yes
Group Name Prefix	XMP-dc:Title	Yes	No†
† Except that group name prefixes are allowed in structures which support arbitrary XMP fields (eg. Region Extensions)
Serialization
Structures are serialized when reading or writing from the command line. However, serialization is not done when reading via the API, and is optional when writing via the API. The default serialization algorithm is outlined below, but note that ExifTool 12.64 has an API StructFormat option to allow JSON-format serialized structures.

Default serialization algorithm

Escape the following characters in string values (structure field values and list items) by adding a leading pipe symbol (|):
pipe symbols (|) and commas (,) anywhere in the string
closing curly brackets (}) anywhere in structure field values
closing square brackets (]) anywhere in list items
an opening curly ({) or square ([) bracket, or whitespace character (SPACE, TAB, CR or LF) if it appears at the beginning of the string
(Note: Any other character may be escaped by adding a leading pipe symbol without effect.)
Enclose structures in curly brackets. Use an equal sign (=) to separate field names from their corresponding values, and a comma between structure fields.
Enclose lists in square brackets, with a comma between list items.
Optional whitespace padding may be added anywhere except inside a structure field name, or inside or after a string value, and an optional comma may be added after the last field in a structure.
For example, with this command:

exiftool "-RegionInfo<=INFILE" a.xmp
and the INFILE below, structured information is written to XMP-mwg-rs:RegionInfo.

{
  AppliedToDimensions =
  {
     W = 4288,
     H = 2848,
     Unit = pixel,
  },
  RegionList =
  [
    {
      Area =
      {
        W = 0.15, H = 0.17, X = 0.3, Y = 0.4,
        Unit = normalized,
      },
      Description = A Physics Icon {relatively speaking|},
      Name = Albert Einstein,
      Type = Face,
      Extensions = {
        XMP-xmpRights:UsageTerms = copyright Phil Harvey,
        XMP-xmpRights:UsageTerms-fr = droit d'auteur Phil Harvey,
      },
      SeeAlso = dc:subject,
    },
    {
      Area =
      {
        W = 0.06, H = 0.09, X = 0.5, Y = 0.6,
        Unit = normalized,
      },
      Description = this is a test|, what did you expect?,
      Type = Focus,
      FocusUsage = Evaluated|, Used,
    }
  ],
}
In this example, white space has been added in all allowed locations for demonstration purposes and to improve readability. Also, optional commas have been added after the last field of each structure. (Note that a comma may NOT be added after the last item in a list because this would be interpreted as an additional list item consisting of a zero-length string.)

Examples
Here is an example of an advanced console session showing some commands which manipulate a complex list of structures (see the XMP-iptcExt tag documentation for details about the ArtworkOrObject structure tags used):

# 1. Create a XMP-iptcExt:ArtworkOrObject structure using flattened tags
> exiftool -artworktitle="a title" a.xmp
    1 image files created

# -- Read back as flattened tags (-S is used just to shorten the output)
> exiftool -xmp-iptcext:all -S a.xmp
ArtworkTitle: a title

# -- Read back as a structure
> exiftool -xmp-iptcext:all -S -struct a.xmp
ArtworkOrObject: [{AOTitle=a title}]

# 2. Write another field to the structure as a flattened tag
> exiftool -artworkcreator=phil a.xmp
    1 image files updated

# -- Note that the structure now has a new field
> exiftool -xmp-iptcext:all -S -struct a.xmp
ArtworkOrObject: [{AOCreator=[phil],AOTitle=a title}]

# 3. Add another creator using the "+=" operator
> exiftool -artworkcreator+=joe a.xmp
    1 image files updated

# -- It was added to the first AOCreator list
> exiftool -xmp-iptcext:all -S -struct a.xmp
ArtworkOrObject: [{AOCreator=[phil,joe],AOTitle=a title}]

# 4. Add another artwork title
> exiftool -artworktitle+="another one" a.xmp
    1 image files updated

# -- This created a new ArtworkOrObject structure in the list of structures
# (AOTitle itself is not a list, so a new structure must be created)
> exiftool -xmp-iptcext:all -S -struct a.xmp
ArtworkOrObject: [{AOCreator=[phil,joe],AOTitle=a title},{AOTitle=another one}]

# 5. Simply write a different title (do not add with "+=")
> exiftool -artworktitle="different" a.xmp
    1 image files updated

# -- This deleted all existing AOTitle fields and wrote back only one
# (if the second ArtworkOrObject structure had contained more fields, they would have been
# preserved, and the second structure would still exist, but without an AOTitle field)
> exiftool -xmp-iptcext:all -S -struct a.xmp
ArtworkOrObject: [{AOCreator=[phil,joe],AOTitle=different}]

# 6. Add a completely new structure to the list
# (this is very difficult to do properly using flattened tags)
> exiftool -artworkorobject+="{aotitle=help,aocreator=[paul,ringo]}" a.xmp
    1 image files updated

# -- The new structure was added with the specified fields
> exiftool -xmp-iptcext:all -S -struct a.xmp
ArtworkOrObject: [{AOCreator=[phil,joe],AOTitle=different},{AOCreator=[paul,ringo],AOTitle=help}]

# -- See how the relationships are lost when reading as flattened tags
> exiftool -xmp-iptcext:all -S a.xmp
ArtworkCreator: phil, joe, paul, ringo
ArtworkTitle: different, help

# 7. Delete all structures containing a specific field value
> exiftool -artworkorobject-="{AOCreator=phil}" a.xmp
    1 image files updated

# -- The ArtworkOrObject list now contains only one structure
> exiftool -xmp-iptcext:all -S -struct a.xmp
ArtworkOrObject: [{AOCreator=[paul,ringo],AOTitle=help}]
User-Defined Structures
User-defined XMP structure tags may be created via the ExifTool config file. See the NewXMPxxxStruct tag definition in the XMP-xxx examples of the sample config file for more details.


# FAQ
##  "List-type tags do not behave as expected"

Tags indicated by a plus sign (+) in the tag name documentation are list-type tags. Two examples of common list-type tags are IPTC:Keywords and XMP:Subject. These tags may contain multiple items which are combined into a single string when reading. (By default, extracted list items are separated by a comma and a space, but the -sep option may be used to change this.) When writing, separate items are assigned individually. For example, the following command writes three keywords to all writable files in directory DIR, replacing any previously existing keywords:
exiftool -keywords=one -keywords=two -keywords=three DIR
List items are assigned separately as above, NOT all together, because this would represent a single keyword:
exiftool -keywords="one, two, three" test.jpg  (WRONG!)
The -sep option may be used to split values of list-type tags into separate items when writing. For example,
exiftool -sep ", " -keywords="one, two, three" DIR
will store three separate keywords, the same as the first example above. This feature may also be used to split a tag value into separate items if it was originally stored incorrectly as a single string:
exiftool -sep ", " -tagsfromfile @ -keywords test.jpg
However, sometimes it is desirable to have list items which contain a comma, and this is allowed:
exiftool -contributor="Harvey, Phil" -contributor="Marley, Bob" a.jpg
But to distinguish these entries when extracting information, a different list separator or a different output format must be used. For instance, the following command uses "//" to separate list items,
exiftool -contributor -sep "//" a.jpg
and produces an output like this:
Contributor  : Harvey, Phil//Marley, Bob
Alternatively, the -j, -php and -X options use an output format which preserves the structure of a list (if -sep is NOT used).
Note that the writing examples above overwrite any values which already existed in the original file for these tags. Instead, to add or delete items from an existing list, use "+=" or "-=" in place of "=". For example:
exiftool -keywords+="add this" -keywords-="remove this" DIR
With commands like this, new items are added to the list in place of the first deleted item, or at the end of the list if no items were removed.
Note: Using "=" is equivalent to "+=" in any command where the same List-type tag is set with "+=" or "-=" in another assignment. (ie. existing items will be preserved unless specifically deleted with "-=".) [For non List-type tags, "+=" has a different meaning, and is used to increment numerical values or shift dates.]
To prevent duplication when adding new items, specific items can be deleted then added back again in the same command. For example, the following command adds the keywords "one" and "two", ensuring that they are not duplicated if they already existed in the keywords of an image:
exiftool -keywords-=one -keywords+=one -keywords-=two -keywords+=two DIR
When copying list tags using the -tagsFromFile feature, items are copied individually to form proper lists if the tag is copied directly (note that -tagsFromFile @ is implied by the "<" operation in this and the following commands, causing tags to be copied from the original file):
exiftool "-keywords<subject" DIR
However, this is not the case if the tag is interpolated within a format string (ie. has a leading "$" symbol), like this
exiftool "-keywords<$subject" DIR  (WRONG!)
but here the -sep option may be used to split the list back into separate items:
exiftool "-keywords<$subject" -sep "//" DIR
Note there is a complication when copying multiple tags to a single list tag: Here, any assignment to a tag overrides earlier assignments to the same tag in the command. For instance, this command:
exiftool "-keywords<filename" "-keywords<comment" DIR  (WRONG!)
writes only the value from the Comment tag. This may seem strange, but it prevents duplicate items from being added to a list when copying a group of tags from a file containing duplicate information. Alternatively, a leading + may be added to accumulate queued items when copying from multiple tags to a single list:
exiftool "-keywords<filename" "-+keywords<comment" DIR
Note that as with "=" in the first three examples above, the "<" operation of this command overwrites any Keywords that existed previously in the original file. To add to or remove from the existing keywords, use "+<" or "-<".
One final note: In rare cases when copying the contents of two other tags into a single list, the resulting queued list values may contain duplicates that would be written to the target file. There is an API NoDups option which removes duplicates items from list values that are queued for writing. For example,
exiftool -tagsfromfile a.jpg -subject -tagsfromfile b.jpg -+subject -api nodups c.jpg
combines Subject items from a.jpg and b.jpg and writes them without duplicates to c.jpg (overwriting any previous Subject in c.jpg).
````

## File: error_files.txt
````
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-229/test_process_directory_batch_f0/test.jpeg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-231/test_process_directory_batch_f0/test.jpeg
C:/Users/anthony/AppData/Local/Temp/tmpmbt88zfm/_Corbeille/test_image.jpg
C:/Users/anthony/AppData/Local/Temp/tmpj3fxo9py/_Corbeille/test_image.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-237/test_process_directory_batch_f0/test.jpeg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-239/test_batch_sidecar_cleanup_wit0/non_existent.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-244/test_batch_sidecar_cleanup_wit0/non_existent.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-244/test_process_directory_batch_f0/test.jpeg
C:/Users/anthony/AppData/Local/Temp/tmpf_ptzoug/_Corbeille/test_image.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-245/test_batch_sidecar_cleanup_wit0/non_existent.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-245/test_process_directory_batch_f0/test.jpeg
C:/Users/anthony/AppData/Local/Temp/tmph8ulm9ef/_Corbeille/test_image.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-246/test_batch_sidecar_cleanup_wit0/non_existent.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-246/test_process_directory_batch_f0/test.jpeg
C:/Users/anthony/AppData/Local/Temp/tmpc9pn2wg_/_Corbeille/test_image.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-247/test_batch_sidecar_cleanup_wit0/non_existent.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-247/test_process_directory_batch_f0/test.jpeg
````

## File: pyproject.toml
````toml
[build-system]
requires = ["setuptools>=61.0", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "google_takeout_metadata"
version = "0.1.0"
description = "Merge Google Takeout metadata into images"
readme = "README.md"
license = {file = "LICENSE"}
authors = [
    {name = "Anthony", email = "anthony@example.com"}
]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: End Users/Desktop",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.8",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Programming Language :: Python :: 3.13",
]
dependencies = []

[project.optional-dependencies]
test = ["pytest", "pillow"]

[project.scripts]
google-takeout-metadata = "google_takeout_metadata.cli:main"

[tool.setuptools.packages.find]
where = ["src"]

[tool.pytest.ini_options]
testpaths = ["tests"]
markers = [
    "integration: marks tests as integration tests (requiring exiftool)",
]
````

## File: pytest.ini
````
[pytest]
addopts = -ra
pythonpath = src
markers =
    integration: marks tests as integration tests requiring exiftool
````

## File: README.md
````markdown
# exif_metadata_google_photo_takeout

Ce projet permet d'incorporer les métadonnées des fichiers JSON produits par Google Takeout dans les photos correspondantes.

## Fonctionnalités

✅ **Métadonnées supportées:**
- Descriptions/légendes
- Personnes identifiées (avec déduplication automatique)
- Dates de prise de vue et de création
- Coordonnées GPS (filtrage automatique des coordonnées 0/0 peu fiables)
- Favoris (mappés sur le tag Favorite booléen)
- **Albums** (détectés depuis les fichiers metadata.json de dossier et ajoutés comme mots-clés "Album: <nom>")

✅ **Mode de fonctionnement sûr par défaut:**
- **Append-only par défaut**: Les métadonnées existantes sont préservées
- Les descriptions ne sont écrites que si elles n'existent pas déjà
- Les personnes et albums sont ajoutés aux listes existantes sans suppression
- **Mode sécurisé des sidecars**: Par défaut, les sidecars JSON sont marqués avec le préfixe "OK_" après traitement réussi
- Utiliser `--overwrite` pour forcer l'écrasement des métadonnées existantes
- Utiliser `--immediate-delete` pour supprimer immédiatement les sidecars (mode destructeur)

✅ **Options avancées:**
- `--localtime`: Conversion des timestamps en heure locale au lieu d'UTC
- `--overwrite`: Force l'écrasement des métadonnées existantes (mode destructif)
- `--immediate-delete`: Mode destructeur - supprime immédiatement les sidecars JSON après succès
- `--batch`: Mode batch pour traitement optimisé de gros volumes de fichiers
- `--organize-files`: Organisation automatique des fichiers selon leur statut archived/trashed

✅ **Qualité:**
- Tests unitaires complets
- Tests d'intégration E2E avec exiftool
- Support des formats photo et vidéo
- **Arguments sécurisés** : Protection contre l'injection shell avec noms contenant des espaces
- **Opérateur `+=` optimisé** : Utilise l'opérateur exiftool `+=` pour accumulation sûre des tags de type liste

## Installation

Prérequis: `exiftool` doit être installé et accessible dans le PATH.

```bash
pip install -e .
```

## Utilisation

### Utilisation basique (mode sûr par défaut)
```bash
# Mode append-only par défaut - préserve les métadonnées existantes
google-takeout-metadata /chemin/vers/le/dossier
```

### Avec options
```bash
# Utiliser l'heure locale pour les timestamps
google-takeout-metadata --localtime /chemin/vers/le/dossier

# Mode destructif: écraser les métadonnées existantes (à utiliser avec précaution)
google-takeout-metadata --overwrite /chemin/vers/le/dossier

# Mode destructeur: supprimer les sidecars immédiatement après traitement
google-takeout-metadata --immediate-delete /chemin/vers/le/dossier

# Organisation automatique des fichiers selon leur statut
google-takeout-metadata --organize-files /chemin/vers/le/dossier

# Combiner les options (mode sûr avec heure locale)
google-takeout-metadata --localtime /chemin/vers/le/dossier

# Exemple complet avec toutes les options utiles
google-takeout-metadata --batch --localtime --organize-files /chemin/vers/le/dossier
```

### Mode batch (optimisé pour gros volumes)
```bash
# Mode batch: traitement optimisé pour de nombreux fichiers
google-takeout-metadata --batch /chemin/vers/le/dossier

# Mode batch avec autres options
google-takeout-metadata --batch --localtime /chemin/vers/le/dossier
google-takeout-metadata --batch --overwrite /chemin/vers/le/dossier

# Exemple concret avec toutes les options (pointer vers le dossier Takeout)
google-takeout-metadata --batch --localtime --immediate-delete "C:\Users\anthony\Downloads\google photos\Takeout"
```

**Si la commande `google-takeout-metadata` n'est pas trouvée:**
```bash
# Option 1: Utiliser le module Python directement (attention aux underscores)
python -m google_takeout_metadata --batch --localtime --immediate-delete "/chemin/vers/dossier"

# Option 2: Utiliser l'environnement virtuel complet avec le module
C:/Users/anthony/Documents/PROJETS/exif_metadata_google_photo_takeout/.venv/Scripts/python.exe -m google_takeout_metadata --batch --localtime --immediate-delete "C:\Users\anthony\Downloads\google photos\Takeout"

# Option 3: Utiliser l'exécutable directement depuis l'environnement virtuel
C:/Users/anthony/Documents/PROJETS/exif_metadata_google_photo_takeout/.venv/Scripts/google-takeout-metadata.exe --batch --localtime --immediate-delete "C:\Users\anthony\Downloads\google photos\Takeout"

# Option 4: Activer l'environnement virtuel d'abord
.venv/Scripts/activate  # Sur Windows
google-takeout-metadata --batch --localtime --immediate-delete "/chemin/vers/dossier"
```

**Avantages du mode batch:**
- **Performance améliorée** : Traitement par lots avec exiftool pour réduire le nombre d'appels système
- **Idéal pour gros volumes** : Optimisé pour traiter des milliers de fichiers
- **Moins de fragmentation** : Réduit la charge système en groupant les opérations
- **Même sécurité** : Conserve le comportement append-only par défaut

**Quand utiliser le mode batch:**
- Traitement de bibliothèques photo importantes (>100 fichiers)
- Archives Google Takeout volumineuses
- Situations où la performance est critique

**Note de performance:**
Le mode batch réduit significativement le temps de traitement en groupant les appels à exiftool. 
Pour 1000 fichiers, le gain peut être de 50-80% selon la configuration système.

## Organisation automatique des fichiers

**Nouvelle fonctionnalité** : Organisation automatique des fichiers selon leur statut dans Google Takeout.

```bash
# Activer l'organisation automatique
google-takeout-metadata --organize-files /chemin/vers/le/dossier

# Combiner avec d'autres options
google-takeout-metadata --batch --organize-files --localtime /chemin/vers/le/dossier
```

### 📁 Fonctionnement:

**Statuts détectés** dans les sidecars JSON Google Takeout:
- `"archived": true` → Fichier déplacé vers `archive/`
- `"trashed": true` → Fichier déplacé vers `corbeille/`
- **Priorité** : Si un fichier a `archived: true` ET `trashed: true`, le statut `trashed` l'emporte

**Structure créée automatiquement:**
```
dossier_source/
├── archive/          # Fichiers avec "archived": true
├── corbeille/        # Fichiers avec "trashed": true  
└── autres_fichiers   # Fichiers sans statut spécial
```

### 🔒 Sécurité:

- **Gestion des conflits** : Si un fichier existe déjà dans le dossier de destination, un suffixe numérique est ajouté
- **Déplacement avec sidecar** : Le fichier JSON correspondant est déplacé avec le fichier média
- **Préservation** : Tous les fichiers sont déplacés, jamais supprimés
- **Logs détaillés** : Information sur chaque déplacement effectué

### ⚙️ Avantages:

- **Nettoyage automatique** : Sépare automatiquement les fichiers archivés et supprimés
- **Préservation de l'historique** : Les fichiers "trashés" restent accessibles dans `corbeille/`
- **Workflow Google Takeout** : Respecte parfaitement la logique de statut de Google Photos
- **Combinable** : Fonctionne avec toutes les autres options (batch, localtime, etc.)

**Exemple concret:**
```bash
# Traitement complet d'un export Google Takeout avec organisation
google-takeout-metadata --batch --localtime --organize-files "C:\Downloads\Takeout\Google Photos"
```

Le programme parcourt récursivement le dossier, cherche les fichiers `*.json` et écrit les informations pertinentes dans les fichiers image correspondants à l'aide d'`exiftool`.

## Comportement par défaut (Sécurisé)

**Le mode append-only est désormais activé par défaut** pour éviter la perte accidentelle de métadonnées:

### ✅ Métadonnées préservées:
- **Descriptions existantes** ne sont jamais écrasées
- **Dates existantes** ne sont jamais modifiées
- **Coordonnées GPS existantes** ne sont jamais remplacées
- **Ratings existants** ne sont jamais changés

### ✅ Métadonnées ajoutées:
- **Personnes** sont ajoutées aux listes existantes avec déduplication intelligente
- **Albums** sont ajoutés aux mots-clés existants avec déduplication intelligente

### 🔧 Déduplication intelligente:
**Nouvelle fonctionnalité** : Le système évite automatiquement les doublons dans les tags de liste.

- **Normalisation des noms** : "anthony vincent" et "Anthony Vincent" sont reconnus comme identiques
- **Gestion des cas spéciaux** : Support intelligent pour "McDonald", "O'Connor", "van der Berg", etc.
- **Approche robuste** : Utilise la stratégie "supprimer puis ajouter" (-TAG-=val -TAG+=val) pour garantir zéro doublon final
- **Performance optimisée** : Logs -efile pour reprises intelligentes en cas d'interruption
- **Gestion des `-wm cg`** : Logic groupée pour optimiser les arguments ExifTool en mode append-only

### ⚠️ Mode destructif:
Utilisez `--overwrite` seulement si vous voulez explicitement écraser les métadonnées existantes.

### 🔐 Gestion des sidecars JSON:
**Mode sécurisé par défaut** : Les sidecars sont préservés avec un préfixe après traitement réussi.

- **Mode sécurisé** (défaut) : Les sidecars sont renommés avec le préfixe "OK_" après succès
- **Mode destructeur** (`--immediate-delete`) : Les sidecars sont supprimés immédiatement après traitement réussi
- **Sécurité** : En cas d'erreur, les sidecars restent intacts pour permettre de retenter
- **Traçabilité** : Les fichiers "OK_" permettent de voir quels sidecars ont été traités avec succès

## Détails techniques

### Opérateur exiftool `+=` pour les listes
Notre implémentation utilise l'opérateur `+=` d'exiftool pour une gestion sûre des tags de type liste :

```bash
# ✅ Correct : L'opérateur += ajoute ET crée le tag si nécessaire
exiftool "-XMP-iptcExt:PersonInImage+=John Doe" photo.jpg

# ❌ Incorrect : L'opérateur += seul ne crée pas un tag inexistant
# (ancien comportement qui échouait)
```

**Avantages de notre approche :**
- **Création automatique** : `+=` crée le tag s'il n'existe pas
- **Accumulation sûre** : Ajoute aux listes existantes sans duplication
- **Sécurité** : Arguments séparés préviennent l'injection shell avec espaces
- **Mode overwrite** : Vide explicitement puis reremplit avec `+=`
- **Logic `-wm cg` optimisée** : Arguments groupés pour éviter la fragmentation des paramètres

### Format Google Takeout supporté
```json
{
  "title": "IMG_20240716_200232.jpg",
  "description": "Description de la photo",
  "photoTakenTime": {"timestamp": "1721152952"},
  "creationTime": {"timestamp": "1721152952"},
  "geoData": {
    "latitude": 48.8566,
    "longitude": 2.3522,
    "altitude": 35.0
  },
  "people": [
    {"name": "John Doe"},
    {"name": "Jane Smith"}
  ],
  "favorited": true,
  "archived": false,
  "trashed": false
}
```

**Champs supportés pour l'organisation des fichiers:**
- `archived`: Déplace le fichier vers le dossier `archive/` si `true`
- `trashed`: Déplace le fichier vers le dossier `corbeille/` si `true` (priorité sur `archived`)
```

## Tests

```bash
# Tests unitaires
pytest tests/ -m "not integration"

# Tests complets (nécessite exiftool)
pytest tests/

# Tests d'intégration uniquement
pytest tests/ -m "integration"
```

Les tests comprennent:
- **Tests unitaires**: Parsing des sidecars, génération des arguments exiftool
- **Tests d'intégration**: Écriture et relecture effective des métadonnées avec exiftool
- **Tests du mode batch**: Vérification des performances et de la compatibilité du traitement par lots
- **Tests CLI**: Validation de l'interface en ligne de commande et de toutes les options
- **Tests de l'approche robuste**: Validation de la déduplication et de la logique "supprimer puis ajouter"
- **Tests P1**: Vérification du fix pour l'écrasement des timestamps en mode append-only
- **Tests d'organisation**: Validation du déplacement automatique des fichiers archived/trashed
````

## File: requirements.txt
````
pillow
pytest
````

## File: SIDECAR_SAFETY_IMPLEMENTATION.md
````markdown
# Système de Sas de Sécurité pour les Sidecars

## 📋 Résumé de l'implémentation

Le nouveau système de sécurité a été implémenté avec succès pour protéger contre la suppression accidentelle des fichiers sidecar JSON.

## 🔧 Changements apportés

### 1. Nouveau module `sidecar_safety.py`
- **Fonctions principales** :
  - `mark_sidecar_as_processed(json_path)` : Renomme avec préfixe `OK_`
  - `is_sidecar_processed(json_path)` : Vérifie si déjà traité
  - `get_processed_sidecars(directory)` : Liste tous les sidecars traités
  - `find_sidecars_to_skip(directory)` : Sidecars à ignorer lors de retraitement
  - `generate_cleanup_script(directory)` : Script de suppression définitive
  - `generate_rollback_script(directory)` : Script de restauration
  - `generate_scripts_summary(directory)` : Résumé et statistiques

### 2. Modifications des processeurs

#### `processor.py` et `processor_batch.py`
- **Ancien paramètre** : `clean_sidecars: bool = False`
- **Nouveau paramètre** : `immediate_delete: bool = False`
- **Logique** :
  - `immediate_delete=False` (défaut) → Mode sécurisé avec préfixe `OK_`
  - `immediate_delete=True` → Mode destructeur (ancien comportement)
- **Filtrage** : Ignorer automatiquement les sidecars déjà traités lors de nouveaux traitements
- **Scripts** : Génération automatique des scripts de gestion en fin de traitement

### 3. Interface CLI `cli.py`

#### Nouveaux arguments
```bash
# Mode sécurisé par défaut (nouveau comportement)
python -m google_takeout_metadata process /path/to/photos

# Mode destructeur explicite (ancien comportement)  
python -m google_takeout_metadata process /path/to/photos --immediate-delete

# Compatibilité ascendante (avec avertissement de dépréciation)
python -m google_takeout_metadata process /path/to/photos --clean-sidecars
```

#### Changements dans l'interface
- `--immediate-delete` : Nouveau flag pour mode destructeur
- `--clean-sidecars` : Marqué comme déprécié, redirige vers `--immediate-delete`
- Messages informatifs sur le mode utilisé

## 🔄 Workflow utilisateur

### Mode sécurisé (défaut)
1. **Traitement** : `python -m google_takeout_metadata process /path/to/photos`
2. **Succès ExifTool** → Sidecar renommé : `photo.jpg.json` → `OK_photo.jpg.json`
3. **Échec ExifTool** → Sidecar conservé tel quel pour retry
4. **Fin de traitement** → Scripts générés automatiquement
5. **Vérification manuelle** → Utilisateur vérifie les résultats
6. **Action finale** → Exécution du script de nettoyage ou rollback

### Scripts générés automatiquement
- **`cleanup_processed_sidecars.bat/.sh`** : Suppression définitive des sidecars traités
- **`rollback_processed_sidecars.bat/.sh`** : Restauration des noms originaux

### Exemple d'usage
```bash
# Traitement initial (mode sécurisé)
python -m google_takeout_metadata process "Google Photos"

# Vérification manuelle des résultats
# Les sidecars traités ont le préfixe OK_

# Si tout est correct, nettoyage final
./cleanup_processed_sidecars.bat

# Si problème détecté, rollback
./rollback_processed_sidecars.bat
```

## 🛡️ Avantages du nouveau système

### Sécurité
- **Aucune perte de données** : Les sidecars ne sont jamais supprimés immédiatement
- **Vérification manuelle** : L'utilisateur peut contrôler avant suppression définitive
- **Rollback facile** : Restauration des noms originaux en un clic

### Robustesse
- **Reprise intelligente** : Les sidecars déjà traités sont automatiquement ignorés
- **Pas de double traitement** : Évite de retraiter les fichiers déjà processés
- **Gestion d'erreurs** : En cas d'interruption, reprise possible sans perte

### Transparence
- **Scripts générés** : L'utilisateur voit exactement ce qui sera supprimé
- **Logs détaillés** : Informations claires sur le mode utilisé
- **Statistiques** : Résumé du nombre de fichiers traités vs en attente

## 🔧 Compatibilité

### Rétrocompatibilité
- **`--clean-sidecars`** : Toujours supporté mais déprécié
- **Comportement identique** : Les anciens scripts continuent de fonctionner
- **Messages d'avertissement** : Incitent à migrer vers `--immediate-delete`

### Migration
```bash
# Ancien usage (toujours supporté)
python -m google_takeout_metadata process /path --clean-sidecars

# Nouveau usage recommandé pour même comportement
python -m google_takeout_metadata process /path --immediate-delete

# Nouveau usage recommandé (mode sécurisé)
python -m google_takeout_metadata process /path
```

## 🧪 Tests

Le système a été testé avec succès :
- ✅ Marquage des sidecars comme traités
- ✅ Génération des scripts de nettoyage et rollback
- ✅ Filtrage des sidecars déjà traités
- ✅ Résumé et statistiques
- ✅ Scripts Windows (.bat) et Unix (.sh) fonctionnels

## 📁 Fichiers modifiés

1. **Nouveau** : `src/google_takeout_metadata/sidecar_safety.py`
2. **Modifié** : `src/google_takeout_metadata/processor.py`
3. **Modifié** : `src/google_takeout_metadata/processor_batch.py`
4. **Modifié** : `src/google_takeout_metadata/cli.py`
5. **Test** : `test_sidecar_safety.py`

## 🎯 Résultat

Le système de sas de sécurité est maintenant opérationnel et offre :
- **Sécurité par défaut** : Pas de suppression accidentelle
- **Flexibilité** : Choix entre mode sécurisé et destructeur
- **Transparence** : Scripts et logs détaillés
- **Robustesse** : Gestion d'erreurs et reprises intelligentes
- **Compatibilité** : Support des anciens scripts

L'utilisateur peut maintenant traiter ses photos Google Takeout en toute sécurité ! 🔐✨
````

## File: src/google_takeout_metadata/__init__.py
````python
"""Utilitaires pour fusionner les métadonnées annexes Google Takeout dans des fichiers image."""
__all__ = [
    "sidecar",
    "exif_writer",
    "processor",
]
````

## File: src/google_takeout_metadata/__main__.py
````python
"""Point d'entrée principal du paquet google_takeout_metadata."""
from google_takeout_metadata.cli import main
if __name__ == "__main__":
    main()
````

## File: src/google_takeout_metadata/cli.py
````python
"""Interface en ligne de commande."""
from __future__ import annotations
import argparse
import logging
import shutil
import sys
from pathlib import Path
from .processor import process_directory
from .processor_batch import process_directory_batch
from .statistics import ProcessingStats
import google_takeout_metadata.statistics as stats_module
def main(argv: list[str] | None = None) -> None:
    parser = argparse.ArgumentParser(description="Fusionner les métadonnées Google Takeout dans les images")
    parser.add_argument("path", type=Path, help="Répertoire à analyser récursivement")
    parser.add_argument(
        "--localtime", action="store_true",
        help="Convertir les horodatages en heure locale au lieu de l'UTC (par défaut : UTC)"
    )
    parser.add_argument(
        "--overwrite", action="store_true",
        help="Autoriser l'écrasement des champs de métadonnées existants (par défaut, les métadonnées existantes sont préservées)"
    )
    parser.add_argument(
        "--immediate-delete", action="store_true",
        help="Mode destructeur: supprimer immédiatement les sidecars JSON après succès (par défaut: mode sécurisé avec préfixe OK_)"
    )
    parser.add_argument(
        "--organize-files", action="store_true",
        help="Organiser les fichiers selon leur statut: déplacer les fichiers archivés vers '_Archive' et supprimés vers '_Corbeille'"
    )
    parser.add_argument(
        "-v", "--verbose", action="store_true",
        help="Activer les logs détaillés (niveau DEBUG)"
    )
    parser.add_argument(
        "--batch", action="store_true",
        help="Traiter les fichiers par lots"
    )
    args = parser.parse_args(argv)
    # Configuration du logging avec le niveau approprié
    log_level = logging.DEBUG if args.verbose else logging.INFO
    logging.basicConfig(
        level=log_level, 
        format="%(asctime)s - %(levelname)s - %(message)s"
    )
    # Gestion de la compatibilité du système de sécurité
    immediate_delete = args.immediate_delete
    if immediate_delete:
        logging.info("🔥 Mode destructeur activé : les sidecars seront supprimés immédiatement après succès")
    else:
        logging.info("🔐 Mode sécurisé activé : les sidecars seront marqués avec le préfixe 'OK_' (défaut)")
    if not args.path.is_dir():
        logging.error("Le chemin indiqué n'est pas un répertoire : %s", args.path)
        sys.exit(1)
    # Réinitialiser les statistiques pour cette exécution (nouvelle instance)
    stats_module.stats = ProcessingStats()
    # Le mode par défaut est maintenant append_only=True (sécurité par défaut)
    # L'option --overwrite permet d'écraser les métadonnées existantes
    append_only = not args.overwrite
    # Vérifier que exiftool est disponible uniquement si on va traiter
    if shutil.which("exiftool") is None:
        logging.error("exiftool introuvable. Veuillez l'installer pour utiliser ce script.")
        sys.exit(1)
    if args.batch:
        process_directory_batch(args.path, use_localtime=args.localtime, append_only=append_only, immediate_delete=immediate_delete, organize_files=args.organize_files)
    else:
        process_directory(args.path, use_localtime=args.localtime, append_only=append_only, immediate_delete=immediate_delete, organize_files=args.organize_files)
if __name__ == "__main__":  # pragma: no cover - CLI entry
    main()
````

## File: src/google_takeout_metadata/exif_writer.py
````python
# Fichier : src/google_takeout_metadata/exif_writer.py
import subprocess
import logging
import re
from datetime import datetime, timezone
from pathlib import Path
from typing import List, Iterable
from .sidecar import SidecarData
logger = logging.getLogger(__name__)
VIDEO_EXTS = {".mp4", ".mov", ".m4v", ".3gp"}
# === CONSTANTES ET NORMALISATION ===
_SMALL_WORDS = {
    "de", "du", "des", "la", "le", "les", "van", "von", "da", "di", "of", "and",
    "der", "den", "het", "el", "al", "bin", "ibn", "af", "zu", "ben", "ap", "abu", "binti", "bint", "della", "delle", "dalla", "delle", "del", "dos", "das", "do", "mac", "fitz"
}
def get_all_keywords(meta: SidecarData) -> List[str]:
    """Centralise la logique de création des mots-clés à partir des personnes et albums."""
    keywords = (meta.people or []) + [f"Album: {a}" for a in (meta.albums or [])]
    return keywords
def _is_video_file(path: Path) -> bool:
    return path.suffix.lower() in VIDEO_EXTS
def _fmt_dt(ts: int | None, use_localtime: bool) -> str | None:
    if ts is None:
        return None
    dt = datetime.fromtimestamp(ts) if use_localtime else datetime.fromtimestamp(ts, tz=timezone.utc)
    return dt.strftime("%Y:%m:%d %H:%M:%S")
def normalize_person_name(name: str) -> str:
    """Normaliser les noms de personnes (casse intelligente)"""
    if not name:
        return ""
    parts = [p.strip() for p in name.strip().split() if p.strip()]
    fixed: List[str] = []
    for i, p in enumerate(parts):
        low = p.lower()
        if i > 0 and low in _SMALL_WORDS:
            fixed.append(low)
        elif low.startswith("o'") and len(p) > 2:
            fixed.append("O'" + p[2:].capitalize())
        elif low.startswith("mc") and len(p) > 2:
            fixed.append("Mc" + p[2:].capitalize())
        else:
            fixed.append(p[:1].upper() + p[1:].lower())
    return " ".join(fixed)
def normalize_keyword(keyword: str) -> str:
    """Normaliser un mot-clé: trim + capitaliser chaque mot."""
    if not keyword:
        return ""
    parts = [p.strip() for p in keyword.strip().split() if p.strip()]
    # Capitaliser chaque partie (similaire à normalize_person_name mais plus simple)
    return " ".join(p[:1].upper() + p[1:].lower() for p in parts)
def _sanitize_description(desc: str) -> str:
    """Centralise le nettoyage des descriptions pour ExifTool."""
    return desc.replace("\r", " ").replace("\n", " ").strip()
# === CONSTRUCTION D'ARGUMENTS MODULAIRE ===
def _quote_if_needed(value: str) -> str:
    """Retourne value cotée si elle contient des espaces pour argfile."""
    return f'"{value}"' if (" " in value or "\t" in value) else value
def build_remove_then_add_args_for_people(people: Iterable[str]) -> List[str]:
    """-TAG-=val puis -TAG+=val pour chaque personne normalisée."""
    args: List[str] = []
    for raw in people:
        person = normalize_person_name(raw)
        if not person:
            continue
        add_remove_then_add(args, "XMP-iptcExt:PersonInImage", person)
    return args
def build_remove_then_add_args_for_keywords(keywords: Iterable[str]) -> List[str]:
    """Construction robuste pour Subject/Keywords avec déduplication.
    ATTENTION: Les keywords sont supposés déjà normalisés (personnes avec normalize_person_name, 
    albums avec normalize_keyword). Ne pas normaliser à nouveau.
    """
    args: List[str] = []
    for kw in keywords:
        if not kw.strip():  # Ignorer les valeurs vides
            continue
        # XMP-dc:Subject (bag) + IPTC:Keywords (liste IPTC)
        add_remove_then_add(args, "XMP-dc:Subject", kw)
        add_remove_then_add(args, "IPTC:Keywords", kw)
    return args
# === VARIANTE CONDITIONNELLE (POUR PERFORMANCE) ===
def _regex_escape_word(value: str) -> str:
    """Échappe une valeur pour recherche regex avec word boundary."""
    escaped = re.escape(value)
    return rf"\b{escaped}\b"
def build_conditional_add_args_for_people(people: Iterable[str]) -> List[str]:
    """Option conditionnelle: n'ajoute que si absent (pour relances/perf)."""
    args: List[str] = []
    for raw in people:
        person = normalize_person_name(raw)
        if not person:
            continue
        regex = _regex_escape_word(person)
        args.extend([
            "-if", f"not $XMP-iptcExt:PersonInImage=~/{regex}/i",
            f"-XMP-iptcExt:PersonInImage+={person}"
        ])
    return args
def build_overwrite_args_for_people(people: Iterable[str]) -> List[str]:
    """Arguments mode overwrite : vider puis ajouter chaque personne."""
    args: List[str] = []
    if people:
        # Vider d'abord
        args.append("-XMP-iptcExt:PersonInImage=")
        # Puis ajouter chaque personne normalisée
        for raw in people:
            person = normalize_person_name(raw)
            if person:
                args.append(f"-XMP-iptcExt:PersonInImage+={person}")
    return args
def build_overwrite_args_for_keywords(keywords: Iterable[str]) -> List[str]:
    """Arguments mode overwrite : vider puis ajouter chaque keyword."""
    args: List[str] = []
    if keywords:
        # Vider d'abord
        args.extend(["-XMP-dc:Subject=", "-IPTC:Keywords="])
        # Puis ajouter chaque keyword 
        for kw in keywords:
            if kw.strip():
                args.extend([f"-XMP-dc:Subject+={kw}", f"-IPTC:Keywords+={kw}"])
    return args
def build_conditional_add_args_for_keywords(keywords: Iterable[str]) -> List[str]:
    """Option conditionnelle pour keywords.
    ATTENTION: Les keywords sont supposés déjà normalisés.
    """
    args: List[str] = []
    for kw in keywords:
        if not kw.strip():
            continue
        regex = _regex_escape_word(kw)
        args.extend([
            "-if", f"not $XMP-dc:Subject=~/{regex}/i",
            f"-XMP-dc:Subject+={kw}",
            "-if", f"not $IPTC:Keywords=~/{regex}/i",
            f"-IPTC:Keywords+={kw}"
        ])
    return args
# === HELPER POUR GARANTIR L'ORDRE SUPPRIMER-PUIS-AJOUTER ===
def add_remove_then_add(args: List[str], tag: str, value: str) -> None:
    """Helper pour garantir l'ordre supprime puis ajoute et éviter les coquilles.
    APPROCHE ROBUSTE (NETTOYAGE) :
    Implémente la sémantique -TAG-=val puis -TAG+=val qui :
    - Supprime toutes les occurrences de 'val' dans le tag
    - Puis ajoute une seule occurrence de 'val'
    - Résultat : zéro doublon garanti, idempotent
    - Compatible avec -api NoDups=1 pour déduplication intra-lot
    Args:
        args: Liste d'arguments à laquelle ajouter
        tag: Tag exiftool (ex: "XMP-iptcExt:PersonInImage")  
        value: Valeur à supprimer puis ajouter
    """
    args.extend([f"-{tag}-={value}", f"-{tag}+={value}"])
# === CONSTRUCTION DES ARGUMENTS PRINCIPAUX ===
def build_people_keywords_args(meta: SidecarData, *, conditional_mode: bool = False, overwrite_mode: bool = False) -> List[str]:
    """Construit les arguments pour PersonInImage et Keywords selon la stratégie choisie."""
    args: List[str] = []
    # PersonInImage
    if meta.people:
        if overwrite_mode:
            args.extend(build_overwrite_args_for_people(meta.people))
        elif conditional_mode:
            args.extend(build_conditional_add_args_for_people(meta.people))
        else:
            args.extend(build_remove_then_add_args_for_people(meta.people))
    # Keywords (personnes + albums Google Photos uniquement)
    all_keywords = []
    if meta.people:
        # Ajouter les personnes normalisées comme mots-clés
        normalized_people = [normalize_person_name(person) for person in meta.people]
        all_keywords.extend(normalized_people)
    if meta.albums:
        # Ajouter SEULEMENT les vrais albums Google Photos avec préfixe
        album_keywords = [f"Album: {normalize_keyword(album)}" for album in meta.albums]
        all_keywords.extend(album_keywords)
    if all_keywords:
        if overwrite_mode:
            args.extend(build_overwrite_args_for_keywords(all_keywords))
        elif conditional_mode:
            args.extend(build_conditional_add_args_for_keywords(all_keywords))
        else:
            args.extend(build_remove_then_add_args_for_keywords(all_keywords))
    return args
def build_description_args(meta: SidecarData, *, conditional_mode: bool = False) -> List[str]:
    """Construit les arguments pour la description."""
    args: List[str] = []
    if not meta.description:
        return args
    safe_desc = _sanitize_description(meta.description)
    if conditional_mode:
        # Mode conditionnel : n'écrire que si absent
        args.extend(["-wm", "cg"])  # Mode append-only pour description
        args.extend([
            "-if", "not $EXIF:ImageDescription",
            f"-EXIF:ImageDescription={safe_desc}",
            "-if", "not $XMP-dc:Description", 
            f"-XMP-dc:Description={safe_desc}",
            "-if", "not $IPTC:Caption-Abstract",
            f"-IPTC:Caption-Abstract={safe_desc}"
        ])
    else:
        # Mode écrasement ou append-only simple
        args.extend([
            f"-EXIF:ImageDescription={safe_desc}",
            f"-XMP-dc:Description={safe_desc}",
            f"-IPTC:Caption-Abstract={safe_desc}"
        ])
    return args
def build_datetime_args(meta: SidecarData, use_localtime: bool, is_video: bool) -> List[str]:
    """Construit les arguments pour les dates."""
    args: List[str] = []
    # Dates
    if (s := _fmt_dt(meta.taken_at, use_localtime)):
        args.append(f"-DateTimeOriginal={s}")
        if is_video:
            args.append(f"-QuickTime:CreateDate={s}")
    base_ts = meta.created_at or meta.taken_at
    if (s := _fmt_dt(base_ts, use_localtime)):
        args.append(f"-CreateDate={s}")
        args.append(f"-ModifyDate={s}")
        if is_video:
            args.append(f"-QuickTime:ModifyDate={s}")
    return args
def build_gps_args(meta: SidecarData, is_video: bool = False) -> List[str]:
    """Construit les arguments pour GPS."""
    args: List[str] = []
    if meta.latitude is not None and meta.longitude is not None:
        args.extend([
            f"-GPS:GPSLatitude={meta.latitude}",
            f"-GPS:GPSLongitude={meta.longitude}",
            f"-GPS:GPSLatitudeRef={'N' if meta.latitude >= 0 else 'S'}",
            f"-GPS:GPSLongitudeRef={'E' if meta.longitude >= 0 else 'W'}",
        ])
        if meta.altitude is not None:
            args.append(f"-GPSAltitude={meta.altitude}")
        # Pour les vidéos, ajouter aussi Keys:Location et QuickTime:GPSCoordinates
        if is_video:
            location = f"{meta.latitude},{meta.longitude}"
            args.extend([
                f"-Keys:Location={location}",
                f"-QuickTime:GPSCoordinates={location}"
            ])
    return args
def build_rating_args(meta: SidecarData) -> List[str]:
    """Construit les arguments pour le rating."""
    args: List[str] = []
    if meta.favorite:
        args.append("-XMP:Rating=5")
    return args
def build_source_app_args(meta: SidecarData, *, conditional_mode: bool = False) -> List[str]:
    """Construit les arguments pour l'application/source d'origine (local_folder_name).
    Écrit dans les tags Software/CreatorTool pour indiquer l'application source
    (Camera, WhatsApp, Instagram, etc.) plutôt que comme album.
    """
    args: List[str] = []
    if not meta.local_folder_name:
        return args
    source_app = meta.local_folder_name.strip()
    if conditional_mode:
        # Mode conditionnel : n'écrire que si absent
        args.extend([
            "-if", "not $EXIF:Software",
            f"-EXIF:Software={source_app}",
            "-if", "not $XMP-xmp:CreatorTool", 
            f"-XMP-xmp:CreatorTool={source_app}"
        ])
    else:
        # Mode écrasement ou append-only simple
        args.extend([
            f"-EXIF:Software={source_app}",
            f"-XMP-xmp:CreatorTool={source_app}"
        ])
    return args
# === FONCTION PRINCIPALE REFACTORISÉE ===
def build_exiftool_args(meta: SidecarData, media_path: Path = None, use_localtime: bool = False, append_only: bool = True) -> list[str]:
    """Construit les arguments exiftool pour traiter un fichier média avec les métadonnées fournies.
    ARCHITECTURE EN DEUX AXES INDÉPENDANTS :
    Axe 1 — Sémantique d'écriture (3 modes) :
    - Append-only : -wm cg + -if not $TAG pour scalaires (Description, GPS, dates)
    - Robuste (nettoyage) : -TAG-=val puis -TAG+=val pour listes → zéro doublon, idempotent
    - Conditionnel (perf) : -if 'not $TAG=~/val/i' -TAG+=val → optimisation relances
    Axe 2 — Stratégie d'exécution (orthogonal) :
    - Unitaire : un appel exiftool par fichier (cette fonction)
    - Batch : un seul process avec -@ args.txt (dans processor_batch.py)
    CHOIX PAR DÉFAUT :
    - PersonInImage/Keywords : mode robuste (-=/+=) pour éviter doublons
    - Description/GPS/Dates : mode append-only (-wm cg) pour préserver existant
    - Normalisation obligatoire en amont (normalize_person_name, normalize_keyword)
    Args:
        meta: Métadonnées à écrire
        media_path: Chemin du fichier média (optionnel, pour la détection vidéo)
        use_localtime: Utiliser l'heure locale au lieu d'UTC
        append_only: Mode append-only (True) ou mode écrasement complet (False)
    Returns:
        Liste des arguments exiftool
    """
    args = []
    is_video = media_path and _is_video_file(media_path)
    if is_video:
        args.extend(["-api", "QuickTimeUTC=1"])
    if append_only:
        # Mode append-only avec approche robuste pour les listes
        # Description avec mode conditionnel (append-only)
        args.extend(build_description_args(meta, conditional_mode=True))
        # PersonInImage et Keywords avec approche robuste (supprimer-puis-ajouter)
        # IMPORTANT: Pas de -wm cg car incompatible avec -TAG-= (suppression = édition)
        args.extend(build_people_keywords_args(meta, conditional_mode=False, overwrite_mode=False))
        # Grouper tous les champs qui nécessitent -wm cg
        append_only_args = []
        # Dates
        datetime_args = build_datetime_args(meta, use_localtime, is_video)
        if datetime_args:
            append_only_args.extend(datetime_args)
        # Vidéo spécifique
        if is_video and meta.description:
            safe_desc = _sanitize_description(meta.description)
            append_only_args.append(f"-Keys:Description={safe_desc}")
        # GPS et Rating 
        gps_args = build_gps_args(meta, is_video)
        if gps_args:
            append_only_args.extend(gps_args)
        rating_args = build_rating_args(meta)
        if rating_args:
            append_only_args.extend(rating_args)
        # Application source (local_folder_name) 
        source_app_args = build_source_app_args(meta, conditional_mode=True)
        if source_app_args:
            append_only_args.extend(source_app_args)
        # Ajouter -wm cg une seule fois au début si nécessaire
        if append_only_args:
            args.extend(["-wm", "cg"])
            args.extend(append_only_args)
    else:
        # Mode écrasement : pas de -wm cg, pas de conditions
        # Description
        args.extend(build_description_args(meta, conditional_mode=False))
        # PersonInImage et Keywords (mode overwrite: vider puis ajouter)
        args.extend(build_people_keywords_args(meta, conditional_mode=False, overwrite_mode=True))
        # Dates
        args.extend(build_datetime_args(meta, use_localtime, is_video))
        # Vidéo spécifique
        if is_video and meta.description:
            safe_desc = _sanitize_description(meta.description)
            args.append(f"-Keys:Description={safe_desc}")
        # GPS
        args.extend(build_gps_args(meta, is_video))
        # Rating
        args.extend(build_rating_args(meta))
        # Application source (local_folder_name)
        args.extend(build_source_app_args(meta, conditional_mode=False))
    return args
# === FONCTIONS EXISTANTES PRÉSERVÉES ===
def _run_exiftool_command(media_path: Path, args: list[str], _append_only: bool = True) -> None:
    """Exécute une commande exiftool avec gestion d'erreurs."""
    cmd = [
        "exiftool", 
        "-overwrite_original", 
        "-charset", "filename=UTF8",
        "-charset", "iptc=UTF8",
        "-charset", "exif=UTF8", 
        "-codedcharacterset=utf8"
    ]
    if not _append_only:
        # En mode écrasement, on peut utiliser des options plus agressives
        pass
    cmd.extend(args)
    cmd.append(str(media_path))
    logger.debug(f"Commande exiftool : {' '.join(cmd)}")
    try:
        result = subprocess.run(cmd, capture_output=True, text=True, check=True, timeout=30, encoding='utf-8')
        if result.stdout.strip():
            logger.debug(f"exiftool stdout: {result.stdout.strip()}")
        if result.stderr.strip():
            logger.warning(f"exiftool stderr: {result.stderr.strip()}")
    except subprocess.CalledProcessError as e:
        # En mode append_only, le code de sortie 2 avec "files failed condition" est normal
        # (cela signifie que les métadonnées existent déjà)
        if _append_only and e.returncode == 2 and e.stdout and "files failed condition" in e.stdout:
            logger.debug(f"Mode append-only: métadonnées existantes ignorées pour {media_path}")
            return
        logger.error(f"Erreur exiftool pour {media_path}: code {e.returncode}")
        logger.error(f"stdout: {e.stdout}")
        logger.error(f"stderr: {e.stderr}")
        raise RuntimeError(f"Échec de la commande exiftool pour {media_path}: {e.stderr}")
    except subprocess.TimeoutExpired:
        logger.error(f"Timeout exiftool pour {media_path}")
        raise RuntimeError(f"Timeout exiftool pour {media_path}")
def write_metadata(media_path: Path, meta: SidecarData, use_localtime: bool = False, append_only: bool = True) -> None:
    """Écrit les métadonnées sur un média en utilisant ExifTool."""
    if append_only:
        # Mode append-only : séparer les opérations conditionnelles des opérations remove-then-add
        # 1. D'abord traiter les champs conditionnels (description, dates) avec -wm cg
        conditional_args = []
        conditional_args.extend(build_description_args(meta, conditional_mode=True))
        is_video = _is_video_file(media_path)
        if is_video:
            conditional_args.extend(["-api", "QuickTimeUTC=1"])
        datetime_args = build_datetime_args(meta, use_localtime, is_video)
        if datetime_args:
            # CORRECTION P1: Toujours ajouter -wm cg pour les timestamps en mode append-only
            # pour éviter d'écraser les valeurs existantes, même si pas de description
            conditional_args.extend(["-wm", "cg"])
            conditional_args.extend(datetime_args)
        # Vidéo spécifique (description)
        if is_video and meta.description:
            safe_desc = _sanitize_description(meta.description)
            conditional_args.append(f"-Keys:Description={safe_desc}")
        if conditional_args:
            _run_exiftool_command(media_path, conditional_args, _append_only=True)
        # 2. Ensuite traiter les personnes/keywords avec remove-then-add (sans -wm cg)
        people_args = []
        people_args.extend(build_people_keywords_args(meta, conditional_mode=False, overwrite_mode=False))
        # GPS (pas besoin de -wm cg)
        gps_args = build_gps_args(meta, is_video)
        if gps_args:
            people_args.extend(gps_args)
        # Rating
        rating_args = build_rating_args(meta)
        if rating_args:
            people_args.extend(rating_args)
        if people_args:
            _run_exiftool_command(media_path, people_args, _append_only=True)
    else:
        # Mode écrasement : utiliser build_exiftool_args directement
        all_args = build_exiftool_args(meta, media_path, use_localtime, append_only=False)
        # Exécuter en mode écrasement
        if all_args:
            _run_exiftool_command(media_path, all_args, _append_only=False)
        # En mode écrasement, pour les personnes on veut accumuler (pas écraser complètement)
        # selon les attentes du test test_explicit_overwrite_behavior
        if meta.people:
            people_args = []
            # Utiliser remove-then-add pour les personnes pour garantir l'ajout
            people_args.extend(build_remove_then_add_args_for_people(meta.people))
            # Keywords pour les personnes aussi
            normalized_people = [normalize_person_name(person) for person in meta.people]
            people_args.extend(build_remove_then_add_args_for_keywords(normalized_people))
            if people_args:
                _run_exiftool_command(media_path, people_args, _append_only=False)
# Fonctions utilitaires héritées
def _build_keywords(meta: SidecarData) -> list[str]:
    """Centralise la logique de création des mots-clés à partir des personnes, albums et dossier source."""
    keywords = (meta.people or []) + [f"Album: {a}" for a in (meta.albums or [])]
    if meta.local_folder_name:
        keywords.append(f"Album: {meta.local_folder_name}")
    return keywords
````

## File: src/google_takeout_metadata/file_organizer.py
````python
"""Module de gestion des fichiers archivés et supprimés selon les métadonnées Google Takeout."""
from __future__ import annotations
import logging
import shutil
from pathlib import Path
from typing import Optional, Tuple
from .sidecar import SidecarData
logger = logging.getLogger(__name__)
class FileOrganizer:
    """Gestionnaire pour organiser les fichiers selon leur statut archive/corbeille."""
    def __init__(self, base_directory: Path):
        """
        Initialiser l'organisateur de fichiers.
        Args:
            base_directory: Répertoire de base où créer les dossiers d'organisation
        """
        self.base_directory = Path(base_directory)
        self.archive_dir = self.base_directory / "_Archive"
        self.trash_dir = self.base_directory / "_Corbeille"
        self.locked_dir = self.base_directory / "_Verrouillé"
    def ensure_directories(self) -> None:
        """Créer les répertoires d'organisation s'ils n'existent pas."""
        self.archive_dir.mkdir(exist_ok=True)
        self.trash_dir.mkdir(exist_ok=True)
        self.locked_dir.mkdir(exist_ok=True)
        logger.debug(f"Répertoires d'organisation créés: {self.archive_dir}, {self.trash_dir}, {self.locked_dir}")
    def get_target_directory(self, meta: SidecarData) -> Optional[Path]:
        """
        Déterminer le répertoire cible selon le statut du fichier.
        Args:
            meta: Métadonnées du fichier
        Returns:
            Chemin du répertoire cible ou None si aucun déplacement nécessaire
        Règles de priorité:
        1. Si trashed=True -> Corbeille (priorité absolue)
        2. Si locked=True -> Dossier verrouillé (priorité haute)
        3. Si archived=True -> Archive  
        4. Sinon -> None (pas de déplacement)
        """
        if meta.trashed:
            return self.trash_dir
        elif meta.locked:
            return self.locked_dir
        elif meta.archived:
            return self.archive_dir
        else:
            return None
    def move_file_with_sidecar(
        self, 
        media_path: Path, 
        sidecar_path: Path, 
        meta: SidecarData
    ) -> Tuple[Optional[Path], Optional[Path]]:
        """
        Déplacer un fichier média et son sidecar selon le statut.
        Args:
            media_path: Chemin du fichier média
            sidecar_path: Chemin du fichier sidecar JSON
            meta: Métadonnées extraites du sidecar
        Returns:
            Tuple (nouveau_chemin_media, nouveau_chemin_sidecar) ou (None, None) si pas de déplacement
        Raises:
            OSError: En cas d'erreur de déplacement
        """
        target_dir = self.get_target_directory(meta)
        if target_dir is None:
            # Pas de déplacement nécessaire
            return None, None
        # Créer les répertoires si nécessaire
        self.ensure_directories()
        # Calculer les nouveaux chemins
        new_media_path = target_dir / media_path.name
        new_sidecar_path = target_dir / sidecar_path.name
        # Gérer les conflits de noms
        new_media_path = self._resolve_name_conflict(new_media_path)
        new_sidecar_path = self._resolve_name_conflict(new_sidecar_path)
        try:
            # Déplacer le fichier média
            if media_path.exists():
                shutil.move(str(media_path), str(new_media_path))
                logger.info(f"📁 Déplacé vers {target_dir.name}: {media_path.name} → {new_media_path.name}")
            else:
                new_media_path = None
                logger.warning(f"Fichier média introuvable pour déplacement: {media_path}")
            # Déplacer le sidecar
            if sidecar_path.exists():
                shutil.move(str(sidecar_path), str(new_sidecar_path))
                logger.debug(f"Sidecar déplacé: {sidecar_path.name} → {new_sidecar_path.name}")
            else:
                new_sidecar_path = None
                logger.warning(f"Sidecar introuvable pour déplacement: {sidecar_path}")
            return new_media_path, new_sidecar_path
        except (OSError, shutil.Error) as e:
            logger.error(f"Erreur lors du déplacement de {media_path.name}: {e}")
            raise
    def _resolve_name_conflict(self, target_path: Path) -> Path:
        """
        Résoudre les conflits de noms en ajoutant un suffixe numérique.
        Args:
            target_path: Chemin cible souhaité
        Returns:
            Chemin disponible (avec suffixe si nécessaire)
        """
        if not target_path.exists():
            return target_path
        # Générer un nom alternatif avec suffixe numérique
        stem = target_path.stem
        suffix = target_path.suffix
        parent = target_path.parent
        counter = 1
        while True:
            new_name = f"{stem}_{counter}{suffix}"
            new_path = parent / new_name
            if not new_path.exists():
                logger.debug(f"Conflit de nom résolu: {target_path.name} → {new_name}")
                return new_path
            counter += 1
            # Sécurité: éviter les boucles infinies
            if counter > 1000:
                raise OSError(f"Impossible de résoudre le conflit de nom pour {target_path}")
def should_organize_file(meta: SidecarData) -> bool:
    """
    Vérifier si un fichier doit être organisé selon son statut.
    Args:
        meta: Métadonnées du fichier
    Returns:
        True si le fichier doit être déplacé
    """
    return meta.trashed or meta.archived or meta.locked
def get_organization_status(meta: SidecarData) -> str:
    """
    Obtenir le statut d'organisation d'un fichier.
    Args:
        meta: Métadonnées du fichier
    Returns:
        String décrivant le statut ("trashed", "archived", "locked", "normal")
    """
    if meta.trashed:
        return "trashed"
    elif meta.archived:
        return "archived"
    elif meta.locked:
        return "locked"
    else:
        return "normal"
````

## File: src/google_takeout_metadata/processor_batch.py
````python
import logging
import subprocess
import tempfile
from pathlib import Path
from typing import List, Tuple
from datetime import datetime
from .exif_writer import build_exiftool_args
from .sidecar import find_albums_for_directory, parse_sidecar
from .processor import IMAGE_EXTS, fix_file_extension_mismatch, _is_sidecar_file 
from . import sidecar_safety
from . import statistics
from .file_organizer import FileOrganizer
logger = logging.getLogger(__name__)
def process_batch(batch: List[Tuple[Path, Path, List[str]]], immediate_delete: bool) -> int:
    """Traiter un lot de fichiers avec exiftool via un fichier d'arguments."""
    if not batch:
        return 0
    argfile_path = None
    try:
        with tempfile.NamedTemporaryFile(mode='w', delete=False, encoding='utf-8', suffix=".txt") as argfile:
            argfile_path = argfile.name
        with open(argfile_path, 'w', encoding='utf-8') as argfile:
            for media_path, _, args in batch:
                for arg in args:
                    argfile.write(f"{arg}\n")
                argfile.write(f"{media_path}\n")
                argfile.write("-execute\n")
        logger.info(f"📦 Traitement d'un lot de {len(batch)} fichier(s)...")
        # ✅ IMPLÉMENTATION -efile pour journalisation et reprises intelligentes
        cmd = [
            "exiftool",
            # Charset settings MUST come before -@ for proper ExifTool behavior.
            "-charset", "filename=UTF8",    # For Unicode filenames (must be before -@)
            "-charset", "iptc=UTF8",        # For IPTC writing
            "-charset", "exif=UTF8",        # For EXIF writing
            "-codedcharacterset=utf8",      # For IPTC encoding (must be before -@)
            "-@", argfile_path,
            "-common_args",                 # After -@ : applied to each block
            "-overwrite_original",
            "-q", "-q",
            "-api", "NoDups=1",            # For intra-batch deduplication
            "-efile1", "error_files.txt",     # errors = 1
            "-efile2", "unchanged_files.txt", # unchanged = 2  
            "-efile4", "failed_condition_files.txt", # failed -if condition = 4
            "-efile8", "updated_files.txt"    # updated = 8
        ]
        timeout_seconds = 60 + (len(batch) * 5)
        result = subprocess.run(
            cmd, capture_output=True, text=True, check=True, timeout=timeout_seconds, encoding='utf-8'
        )
        # Analyser la sortie pour compter les fichiers traités
        processed_count = 0
        if result.stdout and result.stdout.strip():
            stdout_lines = result.stdout.strip().split('\n')
            for line in stdout_lines:
                if 'image files updated' in line.lower() or 'files updated' in line.lower():
                    # Extraire le nombre de fichiers mis à jour
                    try:
                        numbers = [int(word) for word in line.split() if word.isdigit()]
                        if numbers:
                            processed_count = numbers[0]
                    except (ValueError, IndexError):
                        pass
                    logger.info(f"✅ {line.strip()}")
        # Si on n'a pas pu extraire le nombre, utiliser la taille du lot
        if processed_count == 0:
            processed_count = len(batch)
            logger.info(f"✅ Lot de {len(batch)} fichier(s) traité avec succès")
        # Mettre à jour les statistiques pour chaque fichier du lot
        for media_path, _, _ in batch:
            is_image = media_path.suffix.lower() in IMAGE_EXTS
            statistics.stats.add_processed_file(is_image)
        # Gestion des sidecars après traitement réussi
        if immediate_delete:
            # Mode destructeur : suppression immédiate
            cleaned_count = 0
            for _, json_path, _ in batch:
                try:
                    json_path.unlink()
                    cleaned_count += 1
                except OSError as e:
                    logger.warning(f"Échec de la suppression du fichier de métadonnées {json_path.name}: {e}")
            statistics.stats.sidecars_cleaned += cleaned_count
        else:
            # Mode sécurisé : marquage avec préfixe OK_
            marked_count = 0
            for _, json_path, _ in batch:
                try:
                    if sidecar_safety.mark_sidecar_as_processed(json_path):
                        marked_count += 1
                except OSError as e:
                    logger.warning(f"Échec du marquage du sidecar {json_path.name}: {e}")
            statistics.stats.sidecars_cleaned += marked_count  # Réutilise le compteur pour "traités"
        return len(batch)
    except FileNotFoundError as exc:
        raise RuntimeError("exiftool introuvable") from exc
    except subprocess.CalledProcessError as exc:
        stderr_msg = exc.stderr or ""
        stdout_msg = exc.stdout or ""
        # Analyser le type d'erreur pour donner un message plus clair
        if "files failed condition" in stderr_msg or "files failed condition" in stdout_msg:
            logger.info(f"ℹ️ Lot traité avec conditions non remplies (normal en mode append-only). "
                       f"Certaines métadonnées existaient déjà pour {len(batch)} fichier(s).")
            # En mode append-only, considérer ceci comme un succès partiel
            for media_path, _, _ in batch:
                is_image = media_path.suffix.lower() in IMAGE_EXTS
                statistics.stats.add_processed_file(is_image)
            # Nettoyer les sidecars si demandé (comme dans le cas de succès normal)
            if immediate_delete:
                cleaned_count = 0
                for _, json_path, _ in batch:
                    try:
                        json_path.unlink()
                        cleaned_count += 1
                    except OSError as e:
                        logger.warning(f"Échec de la suppression du fichier de métadonnées {json_path.name}: {e}")
                statistics.stats.sidecars_cleaned += cleaned_count
            else:
                # Mode sécurisé : marquage avec préfixe OK_
                marked_count = 0
                for _, json_path, _ in batch:
                    try:
                        if sidecar_safety.mark_sidecar_as_processed(json_path):
                            marked_count += 1
                    except OSError as e:
                        logger.warning(f"Échec du marquage du sidecar {json_path.name}: {e}")
                statistics.stats.sidecars_cleaned += marked_count
            return len(batch)
        elif "doesn't exist or isn't writable" in stderr_msg:
            logger.warning(f"⚠️ Certains champs de métadonnées non supportés par les fichiers du lot. "
                          f"Normal pour vidéos ou certains formats. Détails: {stderr_msg.strip()}")
            # Considérer comme un succès partiel
            for media_path, _, _ in batch:
                is_image = media_path.suffix.lower() in IMAGE_EXTS  
                statistics.stats.add_processed_file(is_image)
            # Nettoyer les sidecars si demandé (comme dans le cas de succès normal)
            if immediate_delete:
                cleaned_count = 0
                for _, json_path, _ in batch:
                    try:
                        json_path.unlink()
                        cleaned_count += 1
                    except OSError as e:
                        logger.warning(f"Échec de la suppression du fichier de métadonnées {json_path.name}: {e}")
                statistics.stats.sidecars_cleaned += cleaned_count
            else:
                # Mode sécurisé : marquage avec préfixe OK_
                marked_count = 0
                for _, json_path, _ in batch:
                    try:
                        if sidecar_safety.mark_sidecar_as_processed(json_path):
                            marked_count += 1
                    except OSError as e:
                        logger.warning(f"Échec du marquage du sidecar {json_path.name}: {e}")
                statistics.stats.sidecars_cleaned += marked_count
            return len(batch)
        elif "character(s) could not be encoded" in stderr_msg:
            error_type = "encoding_error"
            error_msg = "Problème d'encodage de caractères (émojis, accents)"
            logger.warning(f"⚠️ {error_msg}. Détails: {stderr_msg.strip()}")
        else:
            error_type = "exiftool_error"
            error_msg = f"Erreur exiftool (code {exc.returncode}): {stderr_msg.strip() or 'Erreur inconnue'}"
            logger.exception(f"❌ Échec du traitement par lot de {len(batch)} fichier(s). {error_msg}")
        # Marquer tous les fichiers du lot comme échoués
        for media_path, _, _ in batch:
            statistics.stats.add_failed_file(media_path, error_type, error_msg)
        # NE PAS nettoyer les sidecars en cas d'échec exiftool - les garder pour retry
        # LOGIQUE MÉTIER: On ne supprime le sidecar QUE si le traitement a réussi
        return 0
    finally:
        if argfile_path and Path(argfile_path).exists():
            Path(argfile_path).unlink()
def process_directory_batch(root: Path, use_localtime: bool = False, append_only: bool = True, immediate_delete: bool = False, organize_files: bool = False) -> None:
    """Traiter récursivement tous les fichiers sidecar sous ``root`` par lots.
    Args:
        root: Répertoire racine à parcourir
        use_localtime: Convertir les dates en heure locale au lieu d'UTC
        append_only: Ajouter uniquement les champs manquants
        immediate_delete: Mode destructeur - supprimer immédiatement les JSON après succès
                         (par défaut: mode sécurisé avec préfixe OK_)
        organize_files: Organiser les fichiers selon leur statut (archivé/supprimé/vérouillé)
    """
    batch: List[Tuple[Path, Path, List[str]]] = []
    BATCH_SIZE = 100
    # Initialiser les statistiques
    statistics.stats.start_processing()
    # Initialiser l'organisateur de fichiers si demandé
    file_organizer = None
    if organize_files:
        file_organizer = FileOrganizer(root)
        logger.info("📁 Mode organisation activé : les fichiers seront organisés selon leur statut")
    # Exclure les sidecars déjà traités (préfixe OK_)
    all_sidecar_files = [path for path in root.rglob("*.json") if _is_sidecar_file(path)]
    sidecar_files = [path for path in all_sidecar_files if not sidecar_safety.is_sidecar_processed(path)]
    # Afficher les statistiques de filtrage et les comptabiliser
    processed_count = len(all_sidecar_files) - len(sidecar_files)
    if processed_count > 0:
        logger.info("📋 %d sidecars déjà traités ignorés (préfixe OK_)", processed_count)
        # Ajouter les fichiers déjà traités aux statistiques
        for path in all_sidecar_files:
            if sidecar_safety.is_sidecar_processed(path):
                statistics.stats.add_skipped_file(path, "Déjà traité (préfixe OK_)")
    statistics.stats.total_sidecars_found = len(sidecar_files)
    if statistics.stats.total_sidecars_found == 0:
        logger.warning("Aucun fichier de métadonnées (.json) trouvé dans %s", root)
        statistics.stats.end_processing()
        return
    logger.info("🔍 Traitement par lots de %d fichier(s) de métadonnées dans %s", statistics.stats.total_sidecars_found, root)
    for json_path in sidecar_files:
        try:
            meta = parse_sidecar(json_path)
            directory_albums = find_albums_for_directory(json_path.parent)
            meta.albums.extend(directory_albums)
            media_path = json_path.with_name(meta.filename)
            if not media_path.exists():
                error_msg = f"Fichier image introuvable : {meta.filename}"
                statistics.stats.add_failed_file(json_path, "file_not_found", error_msg)
                logger.warning(f"❌ {error_msg}")
                continue
            fixed_media_path, fixed_json_path = fix_file_extension_mismatch(media_path, json_path)
            if fixed_json_path != json_path:
                meta = parse_sidecar(fixed_json_path)
                meta.albums.extend(find_albums_for_directory(fixed_json_path.parent))
            # Organisation des fichiers si demandée
            if file_organizer and (meta.archived or meta.trashed or meta.locked):
                try:
                    moved_media, moved_json = file_organizer.move_file_with_sidecar(fixed_media_path, fixed_json_path, meta)
                    if moved_media and moved_json:
                        # Mettre à jour les chemins pour la suite du traitement
                        fixed_media_path = moved_media
                        fixed_json_path = moved_json
                        logger.info(f"📁 Fichier organisé : {media_path.name} → {moved_media.parent.name}/")
                except Exception as e:
                    logger.warning(f"⚠️ Échec de l'organisation du fichier {media_path.name}: {e}")
            args = build_exiftool_args(
                meta, media_path=fixed_media_path, use_localtime=use_localtime, append_only=append_only
            )
            if args:
                batch.append((fixed_media_path, fixed_json_path, args))
            else:
                # Aucun tag à écrire pour ce sidecar
                statistics.stats.total_skipped += 1
                statistics.stats.skipped_files.append(json_path.name)
            if len(batch) >= BATCH_SIZE:
                process_batch(batch, immediate_delete)
                batch = []
        except (ValueError, RuntimeError) as exc:
            error_msg = f"Erreur de préparation : {exc}"
            statistics.stats.add_failed_file(json_path, "preparation_error", error_msg)
            logger.warning("❌ Échec de la préparation de %s : %s", json_path.name, exc)
    if batch:
        process_batch(batch, immediate_delete)
    statistics.stats.end_processing()
    # Affichage du résumé
    statistics.stats.print_console_summary()
    # Générer les scripts de sécurité si des sidecars ont été traités (mode sécurisé uniquement)
    if not immediate_delete and statistics.stats.sidecars_cleaned > 0:
        logger.info("\n🔐 === SYSTÈME DE SÉCURITÉ ===")
        # Générer les scripts
        cleanup_script = sidecar_safety.generate_cleanup_script(root)
        rollback_script = sidecar_safety.generate_rollback_script(root)
        if cleanup_script and rollback_script:
            logger.info("📜 Scripts de gestion générés :")
            logger.info("   • Nettoyage : %s", cleanup_script)
            logger.info("   • Rollback  : %s", rollback_script)
            logger.info("")
            logger.info("⚠️  Les sidecars traités ont été marqués avec le préfixe 'OK_'")
            logger.info("   Vérifiez le traitement puis utilisez les scripts pour:")
            logger.info("   1. Supprimer définitivement les sidecars traités (cleanup)")
            logger.info("   2. Restaurer les noms originaux en cas d'erreur (rollback)")
        # Afficher le résumé de sécurité
        nb_processed, nb_pending, messages = sidecar_safety.generate_scripts_summary(root)
        for message in messages:
            logger.info(message)
    # Créer un dossier logs s'il n'existe pas
    logs_dir = root / "logs"
    logs_dir.mkdir(exist_ok=True)
    # Sauvegarde du rapport détaillé avec un nom incluant la date
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    log_file = logs_dir / f"traitement_log_{timestamp}.json"
    statistics.stats.save_detailed_report(log_file)
````

## File: src/google_takeout_metadata/processor.py
````python
"""Traitement de haut niveau des répertoires contenant des métadonnées Google Takeout."""
from __future__ import annotations
from pathlib import Path
import logging
import json
import subprocess
import shutil
from datetime import datetime
from .sidecar import parse_sidecar, find_albums_for_directory
from .exif_writer import write_metadata
from . import sidecar_safety
from . import statistics
from .file_organizer import FileOrganizer, should_organize_file
logger = logging.getLogger(__name__)
# Séparer les extensions images et vidéos pour une meilleure cohérence
IMAGE_EXTS = {".jpg", ".jpeg", ".png", ".gif", ".webp", ".heic", ".heif", ".avif"}
VIDEO_EXTS = {".mp4", ".mov", ".m4v", ".3gp"}
ALL_MEDIA_EXTS = IMAGE_EXTS | VIDEO_EXTS
def detect_file_type(file_path: Path) -> str | None:
    """Détecter le type réel du fichier via la commande ``file`` ou les octets magiques.
    Retourne:
        L'extension correcte (avec point) ou ``None`` si la détection échoue
    """
    try:
        # Essayer d'abord la commande ``file`` (disponible sur la plupart des systèmes)
        result = subprocess.run(
            ["file", str(file_path)], 
            capture_output=True, 
            text=True, 
            timeout=10
        )
        if result.returncode == 0:
            output = result.stdout.lower()
            if "jpeg" in output or "jfif" in output:
                return ".jpg"
            elif "png" in output:
                return ".png"
            elif "gif" in output:
                return ".gif"
            elif "webp" in output:
                return ".webp"
            elif "heic" in output:
                return ".heic"
            elif "heif" in output:
                return ".heif"
            elif "mp4" in output:
                return ".mp4"
            elif "quicktime" in output or "mov" in output:
                return ".mov"
    except (subprocess.TimeoutExpired, subprocess.CalledProcessError, FileNotFoundError):
        pass
    # Repli : lecture des octets magiques
    try:
        with open(file_path, "rb") as f:
            header = f.read(16)
            if header.startswith(b'\xff\xd8\xff'):
                return ".jpg"
            elif header.startswith(b'\x89PNG\r\n\x1a\n'):
                return ".png"
            elif header.startswith(b'GIF8'):
                return ".gif"
            elif header.startswith(b'RIFF') and b'WEBP' in header:
                return ".webp"
            elif header[4:8] == b'ftyp':
                if b'heic' in header[:16] or b'mif1' in header[:16]:
                    return ".heic"
                elif b'mp4' in header[:16] or b'isom' in header[:16]:
                    return ".mp4"
    except (OSError, IOError):
        pass
    return None
def fix_file_extension_mismatch(media_path: Path, json_path: Path) -> tuple[Path, Path]:
    """Corriger une incohérence d'extension en renommant les fichiers et en mettant à jour le JSON.
    Args:
        media_path: Chemin du fichier image/vidéo
        json_path: Chemin du fichier JSON associé (sidecar)
    Retourne:
        Un tuple ``(new_media_path, new_json_path)``
    """
    # Détecter le type réel du fichier
    actual_ext = detect_file_type(media_path)
    if not actual_ext or actual_ext == media_path.suffix.lower():
        # Aucune incohérence détectée ou la détection a échoué
        return media_path, json_path
    # Créer de nouveaux chemins avec la bonne extension
    new_media_path = media_path.with_suffix(actual_ext)
    new_json_path = json_path.with_name(new_media_path.name + ".supplemental-metadata.json")
    logger.info("🔧 Extension incorrecte détectée pour %s (devrait être %s). Correction automatique...", 
                media_path.name, actual_ext)
    image_renamed = False
    try:
        # Renommer le fichier image
        media_path.rename(new_media_path)
        image_renamed = True
        logger.info("✅ Fichier renommé : %s → %s", media_path.name, new_media_path.name)
        # Mettre à jour le contenu JSON et renommer le fichier JSON
        with open(json_path, 'r', encoding='utf-8') as f:
            json_data = json.load(f)
        # Mettre à jour le champ title
        json_data['title'] = new_media_path.name
        # Écrire le JSON mis à jour au nouvel emplacement
        with open(new_json_path, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, indent=2, ensure_ascii=False)
        # Supprimer l'ancien fichier JSON
        json_path.unlink()
        logger.info("✅ Métadonnées mises à jour : %s → %s", json_path.name, new_json_path.name)
        # Enregistrer la correction dans les statistiques
        statistics.stats.add_fixed_extension(media_path.name, new_media_path.name)
        return new_media_path, new_json_path
    except (OSError, IOError, json.JSONDecodeError) as exc:
        logger.warning("❌ Échec de la correction d'extension pour %s : %s. "
                       "Le fichier sera traité avec son extension actuelle.", media_path.name, exc)
        # Si l'image a été renommée mais que des étapes ultérieures échouent, tenter un rollback
        if image_renamed:
            try:
                # Supprimer tout nouveau JSON éventuellement créé
                if new_json_path.exists():
                    new_json_path.unlink()
                    logger.info("🔄 Fichier JSON partiellement créé supprimé : %s", new_json_path.name)
                # Renommer l'image avec son nom d'origine
                new_media_path.rename(media_path)
                logger.info("🔄 Annulation du renommage : %s → %s", new_media_path.name, media_path.name)
                return media_path, json_path
            except (OSError, IOError) as rollback_exc:
                logger.exception("❌ Échec de l'annulation du renommage %s → %s : %s. "
                           "ATTENTION : État incohérent - fichier image renommé mais JSON non mis à jour.", 
                           new_media_path.name, media_path.name, rollback_exc)
                # Retourner les nouveaux chemins afin de refléter l'état courant
                return new_media_path, json_path
        return media_path, json_path
def _is_sidecar_file(path: Path) -> bool:
    """Vérifier si un fichier peut être un JSON annexe (Google Photos).
    Cette fonction est permissive car ``parse_sidecar()`` fait une
    validation stricte en comparant le champ ``title`` avec le nom attendu.
    Formats supportés :
    - Nouveau format : photo.jpg.supplemental-metadata.json
    - Ancien format : photo.jpg.json
    """
    if not path.suffix.lower() == ".json":
        return False
    suffixes = [s.lower() for s in path.suffixes]
    # Nouveau format Google Takeout : photo.jpg.supplemental-metadata.json
    if len(suffixes) >= 3 and suffixes[-2] == ".supplemental-metadata" and suffixes[-3] in ALL_MEDIA_EXTS:
        return True
    # Format hérité : photo.jpg.json
    if len(suffixes) >= 2 and suffixes[-2] in ALL_MEDIA_EXTS:
        return True
    # Format plus ancien : photo.json (moins spécifique mais validé ultérieurement)
    # Ne considérer ceci que si le nom de base sans .json pourrait être une image
    stem_parts = path.stem.split('.')
    if len(stem_parts) >= 2:
        potential_ext = '.' + stem_parts[-1].lower()
        if potential_ext in ALL_MEDIA_EXTS:
            return True
    return False
def process_sidecar_file(json_path: Path, use_localtime: bool = False, append_only: bool = True, immediate_delete: bool = False, organize_files: bool = False) -> None:
    """Traiter un fichier annexe ``.json``.
    Args:
        json_path: Chemin du fichier JSON annexe
        use_localtime: Convertir les dates en heure locale au lieu d'UTC
        append_only: Ajouter uniquement les champs manquants
        immediate_delete: Mode destructeur - supprimer immédiatement le JSON après succès 
                         (par défaut: mode sécurisé avec préfixe OK_)
        organize_files: Organiser les fichiers selon leur statut (archivé/supprimé)
    """
    # Vérifier si ce sidecar a déjà été traité (préfixe OK_)
    if sidecar_safety.is_sidecar_processed(json_path):
        logger.debug("Sidecar déjà traité, ignoré: %s", json_path)
        statistics.stats.add_skipped_file(json_path, "Déjà traité (préfixe OK_)")
        return
    try:
        meta = parse_sidecar(json_path)
    except ValueError as exc:
        statistics.stats.add_failed_file(json_path, "parse_error", f"Erreur de lecture JSON : {exc}")
        raise
    # Trouver les albums du répertoire
    directory_albums = find_albums_for_directory(json_path.parent)
    meta.albums.extend(directory_albums)
    media_path = json_path.with_name(meta.filename)
    if not media_path.exists():
        error_msg = f"Fichier image introuvable : {meta.filename}"
        statistics.stats.add_failed_file(json_path, "file_not_found", error_msg)
        raise FileNotFoundError(error_msg)
    # Détecter le type de fichier (image ou vidéo)
    is_image = media_path.suffix.lower() in IMAGE_EXTS
    # Tenter d'écrire les métadonnées dans l'image
    try:
        write_metadata(media_path, meta, use_localtime=use_localtime, append_only=append_only)
        current_json_path = json_path
        # Enregistrer le succès
        statistics.stats.add_processed_file(is_image)
        # Organisation des fichiers selon leur statut (si activée)
        if organize_files and should_organize_file(meta):
            try:
                organizer = FileOrganizer(media_path.parent)
                new_media_path, new_sidecar_path = organizer.move_file_with_sidecar(
                    media_path, current_json_path, meta
                )
                # Mettre à jour les chemins si déplacement effectué
                if new_media_path and new_sidecar_path:
                    media_path = new_media_path
                    current_json_path = new_sidecar_path
                    logger.info(f"📁 Fichier organisé selon statut: {meta.filename}")
            except (OSError, shutil.Error) as exc:
                logger.warning(f"Échec de l'organisation du fichier {media_path.name}: {exc}")
                # Continuer le traitement même si l'organisation échoue
    except RuntimeError as exc:
        # Vérifier s'il s'agit d'une erreur d'incohérence d'extension
        error_msg = str(exc).lower()
        if ("not a valid png" in error_msg and "looks more like a jpeg" in error_msg) or \
           ("not a valid jpeg" in error_msg and "looks more like a png" in error_msg) or \
           ("charset option" in error_msg):
            logger.info("🔍 Extension possiblement incorrecte pour %s. Tentative de correction...", media_path.name)
            # Tenter de corriger l'incohérence d'extension
            fixed_media_path, fixed_json_path = fix_file_extension_mismatch(media_path, json_path)
            if fixed_media_path != media_path or fixed_json_path != json_path:
                # Les fichiers ont été renommés (au moins partiellement), re-analyser le JSON et réessayer
                # Gérer le cas où l'image a été renommée mais pas le JSON (échec de rollback partiel)
                is_image_after_fix = fixed_media_path.suffix.lower() in IMAGE_EXTS
                actual_json_path = fixed_json_path if fixed_json_path.exists() else json_path
                meta = parse_sidecar(actual_json_path)
                directory_albums = find_albums_for_directory(actual_json_path.parent)
                meta.albums.extend(directory_albums)
                write_metadata(fixed_media_path, meta, use_localtime=use_localtime, append_only=append_only)
                current_json_path = actual_json_path
                # Enregistrer le succès après correction
                statistics.stats.add_processed_file(is_image_after_fix)
                logger.info("✅ Traitement réussi de %s après correction d'extension", fixed_media_path.name)
            else:
                # Échec de la correction d'extension, relancer l'erreur originale
                statistics.stats.add_failed_file(media_path, "extension_mismatch", str(exc))
                raise
        else:
            # Ce n'est pas une erreur d'incohérence d'extension, relancer
            statistics.stats.add_failed_file(media_path, "metadata_write_error", str(exc))
            raise
    # Gestion du sidecar après succès
    if immediate_delete:
        # Mode destructeur : suppression immédiate (ancien comportement)
        try:
            current_json_path.unlink()
            statistics.stats.sidecars_cleaned += 1
            logger.info("🗑️ Fichier de métadonnées supprimé : %s", current_json_path.name)
        except OSError as exc:
            logger.warning("Échec de la suppression du fichier de métadonnées %s : %s", current_json_path, exc)
    else:
        # Mode sécurisé : marquage avec préfixe OK_ (nouveau comportement par défaut)
        try:
            if sidecar_safety.mark_sidecar_as_processed(current_json_path):
                statistics.stats.sidecars_cleaned += 1  # Compteur réutilisé pour les "traités"
                logger.info("✅ Sidecar marqué comme traité : %s", current_json_path.name)
        except OSError as exc:
            logger.warning("Échec du marquage du sidecar %s : %s", current_json_path, exc)
def process_directory(root: Path, use_localtime: bool = False, append_only: bool = True, immediate_delete: bool = False, organize_files: bool = False) -> None:
    """Traiter récursivement tous les fichiers annexes sous ``root``.
    Args:
        root: Répertoire racine à parcourir récursivement
        use_localtime: Convertir les dates en heure locale au lieu d'UTC
        append_only: Ajouter uniquement les champs manquants
        immediate_delete: Mode destructeur - supprimer immédiatement les JSON après succès
                         (par défaut: mode sécurisé avec préfixe OK_)
        organize_files: Organiser les fichiers selon leur statut (archivé/supprimé)
    """
    # Initialiser les statistiques
    statistics.stats.start_processing()
    # Exclure les sidecars déjà traités (préfixe OK_)
    all_json_files = [path for path in root.rglob("*.json") if _is_sidecar_file(path)]
    sidecar_files = [path for path in all_json_files if not sidecar_safety.is_sidecar_processed(path)]
    # Afficher les statistiques de filtrage et les comptabiliser
    processed_count = len(all_json_files) - len(sidecar_files)
    if processed_count > 0:
        logger.info("📋 %d sidecars déjà traités ignorés (préfixe OK_)", processed_count)
        # Ajouter les fichiers déjà traités aux statistiques
        for path in all_json_files:
            if sidecar_safety.is_sidecar_processed(path):
                statistics.stats.add_skipped_file(path, "Déjà traité (préfixe OK_)")
    statistics.stats.total_sidecars_found = len(sidecar_files)
    if statistics.stats.total_sidecars_found == 0:
        logger.warning("Aucun fichier de métadonnées (.json) trouvé dans %s", root)
        statistics.stats.end_processing()
        return
    logger.info("🔍 Traitement de %d fichier(s) de métadonnées dans %s", statistics.stats.total_sidecars_found, root)
    for json_file in sidecar_files:
        try:
            process_sidecar_file(json_file, use_localtime=use_localtime, append_only=append_only, immediate_delete=immediate_delete, organize_files=organize_files)
        except (FileNotFoundError, ValueError, RuntimeError) as exc:
            logger.warning("❌ Échec du traitement de %s : %s", json_file.name, exc)
            # Les statistiques sont déjà mises à jour dans process_sidecar_file
    statistics.stats.end_processing()
    # Affichage du résumé
    statistics.stats.print_console_summary()
    # Générer les scripts de sécurité si des sidecars ont été traités (mode sécurisé uniquement)
    if not immediate_delete and statistics.stats.sidecars_cleaned > 0:
        logger.info("\n🔐 === SYSTÈME DE SÉCURITÉ ===")
        # Générer les scripts
        cleanup_script = sidecar_safety.generate_cleanup_script(root)
        rollback_script = sidecar_safety.generate_rollback_script(root)
        if cleanup_script and rollback_script:
            logger.info("📜 Scripts de gestion générés :")
            logger.info("   • Nettoyage : %s", cleanup_script)
            logger.info("   • Rollback  : %s", rollback_script)
            logger.info("")
            logger.info("⚠️  Les sidecars traités ont été marqués avec le préfixe 'OK_'")
            logger.info("   Vérifiez le traitement puis utilisez les scripts pour:")
            logger.info("   1. Supprimer définitivement les sidecars traités (cleanup)")
            logger.info("   2. Restaurer les noms originaux en cas d'erreur (rollback)")
        # Afficher le résumé de sécurité
        nb_processed, nb_pending, messages = sidecar_safety.generate_scripts_summary(root)
        for message in messages:
            logger.info(message)
    # Créer un dossier logs s'il n'existe pas
    logs_dir = root / "logs"
    logs_dir.mkdir(exist_ok=True)
    # Sauvegarde du rapport détaillé avec un nom incluant la date
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    log_file = logs_dir / f"traitement_log_{timestamp}.json"
    statistics.stats.save_detailed_report(log_file)
````

## File: src/google_takeout_metadata/resume_handler.py
````python
# Fichier : src/google_takeout_metadata/resume_handler.py
import logging
from pathlib import Path
from typing import List, Tuple
logger = logging.getLogger(__name__)
def should_resume(output_dir: Path) -> bool:
    """Détecter si des fichiers de log -efile existent pour une reprise.
    Args:
        output_dir: Répertoire à vérifier pour les logs -efile
    Returns:
        True si des logs -efile existent et qu'une reprise est possible
    """
    log_files = [
        "error_files.txt",
        "unchanged_files.txt", 
        "failed_condition_files.txt",
        "updated_files.txt"
    ]
    return any((output_dir / log_file).exists() for log_file in log_files)
def parse_efile_logs(output_dir: Path) -> Tuple[List[Path], List[Path], List[Path], List[Path]]:
    """Parser les logs -efile pour extraire les listes de fichiers.
    Args:
        output_dir: Répertoire contenant les logs -efile
    Returns:
        Tuple de (error_files, updated_files, unchanged_files, failed_condition_files)
    """
    error_files = _read_file_list(output_dir / "error_files.txt")
    updated_files = _read_file_list(output_dir / "updated_files.txt") 
    unchanged_files = _read_file_list(output_dir / "unchanged_files.txt")
    failed_condition_files = _read_file_list(output_dir / "failed_condition_files.txt")
    logger.info(f"📊 Analyse des logs -efile: {len(error_files)} erreurs, "
                f"{len(updated_files)} mis à jour, {len(unchanged_files)} inchangés, "
                f"{len(failed_condition_files)} conditions échouées")
    return error_files, updated_files, unchanged_files, failed_condition_files
def build_resume_batch(error_files: List[Path], unchanged_files: List[Path] = None, resume_mode: str = "errors") -> List[Path]:
    """Construire un lot de reprise à partir des logs -efile.
    Args:
        error_files: Liste des fichiers en erreur
        unchanged_files: Liste des fichiers inchangés (optionnel)
        resume_mode: Mode de reprise ("errors" ou "all")
    Returns:
        Liste des fichiers à retraiter
    """
    files_to_resume = error_files.copy()  # Toujours reprendre les erreurs
    if resume_mode == "all" and unchanged_files:
        files_to_resume.extend(unchanged_files)  # Reprendre aussi les inchangés si policy modifiée
        logger.info(f"🔄 Mode reprise complète: {len(files_to_resume)} fichiers à retraiter")
    else:
        logger.info(f"🔄 Mode reprise erreurs: {len(files_to_resume)} fichiers à retraiter")
    return files_to_resume
def _read_file_list(log_file: Path) -> List[Path]:
    """Lire une liste de fichiers depuis un log -efile.
    Args:
        log_file: Fichier de log à lire
    Returns:
        Liste des chemins de fichiers trouvés dans le log
    """
    if not log_file.exists():
        return []
    files = []
    try:
        with open(log_file, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#'):  # Ignorer les commentaires
                    files.append(Path(line))
    except Exception as e:
        logger.warning(f"⚠️ Erreur lors de la lecture de {log_file}: {e}")
    return files
def cleanup_efile_logs(output_dir: Path) -> None:
    """Nettoyer les anciens logs -efile après un traitement réussi.
    Args:
        output_dir: Répertoire contenant les logs à nettoyer
    """
    log_files = [
        "error_files.txt",
        "unchanged_files.txt", 
        "failed_condition_files.txt",
        "updated_files.txt"
    ]
    cleaned = 0
    for log_file in log_files:
        log_path = output_dir / log_file
        if log_path.exists():
            try:
                log_path.unlink()
                cleaned += 1
            except Exception as e:
                logger.warning(f"⚠️ Impossible de nettoyer {log_file}: {e}")
    if cleaned > 0:
        logger.info(f"🧹 {cleaned} fichiers de log -efile nettoyés")
````

## File: src/google_takeout_metadata/sidecar_safety.py
````python
"""
Système de sas de sécurité pour les sidecars JSON.
Ce module implémente un mécanisme de sécurité pour éviter la suppression immédiate
des fichiers sidecar JSON après traitement. Au lieu de supprimer, on renomme
avec un préfixe 'OK_' pour permettre vérification manuelle et rollback.
Workflow:
1. Succès ExifTool → Sidecar renommé avec préfixe 'OK_'
2. Échec ExifTool → Sidecar conservé (pour retry ultérieur)
3. Génération de scripts de nettoyage/rollback pour l'utilisateur
"""
import logging
import os
from pathlib import Path
from typing import List, Tuple, Set
import platform
logger = logging.getLogger(__name__)
# Préfixe pour marquer les sidecars traités avec succès
PROCESSED_PREFIX = "OK_"
def mark_sidecar_as_processed(json_path: Path) -> bool:
    """
    Renomme un sidecar JSON avec le préfixe OK_ pour indiquer qu'il a été traité.
    Args:
        json_path: Chemin vers le fichier sidecar JSON
    Returns:
        True si le renommage a réussi, False sinon
    Example:
        photo.jpg.json → OK_photo.jpg.json
    """
    if not json_path.exists():
        logger.warning(f"Sidecar not found: {json_path}")
        return False
    if json_path.name.startswith(PROCESSED_PREFIX):
        logger.debug(f"Sidecar already marked as processed: {json_path}")
        return True
    new_name = PROCESSED_PREFIX + json_path.name
    new_path = json_path.parent / new_name
    try:
        json_path.rename(new_path)
        logger.info(f"Marked sidecar as processed: {json_path} → {new_path}")
        return True
    except OSError as e:
        logger.error(f"Failed to mark sidecar as processed: {json_path} - {e}")
        return False
def is_sidecar_processed(json_path: Path) -> bool:
    """
    Vérifie si un sidecar a déjà été marqué comme traité.
    Args:
        json_path: Chemin vers le fichier sidecar JSON
    Returns:
        True si le sidecar est marqué comme traité
    """
    return json_path.name.startswith(PROCESSED_PREFIX)
def get_processed_sidecars(directory: Path) -> List[Path]:
    """
    Trouve tous les sidecars marqués comme traités dans un répertoire.
    Args:
        directory: Répertoire à scanner
    Returns:
        Liste des chemins vers les sidecars traités
    """
    if not directory.is_dir():
        return []
    processed = []
    for file_path in directory.rglob(f"{PROCESSED_PREFIX}*.json"):
        processed.append(file_path)
    return processed
def get_original_sidecar_name(processed_path: Path) -> str:
    """
    Récupère le nom original d'un sidecar traité (sans le préfixe).
    Args:
        processed_path: Chemin vers un sidecar marqué comme traité
    Returns:
        Nom original du sidecar
    """
    if not processed_path.name.startswith(PROCESSED_PREFIX):
        return processed_path.name
    return processed_path.name[len(PROCESSED_PREFIX):]
def find_sidecars_to_skip(directory: Path) -> Set[Path]:
    """
    Trouve les sidecars à ignorer lors d'un nouveau traitement.
    Retourne les chemins originaux (sans préfixe) des sidecars déjà traités,
    pour que le processeur puisse les ignorer.
    Args:
        directory: Répertoire à scanner
    Returns:
        Set des chemins vers les sidecars originaux à ignorer
    """
    processed_sidecars = get_processed_sidecars(directory)
    to_skip = set()
    for processed_path in processed_sidecars:
        original_name = get_original_sidecar_name(processed_path)
        original_path = processed_path.parent / original_name
        to_skip.add(original_path)
    return to_skip
def generate_cleanup_script(directory: Path, output_file: Path = None) -> Path:
    """
    Génère un script pour supprimer définitivement les sidecars traités.
    Args:
        directory: Répertoire contenant les sidecars traités
        output_file: Chemin du script à générer (optionnel)
    Returns:
        Chemin vers le script généré
    """
    processed_sidecars = get_processed_sidecars(directory)
    if not processed_sidecars:
        logger.info("No processed sidecars found for cleanup script")
        return None
    # Déterminer le nom et type de script selon l'OS
    is_windows = platform.system() == "Windows"
    script_ext = ".bat" if is_windows else ".sh"
    if output_file is None:
        output_file = directory / f"cleanup_processed_sidecars{script_ext}"
    script_lines = []
    if is_windows:
        script_lines.extend([
            "@echo off",
            "REM Script pour supprimer les sidecars traités avec succès",
            "REM Généré automatiquement - Vérifiez avant exécution !",
            "echo Suppression des sidecars traités...",
            ""
        ])
        for sidecar_path in processed_sidecars:
            # Échapper les chemins pour Windows
            escaped_path = str(sidecar_path).replace('"', '""')
            script_lines.append(f'del /f "{escaped_path}"')
        script_lines.extend([
            "",
            "echo Nettoyage terminé.",
            "pause"
        ])
    else:
        script_lines.extend([
            "#!/bin/bash",
            "# Script pour supprimer les sidecars traités avec succès",
            "# Généré automatiquement - Vérifiez avant exécution !",
            "echo 'Suppression des sidecars traités...'",
            ""
        ])
        for sidecar_path in processed_sidecars:
            # Échapper les chemins pour bash
            escaped_path = str(sidecar_path).replace("'", "'\"'\"'")
            script_lines.append(f"rm -f '{escaped_path}'")
        script_lines.extend([
            "",
            "echo 'Nettoyage terminé.'"
        ])
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(script_lines))
        # Rendre exécutable sur Unix
        if not is_windows:
            os.chmod(output_file, 0o755)
        logger.info(f"Cleanup script generated: {output_file}")
        logger.info(f"Found {len(processed_sidecars)} processed sidecars to clean")
        return output_file
    except OSError as e:
        logger.error(f"Failed to generate cleanup script: {e}")
        return None
def generate_rollback_script(directory: Path, output_file: Path = None) -> Path:
    """
    Génère un script pour restaurer les noms originaux des sidecars traités.
    Args:
        directory: Répertoire contenant les sidecars traités
        output_file: Chemin du script à générer (optionnel)
    Returns:
        Chemin vers le script généré
    """
    processed_sidecars = get_processed_sidecars(directory)
    if not processed_sidecars:
        logger.info("No processed sidecars found for rollback script")
        return None
    # Déterminer le nom et type de script selon l'OS
    is_windows = platform.system() == "Windows"
    script_ext = ".bat" if is_windows else ".sh"
    if output_file is None:
        output_file = directory / f"rollback_processed_sidecars{script_ext}"
    script_lines = []
    if is_windows:
        script_lines.extend([
            "@echo off",
            "REM Script pour restaurer les noms originaux des sidecars",
            "REM Généré automatiquement - Vérifiez avant exécution !",
            "echo Restauration des noms originaux...",
            ""
        ])
        for processed_path in processed_sidecars:
            original_name = get_original_sidecar_name(processed_path)
            original_path = processed_path.parent / original_name
            # Échapper les chemins pour Windows
            escaped_from = str(processed_path).replace('"', '""')
            escaped_to = str(original_path).replace('"', '""')
            script_lines.append(f'ren "{escaped_from}" "{original_name}"')
        script_lines.extend([
            "",
            "echo Rollback terminé.",
            "pause"
        ])
    else:
        script_lines.extend([
            "#!/bin/bash",
            "# Script pour restaurer les noms originaux des sidecars", 
            "# Généré automatiquement - Vérifiez avant exécution !",
            "echo 'Restauration des noms originaux...'",
            ""
        ])
        for processed_path in processed_sidecars:
            original_name = get_original_sidecar_name(processed_path)
            original_path = processed_path.parent / original_name
            # Échapper les chemins pour bash
            escaped_from = str(processed_path).replace("'", "'\"'\"'")
            escaped_to = str(original_path).replace("'", "'\"'\"'")
            script_lines.append(f"mv '{escaped_from}' '{escaped_to}'")
        script_lines.extend([
            "",
            "echo 'Rollback terminé.'"
        ])
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(script_lines))
        # Rendre exécutable sur Unix
        if not is_windows:
            os.chmod(output_file, 0o755)
        logger.info(f"Rollback script generated: {output_file}")
        logger.info(f"Found {len(processed_sidecars)} processed sidecars to rollback")
        return output_file
    except OSError as e:
        logger.error(f"Failed to generate rollback script: {e}")
        return None
def generate_scripts_summary(directory: Path) -> Tuple[int, int, List[str]]:
    """
    Génère un résumé des sidecars traités et des actions possibles.
    Args:
        directory: Répertoire à analyser
    Returns:
        Tuple (nb_processed, nb_pending, messages)
    """
    processed_sidecars = get_processed_sidecars(directory)
    # Compter les sidecars en attente (non traités)
    all_sidecars = list(directory.rglob("*.json"))
    pending_sidecars = [s for s in all_sidecars if not is_sidecar_processed(s)]
    messages = []
    messages.append("=== Résumé des sidecars ===")
    messages.append(f"Traités avec succès (préfixe {PROCESSED_PREFIX}): {len(processed_sidecars)}")
    messages.append(f"En attente de traitement: {len(pending_sidecars)}")
    if processed_sidecars:
        messages.append("")
        messages.append("Actions disponibles:")
        messages.append("1. Générer script de nettoyage (suppression définitive)")
        messages.append("2. Générer script de rollback (restaurer noms originaux)")
        messages.append("3. Relancer le traitement (ignorera automatiquement les fichiers déjà traités)")
    return len(processed_sidecars), len(pending_sidecars), messages
````

## File: src/google_takeout_metadata/sidecar.py
````python
from __future__ import annotations
from dataclasses import dataclass, field
from pathlib import Path
import json
import logging
from typing import List, Optional
"""Analyse des fichiers annexes JSON de Google Takeout."""
logger = logging.getLogger(__name__)
@dataclass
class SidecarData:
    """Métadonnées sélectionnées extraites d'un JSON annexe Google Photos."""
    filename: str
    description: Optional[str]
    people: List[str]
    taken_at: Optional[int]
    created_at: Optional[int]
    latitude: Optional[float]
    longitude: Optional[float]
    altitude: Optional[float]
    favorite: bool = False
    lat_span: Optional[float] = None
    lon_span: Optional[float] = None
    albums: List[str] = field(default_factory=list)
    archived: bool = False
    trashed: bool = False
    locked: bool = False
    local_folder_name: Optional[str] = None  # Nom du dossier source (appareil)
def parse_sidecar(path: Path) -> SidecarData:
    """Analyser ``path`` et retourner :class:`SidecarData`.
    La fonction vérifie que le champ ``title`` intégré correspond au nom de fichier
    du sidecar pour éviter d'appliquer des métadonnées au mauvais média.
    Formats supportés :
    - Nouveau format : photo.jpg.supplemental-metadata.json -> title attendu "photo.jpg"
    - Ancien format : photo.jpg.json -> title attendu "photo.jpg"
    """
    try:
        with path.open("r", encoding="utf-8") as fh:
            data = json.load(fh)
    except FileNotFoundError as exc:  # pragma: no cover - simple wrapper
        raise FileNotFoundError(f"Sidecar introuvable : {path}") from exc
    except json.JSONDecodeError as exc:
        raise ValueError(f"JSON invalide dans {path}") from exc
    title = data.get("title")
    if not title:
        raise ValueError(f"Champ 'title' manquant dans {path}")
    # Extraire le nom de fichier attendu depuis le chemin du sidecar
    # Pour le nouveau format : IMG_001.jpg.supplemental-metadata.json -> titre attendu : IMG_001.jpg
    # Pour le format hérité : IMG_001.jpg.json -> titre attendu : IMG_001.jpg
    if path.name.lower().endswith(".supplemental-metadata.json"):
        expected_title = path.name[:-len(".supplemental-metadata.json")]
    elif path.name.lower().endswith(".supplemental-metadat.json"):
        expected_title = path.name[:-len(".supplemental-metadat.json")]
    elif path.name.lower().endswith(".supplemental-me.json"):
        expected_title = path.name[:-len(".supplemental-me.json")]
    elif path.name.lower().endswith(".supplemental-meta.json"):
        expected_title = path.name[:-len(".supplemental-meta.json")]
    elif path.name.lower().endswith(".json"):
        expected_title = path.stem
    else:
        expected_title = path.stem
    if expected_title != title:
        raise ValueError(
            f"Le titre du sidecar {title!r} ne correspond pas au nom de fichier attendu {expected_title!r} provenant de {path.name!r}"
        )
    description = data.get("description")
    # Extraire les noms de personnes, supprimer les espaces et dédupliquer
    # Gère plusieurs formats :
    # - [{ "name": "X" }]
    raw_people = data.get("people", []) or []
    people = []
    for p in raw_people:
        if isinstance(p, dict):
            # Format standard : {"name": "X"}
            if isinstance(p.get("name"), str):
                people.append(p["name"].strip())
    # déduplication
    people = sorted(set(filter(None, people)))
    def get_ts(key: str) -> Optional[int]:
        ts = data.get(key, {}).get("timestamp")
        if ts is None:
            return None
        try:
            return int(ts)
        except (TypeError, ValueError):
            return None
    taken_at = get_ts("photoTakenTime")
    created_at = get_ts("creationTime")
    # Extraire les données géographiques - préférer geoData, repli sur geoDataExif
    geo = data.get("geoData", {})
    if not geo or not geo.get("latitude"):
        geo = data.get("geoDataExif", {})
    latitude = geo.get("latitude")
    longitude = geo.get("longitude")
    altitude = geo.get("altitude")
    lat_span = geo.get("latitudeSpan")
    lon_span = geo.get("longitudeSpan")
    # Nettoyer les coordonnées seulement si les DEUX sont à 0/None
    # Conserver les vraies coordonnées 0.0 car elles peuvent être valides (équateur/méridien de Greenwich)
    # Google met parfois 0/0 quand pas de géo fiable → on nettoie uniquement dans ce cas
    if ((latitude in (0, 0.0, None)) and (longitude in (0, 0.0, None))) or \
       (latitude is None or longitude is None):
        latitude = longitude = altitude = None
    # Extraire le statut favori - format booléen Google Takeout
    # Note : "favorited": true si favori, champ absent si pas favori (pas false)
    favorite = bool(data.get("favorited", False))
    # Extraire le statut archivé
    archived = bool(data.get("archived", False))
    # Extraire le statut corbeille
    trashed = bool(data.get("trashed", False))
    # Extraire le statut d'album vérouillé
    locked = bool(data.get("inLockedFolder", False))
    # Extraire le nom du dossier local de l'appareil
    local_folder_name = None
    google_photos_origin = data.get("googlePhotosOrigin", {})
    if isinstance(google_photos_origin, dict):
        mobile_upload = google_photos_origin.get("mobileUpload", {})
        if isinstance(mobile_upload, dict):
            device_folder = mobile_upload.get("deviceFolder", {})
            if isinstance(device_folder, dict):
                folder_name = device_folder.get("localFolderName")
                if isinstance(folder_name, str) and folder_name.strip():
                    local_folder_name = folder_name.strip()
    return SidecarData(
        filename=title,
        description=description,
        people=people,
        taken_at=taken_at,
        created_at=created_at,
        latitude=latitude,
        longitude=longitude,
        altitude=altitude,
        favorite=favorite,
        lat_span=lat_span,
        lon_span=lon_span,
        archived=archived,
        trashed=trashed,
        locked=locked,
        albums=[],  # Les albums sont gérés séparément
        local_folder_name=local_folder_name,
    )
def parse_album_metadata(path: Path) -> List[str]:
    """Analyser un fichier metadata.json d'album et retourner la liste des noms d'albums.
    Les fichiers metadata.json d'albums (Google Takeout) contiennent généralement :
    {
        "title": "halloween",
        "description": "",
        "access": "protected",
        "date": {
            "timestamp": "1730287676",
            "formatted": "30 oct. 2024, 11:27:56 UTC"
        }
    }
    Un seul album par fichier metadata.json.
    Retourne une liste avec le nom de l'album (ou liste vide si erreur).
    """
    try:
        with path.open("r", encoding="utf-8") as fh:
            data = json.load(fh)
    except (FileNotFoundError, json.JSONDecodeError):
        return []
    # Nom d'album depuis le champ title
    title = data.get("title")
    if title and isinstance(title, str):
        title = title.strip()
        if title:  # Vérifier que le titre n'est pas vide après nettoyage
            return [title]
    return []
def find_albums_for_directory(directory: Path, max_depth: int = 5) -> List[str]:
    """Trouver tous les noms d'albums applicables aux photos du répertoire donné.
    Recherche des fichiers metadata.json dans le répertoire et ses parents
    pour collecter les informations d'album.
    Args:
        directory: Répertoire de départ pour la recherche
        max_depth: Nombre maximum de niveaux parents à vérifier (défaut: 5)
    Prend en charge plusieurs motifs de fichiers metadata :
    - metadata.json (anglais)
    - métadonnées.json (français)  
    - métadonnées(1).json, métadonnées(2).json, etc. (français avec doublons)
    - album_metadata.json, folder_metadata.json (hérités)
    """
    albums = []
    metadata_patterns = [
        "metadata.json",
        "métadonnées.json", 
        "album_metadata.json", 
        "folder_metadata.json"
    ]
    # Rechercher dans le répertoire courant et ses parents avec limite de profondeur
    current_dir = directory
    depth = 0
    # Motifs de répertoires marqueurs (insensibles à la casse)
    takeout_markers = ["google photos", "takeout", "google takeout"]
    while current_dir != current_dir.parent and depth < max_depth:
        # Vérifier les motifs standards (insensible à la casse)
        for pattern in metadata_patterns:
            # Rechercher le fichier avec la casse exacte d'abord
            metadata_file = current_dir / pattern
            if metadata_file.exists():
                try:
                    albums.extend(parse_album_metadata(metadata_file))
                except (OSError, PermissionError) as e:
                    # Ignorer les erreurs de parsing et continuer
                    logger.debug(f"Erreur lors du parsing de {metadata_file}: {e}")
            else:
                # Rechercher de manière insensible à la casse si pas trouvé
                try:
                    for existing_file in current_dir.iterdir():
                        if existing_file.is_file() and existing_file.name.lower() == pattern.lower():
                            try:
                                albums.extend(parse_album_metadata(existing_file))
                            except (OSError, PermissionError) as e:
                                logger.debug(f"Erreur lors du parsing de {existing_file}: {e}")
                            break  # Un seul fichier correspondant par motif
                except (OSError, PermissionError):
                    # Ignorer les erreurs d'accès au répertoire
                    logger.debug(f"Impossible d'accéder au répertoire {current_dir}")
        # Vérifier les variations numérotées comme métadonnées(1).json, métadonnées(2).json, etc.
        # (recherche insensible à la casse)
        try:
            for metadata_file in current_dir.iterdir():
                if (metadata_file.is_file() and 
                    metadata_file.name.lower().startswith("métadonnées") and 
                    metadata_file.name.lower().endswith(".json") and
                    metadata_file.name.lower() not in ["métadonnées.json"]):  # déjà vérifié ci-dessus
                    try:
                        albums.extend(parse_album_metadata(metadata_file))
                    except (OSError, PermissionError) as e:
                        # Ignorer les erreurs de parsing et continuer
                        logger.debug(f"Erreur lors du parsing de {metadata_file}: {e}")
        except (OSError, PermissionError):
            # Ignorer les erreurs d'accès au répertoire et continuer
            logger.debug(f"Impossible d'accéder au répertoire {current_dir}")
        # Arrêter si on atteint un répertoire "marqueur" de Google Takeout
        # pour éviter de remonter trop haut dans l'arborescence
        if any(marker in current_dir.name.lower() for marker in takeout_markers):
            logger.debug(f"Arrêt de la recherche d'albums au répertoire marqueur: {current_dir}")
            break
        # Remonter au répertoire parent
        current_dir = current_dir.parent
        depth += 1
    # Déduplication et tri tout en préservant l'ordre de priorité
    # (répertoires plus proches en premier)
    unique_albums = []
    seen = set()
    for album in albums:
        if album not in seen:
            unique_albums.append(album)
            seen.add(album)
    return unique_albums
````

## File: src/google_takeout_metadata/statistics.py
````python
"""Module de gestion des statistiques et rapport de synthèse."""
from __future__ import annotations
import logging
from datetime import datetime
from dataclasses import dataclass, field
from pathlib import Path
from typing import List, Dict, Optional
import json
logger = logging.getLogger(__name__)
@dataclass
class ProcessingStats:
    """Statistiques de traitement des fichiers."""
    # Totaux
    total_sidecars_found: int = 0
    total_processed: int = 0
    total_failed: int = 0
    total_skipped: int = 0
    # Par type de fichier
    images_processed: int = 0
    videos_processed: int = 0
    # Détails des opérations
    files_fixed_extension: int = 0
    sidecars_cleaned: int = 0
    # Listes de détails pour le rapport détaillé
    failed_files: List[str] = field(default_factory=list)
    skipped_files: List[str] = field(default_factory=list)
    fixed_extensions: List[str] = field(default_factory=list)
    # Erreurs par catégorie
    errors_by_type: Dict[str, int] = field(default_factory=dict)
    # Timing
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    def start_processing(self) -> None:
        """Marquer le début du traitement."""
        self.start_time = datetime.now()
    def end_processing(self) -> None:
        """Marquer la fin du traitement."""
        self.end_time = datetime.now()
    @property
    def duration(self) -> Optional[float]:
        """Durée du traitement en secondes."""
        if self.start_time and self.end_time:
            return (self.end_time - self.start_time).total_seconds()
        return None
    @property
    def success_rate(self) -> float:
        """Taux de réussite en pourcentage."""
        if self.total_sidecars_found == 0:
            return 0.0
        return (self.total_processed / self.total_sidecars_found) * 100
    def add_processed_file(self, is_image: bool = True) -> None:
        """Ajouter un fichier traité avec succès."""
        self.total_processed += 1
        if is_image:
            self.images_processed += 1
        else:
            self.videos_processed += 1
    def add_failed_file(self, file_path: Path, error_type: str, error_msg: str) -> None:
        """Ajouter un fichier en échec."""
        self.total_failed += 1
        self.failed_files.append(f"{file_path.name}: {error_msg}")
        # Compter les erreurs par type
        if error_type in self.errors_by_type:
            self.errors_by_type[error_type] += 1
        else:
            self.errors_by_type[error_type] = 1
    def add_skipped_file(self, file_path: Path, reason: str) -> None:
        """Ajouter un fichier ignoré."""
        self.total_skipped += 1
        self.skipped_files.append(f"{file_path.name}: {reason}")
    def add_fixed_extension(self, old_name: str, new_name: str) -> None:
        """Ajouter une correction d'extension."""
        self.files_fixed_extension += 1
        self.fixed_extensions.append(f"{old_name} → {new_name}")
    def print_console_summary(self) -> None:
        """Afficher un résumé concis dans la console."""
        print("\n" + "="*60)
        print("📊 RÉSUMÉ DU TRAITEMENT")
        print("="*60)
        print(f"📁 Fichiers de métadonnées trouvés : {self.total_sidecars_found}")
        print(f"✅ Fichiers traités avec succès : {self.total_processed}")
        if self.images_processed > 0 or self.videos_processed > 0:
            print(f"   📸 Images : {self.images_processed}")
            print(f"   🎥 Vidéos : {self.videos_processed}")
        if self.total_failed > 0:
            print(f"❌ Fichiers en échec : {self.total_failed}")
        if self.total_skipped > 0:
            print(f"⏭️  Fichiers ignorés : {self.total_skipped}")
        if self.files_fixed_extension > 0:
            print(f"🔧 Extensions corrigées : {self.files_fixed_extension}")
        if self.sidecars_cleaned > 0:
            print(f"🗑️  Fichiers de métadonnées supprimés : {self.sidecars_cleaned}")
        # Taux de réussite
        if self.total_sidecars_found > 0:
            print(f"📈 Taux de réussite : {self.success_rate:.1f}%")
        # Durée
        if self.duration:
            print(f"⏱️  Durée : {self.duration:.1f}s")
        # Erreurs principales
        if self.errors_by_type:
            print("\n🔍 Types d'erreurs principales :")
            for error_type, count in sorted(self.errors_by_type.items(), key=lambda x: x[1], reverse=True)[:3]:
                print(f"   • {error_type}: {count} fichier(s)")
        print("="*60)
        if self.total_failed > 0 or self.total_skipped > 0:
            print("💡 Consultez le fichier de log détaillé pour plus d'informations.")
    def save_detailed_report(self, log_file: Path) -> None:
        """Sauvegarder un rapport détaillé dans un fichier spécifique à cette exécution."""
        report = {
            "execution_timestamp": datetime.now().isoformat(),
            "summary": {
                "total_sidecars_found": self.total_sidecars_found,
                "total_processed": self.total_processed,
                "total_failed": self.total_failed,
                "total_skipped": self.total_skipped,
                "images_processed": self.images_processed,
                "videos_processed": self.videos_processed,
                "files_fixed_extension": self.files_fixed_extension,
                "sidecars_cleaned": self.sidecars_cleaned,
                "success_rate": self.success_rate,
                "duration_seconds": self.duration
            },
            "details": {
                "failed_files": self.failed_files,
                "skipped_files": self.skipped_files,
                "fixed_extensions": self.fixed_extensions,
                "errors_by_type": self.errors_by_type
            }
        }
        try:
            with open(log_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            logger.info(f"📄 Rapport détaillé sauvegardé : {log_file}")
        except Exception as e:
            logger.error(f"Erreur lors de la sauvegarde du rapport : {e}")
# Instance globale pour les statistiques
stats = ProcessingStats()
````

## File: TERMINOLOGY_UPDATE.md
````markdown
# Mise à jour de la terminologie du codebase

## Changements effectués

### Terminologie unifiée (cohérente avec exif_writer.py) :

1. **"Approche hybride" → "Approche robuste"**
   - Fonction : `test_hybrid_approach_*` → `test_robust_approach_*`
   - Fichiers : `test_hybrid_approach.py` → `test_robust_approach.py`
   - Commentaires : "approche hybride" → "approche robuste (remove-then-add)"

2. **Terminologie technique cohérente :**
   - **"Robuste"** = Stratégie `-TAG-=val` puis `-TAG+=val` (garantit zéro doublon)
   - **"Conditional"** = Stratégie `-if not $TAG=~/regex/i` puis `-TAG+=val` (performance)
   - **"Overwrite"** = Stratégie `-TAG=` puis `-TAG+=val` (écrasement complet)

### Fichiers modifiés :

1. `tests/test_hybrid_approach.py` → `tests/test_robust_approach.py`
2. `tests/CORRECT_test_hybrid_approach.py` → `tests/CORRECT_test_robust_approach.py`  
3. `experiments/test_tony1.py` (commentaire mis à jour)

### Correspondance avec exif_writer.py :

```python
# Mode append_only=True utilise par défaut l'approche "robuste"
args.extend(build_remove_then_add_args_for_people(meta.people))

# Alternative "conditional" pour performance  
args.extend(build_conditional_add_args_for_people(meta.people))

# Mode overwrite_mode=True
args.extend(build_overwrite_args_for_people(meta.people))
```

## Justification

Cette mise à jour assure la cohérence terminologique dans tout le codebase :
- Les tests utilisent maintenant les mêmes termes que l'implémentation
- La documentation reflète les vrais noms de fonctions
- Évite la confusion entre "hybride" (terme ad-hoc) et "robuste" (terme technique établi)
````

## File: test_assets/README.md
````markdown
# Assets de Test

Ce dossier contient des fichiers de référence pour les tests d'intégration.

## Fichiers disponibles

### Images
- **test_clean.jpg** : Image JPEG 100x100 sans métadonnées (nettoye avec `exiftool -all=`)
- **test_with_metadata.jpg** : Image JPEG 100x100 avec métadonnées de base
  - Description : "Existing description"
  - Rating : 3
  - Keywords : "Existing keyword"

### Vidéos
- **test_video_clean.mp4** : Vidéo MP4 sans métadonnées (nettoyée avec `exiftool -all=`)
- **test_video_with_metadata.mp4** : Vidéo MP4 avec métadonnées de base
  - Description : "Existing video description"
  - DateTimeOriginal : "2020:01:01 12:00:00"
  - Keywords : "Existing video keyword"

## Utilisation dans les tests

Les tests d'intégration utilisent la fonction `_copy_test_asset(asset_name, dest_path)` pour copier ces fichiers vers des répertoires temporaires avant chaque test. Cela garantit :

1. **Reproductibilité** : Chaque test commence avec les mêmes conditions
2. **Isolation** : Les tests ne s'interfèrent pas entre eux
3. **Contrôle** : Les métadonnées existantes sont connues et prévisibles

## Régénération des assets

Si nécessaire, les assets peuvent être régénérés avec :

```bash
# Se placer dans le dossier test_assets
cd test_assets

# Créer les images
python -c "
from PIL import Image
img = Image.new('RGB', (100, 100), color='red')
img.save('test_clean.jpg')
img2 = Image.new('RGB', (100, 100), color='blue') 
img2.save('test_with_metadata.jpg')
"

# Copier la vidéo de référence
cp "../Google Photos/essais/1686356837983.mp4" "test_video_clean.mp4"
cp "test_video_clean.mp4" "test_video_with_metadata.mp4"

# Nettoyer les fichiers clean
exiftool -overwrite_original -all= test_clean.jpg test_video_clean.mp4

# Ajouter des métadonnées aux fichiers with_metadata
exiftool -overwrite_original -EXIF:ImageDescription="Existing description" -XMP:Rating=3 -IPTC:Keywords="Existing keyword" test_with_metadata.jpg
exiftool -overwrite_original -api QuickTimeUTC=1 -XMP-dc:Description="Existing video description" -DateTimeOriginal="2020:01:01 12:00:00" -IPTC:Keywords="Existing video keyword" test_video_with_metadata.mp4
```
````

## File: tests/CORRECT_test_robust_approach.py
````python
import shutil
import tempfile
import subprocess
from pathlib import Path
from google_takeout_metadata.sidecar import SidecarData
from google_takeout_metadata.exif_writer import write_metadata
def read_exif_people(image_path: Path) -> list[str]:
    """Lit les personnes depuis un fichier image en utilisant exiftool."""
    try:
        cmd = ["exiftool", "-s", "-s", "-s", "-XMP-iptcExt:PersonInImage", str(image_path)]
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=30, encoding='utf-8')
        if result.returncode == 0 and result.stdout.strip():
            # ExifTool retourne les valeurs séparées par des virgules
            people = [p.strip() for p in result.stdout.strip().split(',')]
            return [p for p in people if p]  # Filtrer les valeurs vides
    except (subprocess.SubprocessError, OSError):
        pass
    return []
def test_robust_approach_no_duplicates():
    """Test de l'approche robuste (remove-then-add) : pas de doublons quand on ajoute des personnes existantes."""
    with tempfile.TemporaryDirectory() as temp_dir:
        # Copier l'image test dans le répertoire temporaire
        test_image_src = Path("test_assets/test_clean.jpg")
        test_image = Path(temp_dir) / "test_image.jpg"
        shutil.copy2(test_image_src, test_image)
        # Étape 1 : Ajouter les premières personnes (ancien takeout)
        meta1 = SidecarData(
            filename="test_image.jpg",
            description=None,
            people=["Anthony", "Bernard"],
            taken_at=None,
            created_at=None,
            latitude=None,
            longitude=None,
            altitude=None,
            favorite=False,
            albums=["Vacances"]
        )
        write_metadata(test_image, meta1, append_only=True)
        # Vérifier l'état initial
        people_initial = read_exif_people(test_image)
        assert "Anthony" in people_initial
        assert "Bernard" in people_initial
        assert len([p for p in people_initial if p == "Anthony"]) == 1
        assert len([p for p in people_initial if p == "Bernard"]) == 1
        # Étape 2 : Ajouter nouveaux + existants (nouveau takeout avec tous les gens)
        meta2 = SidecarData(
            filename="test_image.jpg",
            description=None,
            people=["Anthony", "Bernard", "Cindy"],  # Contient TOUS les gens, pas juste les nouveaux
            taken_at=None,
            created_at=None,
            latitude=None,
            longitude=None,
            altitude=None,
            favorite=False,
            albums=["Vacances", "Famille"]
        )
        write_metadata(test_image, meta2, append_only=True)
        # Vérifier le résultat final : pas de doublons malgré la redondance
        people_final = read_exif_people(test_image)
        print(f"Personnes finales: {people_final}")
        # Assertions critiques : aucun doublon
        assert "Anthony" in people_final
        assert "Bernard" in people_final 
        assert "Cindy" in people_final
        assert len([p for p in people_final if p == "Anthony"]) == 1, f"Anthony apparaît plusieurs fois: {people_final}"
        assert len([p for p in people_final if p == "Bernard"]) == 1, f"Bernard apparaît plusieurs fois: {people_final}"
        assert len([p for p in people_final if p == "Cindy"]) == 1, f"Cindy apparaît plusieurs fois: {people_final}"
        # Vérifier que toutes les personnes attendues sont présentes
        expected_people = {"Anthony", "Bernard", "Cindy"}
        actual_people = set(people_final)
        assert expected_people.issubset(actual_people), f"Personnes manquantes. Attendu: {expected_people}, Réel: {actual_people}"
def test_robust_approach_only_new_people():
    """Test de l'approche robuste (remove-then-add) : ajouter seulement les nouvelles personnes."""
    with tempfile.TemporaryDirectory() as temp_dir:
        # Copier l'image test
        # Copier l'image test
        test_image_src = Path("test_assets/test_clean.jpg")
        if not test_image_src.exists():
            raise FileNotFoundError(f"Fichier test requis non trouvé : {test_image_src}")
        test_image = Path(temp_dir) / "test_image.jpg"
        shutil.copy2(test_image_src, test_image)
        # Étape 1 : Ajouter les premières personnes
        meta1 = SidecarData(
            filename="test_image.jpg",
            description=None,
            people=["Alice", "Bob"],
            taken_at=None,
            created_at=None,
            latitude=None,
            longitude=None,
            altitude=None,
            favorite=False
        )
        write_metadata(test_image, meta1, append_only=True)
        # Étape 2 : Ajouter seulement les nouvelles personnes 
        meta2 = SidecarData(
            filename="test_image.jpg",
            description=None,
            people=["Charlie"],  # Seulement la nouvelle personne
            taken_at=None,
            created_at=None,
            latitude=None,
            longitude=None,
            altitude=None,
            favorite=False
        )
        write_metadata(test_image, meta2, append_only=True)
        # Vérifier le résultat : toutes les personnes présentes, pas de doublons
        people_final = read_exif_people(test_image)
        expected_people = {"Alice", "Bob", "Charlie"}
        actual_people = set(people_final)
        assert expected_people == actual_people, f"Attendu: {expected_people}, Réel: {actual_people}"
        assert len(people_final) == 3, f"Doublons détectés: {people_final}"
if __name__ == "__main__":
    test_robust_approach_no_duplicates()
    test_robust_approach_only_new_people()
    print("✅ Tests de l'approche robuste (remove-then-add) : SUCCÈS")
````

## File: tests/SIDECAR_CLEANUP_FIXES.md
````markdown
# Correction de la terminologie obsolète dans les tests de suppression des sidecars

## Problèmes identifiés et corrigés

### 1. Terminologie obsolète `clean_sidecars` → `immediate_delete`

**Fichiers corrigés :**
- `tests/test_processor_batch.py` (✅ déjà corrigé)
- `tests/test_improvements.py` (✅ corrigé maintenant)

**Changements effectués dans `test_improvements.py` :**

1. **`test_batch_sidecar_cleanup_with_real_failure`** :
   ```python
   # AVANT
   result = process_batch(batch, clean_sidecars=True)
   
   # APRÈS  
   result = process_batch(batch, immediate_delete=True)
   ```

2. **`test_batch_sidecar_cleanup_with_condition_success`** :
   ```python
   # AVANT
   process_sidecar_file(json_path, append_only=True, clean_sidecars=True)
   
   # APRÈS
   process_sidecar_file(json_path, append_only=True, immediate_delete=True)
   ```

3. **`test_batch_cleanup_logic_unit`** :
   ```python
   # AVANT
   result = process_batch(batch, clean_sidecars=True)
   
   # APRÈS
   result = process_batch(batch, immediate_delete=True)
   ```

### 2. Logique `'files failed condition'` toujours valide ✅

**Vérification :** La logique `'files failed condition'` est toujours d'actualité et correctement implémentée dans :
- `src/google_takeout_metadata/exif_writer.py` (lignes 421-423)
- `src/google_takeout_metadata/processor_batch.py` (ligne 118)

**Comportement correct :** En mode append-only, quand exiftool retourne "files failed condition", c'est normal (métadonnées existantes) et le sidecar peut être supprimé en toute sécurité.

### 3. Signatures de fonctions mises à jour ✅

**Vérification des signatures actuelles :**
```python
# process_batch utilise bien immediate_delete
def process_batch(batch: List[Tuple[Path, Path, List[str]]], immediate_delete: bool) -> int

# process_sidecar_file utilise bien immediate_delete  
def process_sidecar_file(json_path: Path, use_localtime: bool = False, 
                        append_only: bool = True, immediate_delete: bool = False) -> None
```

### 4. Tests validés ✅

- ✅ **16 tests unitaires** dans `test_improvements.py` passent
- ✅ **Logique de suppression des sidecars** cohérente avec l'implémentation
- ✅ **Terminologie unifiée** dans tout le codebase

## Impact

Ces corrections assurent que :
1. **Cohérence terminologique** : Plus de confusion entre `clean_sidecars` et `immediate_delete`
2. **Tests à jour** : Les tests reflètent l'API actuelle
3. **Logique préservée** : Le comportement `'files failed condition'` reste correct
4. **Maintenance facilitée** : Plus de paramètres obsolètes dans les tests

## Fichiers déplacés vers tests/

Les fichiers de test créés précédemment ont été déplacés dans le bon répertoire :
- `test_wm_cg_fix.py` → `tests/test_wm_cg_fix.py`
- `test_p1_specific.py` → `tests/test_p1_specific.py`  
- `test_sidecar_integration.py` → `tests/test_sidecar_integration.py`
````

## File: tests/test_batch_organization.py
````python
#!/usr/bin/env python3
"""Test de l'organisation de fichiers en mode batch."""
import tempfile
import json
from pathlib import Path
from PIL import Image
# Import des modules
import sys
sys.path.insert(0, "src")
from google_takeout_metadata.processor_batch import process_directory_batch
def test_batch_organization():
    """Test d'organisation de fichiers en mode batch."""
    with tempfile.TemporaryDirectory() as temp_dir:
        test_dir = Path(temp_dir)
        # 1. Créer un vrai fichier image minimal avec PIL
        media_file = test_dir / "test_image.jpg"
        img = Image.new('RGB', (100, 100), color='red')
        img.save(media_file)
        # 2. Créer un sidecar avec statut trashed
        sidecar_file = test_dir / "test_image.jpg.json" 
        sidecar_data = {
            "title": "test_image.jpg",
            "description": "Une photo test",
            "photoTakenTime": {"timestamp": "1640995200"},
            "trashed": True,
            "archived": False,
            "locked": False
        }
        with open(sidecar_file, 'w', encoding='utf-8') as f:
            json.dump(sidecar_data, f, indent=2)
        print("📁 Structure initiale :")
        print(f"   {media_file.name}")
        print(f"   {sidecar_file.name}")
        # 3. Lancer le traitement batch avec organisation
        print("\n🚀 Lancement du traitement batch avec organisation...")
        process_directory_batch(
            root=test_dir,
            use_localtime=False,
            append_only=True,
            immediate_delete=False,
            organize_files=True
        )
        # 4. Vérifier que les fichiers ont été déplacés
        corbeille_dir = test_dir / "_Corbeille"
        moved_media = corbeille_dir / "test_image.jpg"
        moved_sidecar = corbeille_dir / "OK_test_image.jpg.json"
        print("\n📋 Vérifications :")
        print(f"   Dossier corbeille créé : {corbeille_dir.exists()}")
        print(f"   Fichier média déplacé : {moved_media.exists()}")
        print(f"   Sidecar déplacé et marqué : {moved_sidecar.exists()}")
        # Utiliser des assertions au lieu de return pour pytest
        assert corbeille_dir.exists(), "Le dossier corbeille devrait être créé"
        assert moved_media.exists(), "Le fichier média devrait être déplacé dans la corbeille"
        print("✅ Test batch avec organisation réussi !")
if __name__ == "__main__":
    print("🧪 Test d'organisation en mode batch")
    print("=" * 50)
    success = test_batch_organization()
    print("\n" + "=" * 50)
    if success:
        print("🎉 Test d'intégration batch réussi !")
    else:
        print("💥 Test d'intégration batch échoué")
````

## File: tests/test_cli.py
````python
"""Tests pour l'interface en ligne de commande."""
import json
import subprocess
import sys
from unittest.mock import patch
import pytest
from PIL import Image
from google_takeout_metadata.cli import main
def test_main_no_args(capsys):
    """Tester que la CLI sans arguments affiche l'aide."""
    with pytest.raises(SystemExit):
        main([])
    captured = capsys.readouterr()
    assert "usage:" in captured.err
def test_main_help(capsys):
    """Tester l'option d'aide de la CLI."""
    with pytest.raises(SystemExit):
        main(["--help"])
    captured = capsys.readouterr()
    assert "Fusionner les métadonnées Google Takeout dans les images" in captured.out
def test_main_invalid_directory(capsys, tmp_path):
    """Tester la CLI avec un répertoire inexistant."""
    non_existent = tmp_path / "does_not_exist"
    with pytest.raises(SystemExit):
        main([str(non_existent)])
    # L'erreur est enregistrée mais pas affichée sur stderr avec la configuration actuelle
    # Donc nous ne vérifions pas la sortie capturée, juste qu'elle se termine
def test_main_file_instead_of_directory(capsys, tmp_path):
    """Tester la CLI avec un chemin de fichier au lieu d'un répertoire."""
    test_file = tmp_path / "test.txt"
    test_file.write_text("test")
    with pytest.raises(SystemExit):
        main([str(test_file)])
    # L'erreur est enregistrée mais pas affichée sur stderr avec la configuration actuelle
    # Donc nous ne vérifions pas la sortie capturée, juste qu'elle se termine
@patch('google_takeout_metadata.cli.process_directory')
def test_main_normal_mode(mock_process_directory, tmp_path):
    """Tester le mode de traitement normal de la CLI."""
    main([str(tmp_path)])
    mock_process_directory.assert_called_once_with(
        tmp_path, use_localtime=False, append_only=True, immediate_delete=False, organize_files=False
    )
@patch('google_takeout_metadata.cli.process_directory_batch')
def test_main_batch_mode(mock_process_directory_batch, tmp_path):
    """Tester le mode de traitement par lot de la CLI."""
    main(["--batch", str(tmp_path)])
    mock_process_directory_batch.assert_called_once_with(
        tmp_path, use_localtime=False, append_only=True, immediate_delete=False, organize_files=False
    )
@patch('google_takeout_metadata.cli.process_directory')
def test_main_localtime_option(mock_process_directory, tmp_path):
    """Tester la CLI avec l'option localtime."""
    main(["--localtime", str(tmp_path)])
    mock_process_directory.assert_called_once_with(
        tmp_path, use_localtime=True, append_only=True, immediate_delete=False, organize_files=False
    )
@patch('google_takeout_metadata.cli.process_directory')
def test_main_overwrite_option(mock_process_directory, tmp_path):
    """Tester la CLI avec l'option overwrite."""
    main(["--overwrite", str(tmp_path)])
    mock_process_directory.assert_called_once_with(
        tmp_path, use_localtime=False, append_only=False, immediate_delete=False, organize_files=False
    )
@patch('google_takeout_metadata.cli.process_directory')
def test_main_immediate_delete_option(mock_process_directory, tmp_path):
    """Tester la CLI avec l'option immediate-delete."""
    main(["--immediate-delete", str(tmp_path)])
    mock_process_directory.assert_called_once_with(
        tmp_path, use_localtime=False, append_only=True, immediate_delete=True, organize_files=False
    )
@patch('google_takeout_metadata.cli.process_directory_batch')
def test_main_batch_with_all_options(mock_process_directory_batch, tmp_path):
    """Tester le mode batch de la CLI avec toutes les options."""
    main(["--batch", "--localtime", "--overwrite", "--immediate-delete", str(tmp_path)])
    mock_process_directory_batch.assert_called_once_with(
        tmp_path, use_localtime=True, append_only=False, immediate_delete=True, organize_files=False
    )
@patch('google_takeout_metadata.cli.process_directory')
def test_main_verbose_logging(mock_process_directory, tmp_path, caplog):
    """Tester que la CLI avec l'option verbose active le logging de debug."""
    # Nous devons tester que basicConfig a été appelé avec le niveau DEBUG
    # mais le niveau du logger root pourrait ne pas changer pendant le test
    main(["--verbose", str(tmp_path)])
    # S'assurer simplement que la fonction a été appelée - le test de logging est plus complexe
    # en raison de la façon dont pytest gère le logging
    mock_process_directory.assert_called_once()
@pytest.mark.integration
def test_main_integration_normal_mode(tmp_path):
    """Test d'intégration pour le mode normal de la CLI avec des fichiers réels."""
    try:
        # Créer une image de test
        media_path = tmp_path / "cli_test.jpg"
        img = Image.new('RGB', (100, 100), color='purple')
        img.save(media_path)
        # Créer le sidecar
        sidecar_data = {
            "title": "cli_test.jpg",
            "description": "CLI integration test"
        }
        json_path = tmp_path / "cli_test.jpg.json"
        json_path.write_text(json.dumps(sidecar_data), encoding="utf-8")
        # Exécuter la CLI
        main([str(tmp_path)])
        # Vérifier que les métadonnées ont été écrites
        cmd = [
            "exiftool",
            "-j",
            "-EXIF:ImageDescription",
            str(media_path)
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, check=True, timeout=30)
        metadata = json.loads(result.stdout)[0]
        assert metadata.get("ImageDescription") == "CLI integration test"
    except FileNotFoundError:
        pytest.skip("exiftool introuvable - skipping CLI integration test")
@pytest.mark.integration
def test_main_integration_batch_mode(tmp_path):
    """Test d'intégration pour le mode batch de la CLI avec des fichiers réels."""
    try:
        # Créer plusieurs images de test
        files_data = [
            ("batch1.jpg", "CLI batch test 1"),
            ("batch2.jpg", "CLI batch test 2")
        ]
        for filename, description in files_data:
            # Créer l'image
            media_path = tmp_path / filename
            img = Image.new('RGB', (100, 100), color='orange')
            img.save(media_path)
            # Créer le sidecar
            sidecar_data = {
                "title": filename,
                "description": description
            }
            json_path = tmp_path / f"{filename}.json"
            json_path.write_text(json.dumps(sidecar_data), encoding="utf-8")
        # Exécuter la CLI en mode batch
        main(["--batch", str(tmp_path)])
        # Vérifier que tous les fichiers ont été traités
        for filename, expected_description in files_data:
            media_path = tmp_path / filename
            cmd = [
                "exiftool",
                "-j",
                "-EXIF:ImageDescription",
                str(media_path)
            ]
            result = subprocess.run(cmd, capture_output=True, text=True, check=True, timeout=30)
            metadata = json.loads(result.stdout)[0]
            assert metadata.get("ImageDescription") == expected_description
    except FileNotFoundError:
        pytest.skip("exiftool introuvable - skipping CLI batch integration test")
@pytest.mark.integration
def test_main_integration_immediate_delete(tmp_path):
    """Test d'intégration pour la CLI avec suppression immédiate des sidecars."""
    try:
        # Créer une image de test
        media_path = tmp_path / "cleanup.jpg"
        img = Image.new('RGB', (100, 100), color='cyan')
        img.save(media_path)
        # Créer le sidecar
        sidecar_data = {
            "title": "cleanup.jpg",
            "description": "CLI immediate delete test"
        }
        json_path = tmp_path / "cleanup.jpg.json"
        json_path.write_text(json.dumps(sidecar_data), encoding="utf-8")
        # Vérifier que le sidecar existe
        assert json_path.exists()
        # Exécuter la CLI avec suppression immédiate
        main(["--immediate-delete", str(tmp_path)])
        # Vérifier que le sidecar a été supprimé
        assert not json_path.exists()
        # Vérifier que les métadonnées ont quand même été écrites
        cmd = [
            "exiftool",
            "-j",
            "-EXIF:ImageDescription",
            str(media_path)
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, check=True, timeout=30)
        metadata = json.loads(result.stdout)[0]
        assert metadata.get("ImageDescription") == "CLI immediate delete test"
    except FileNotFoundError:
        pytest.skip("exiftool introuvable - skipping CLI immediate delete integration test")
def test_main_entry_point():
    """Tester que la fonction main peut être appelée sans arguments depuis le point d'entrée."""
    # Cela teste principalement que la signature de la fonction main est correcte pour les points d'entrée
    # Nous ne pouvons pas tester l'analyse CLI réelle sans mocker sys.argv
    with patch.object(sys, 'argv', ['google-takeout-metadata', '--help']):
        with pytest.raises(SystemExit):
            main()
````

## File: tests/test_deduplication_robuste.py
````python
# Fichier : tests/test_deduplication_robuste.py
"""Tests spécifiques pour la nouvelle approche anti-duplication."""
from google_takeout_metadata.sidecar import SidecarData
from google_takeout_metadata.exif_writer import build_exiftool_args, normalize_person_name, normalize_keyword
def test_normalize_person_name():
    """Tester la normalisation intelligente des noms de personnes."""
    # Cas basiques
    assert normalize_person_name("anthony vincent") == "Anthony Vincent"
    assert normalize_person_name("ALICE DUPONT") == "Alice Dupont"
    assert normalize_person_name("bob martin") == "Bob Martin"
    # Cas spéciaux - mots de liaison
    assert normalize_person_name("jean de la fontaine") == "Jean de la Fontaine"
    assert normalize_person_name("marie van der berg") == "Marie van der Berg"
    assert normalize_person_name("peter von neumann") == "Peter von Neumann"
    # Cas spéciaux - noms irlandais/écossais
    assert normalize_person_name("patrick o'connor") == "Patrick O'Connor"
    assert normalize_person_name("SEAN O'BRIEN") == "Sean O'Brien"
    # Cas spéciaux - noms écossais/irlandais Mc
    assert normalize_person_name("john mcdonald") == "John McDonald"
    assert normalize_person_name("MARY MCGREGOR") == "Mary McGregor"
    # Cas limites
    assert normalize_person_name("") == ""
    assert normalize_person_name("   ") == ""
    assert normalize_person_name("a") == "A"
def test_normalize_keyword():
    """Tester la normalisation des mots-clés (première lettre de chaque mot en majuscule)."""
    assert normalize_keyword("vacances été") == "Vacances Été"
    assert normalize_keyword("photos de famille") == "Photos De Famille"
    assert normalize_keyword("ÉVÉNEMENTS SPÉCIAUX") == "Événements Spéciaux"
    assert normalize_keyword("test album") == "Test Album"
    # Cas limites
    assert normalize_keyword("") == ""
    assert normalize_keyword("   ") == ""
    assert normalize_keyword("a b c") == "A B C"
def test_remove_then_add_deduplication():
    """Tester que l'approche -=/+= élimine les doublons pré-existants.
    Ce test vérifie la génération correcte des arguments de déduplication
    selon l'approche "supprimer puis ajouter".
    """
    meta = SidecarData(
        filename="test.jpg",
        description="Test description",
        people=["Anthony Vincent", "alice dupont", "BOB MARTIN"],
        taken_at=None,
        created_at=None,
        latitude=None,
        longitude=None,
        altitude=None,
        favorite=False,
        albums=["Vacances 2024", "test album"]
    )
    # Mode append-only avec déduplication
    args = build_exiftool_args(meta, append_only=True)
    # Vérifier la normalisation et la déduplication pour PersonInImage
    expected_people = ["Anthony Vincent", "Alice Dupont", "Bob Martin"]
    for person in expected_people:
        assert f"-XMP-iptcExt:PersonInImage-={person}" in args
        assert f"-XMP-iptcExt:PersonInImage+={person}" in args
    # Vérifier la normalisation et la déduplication pour les mots-clés (personnes)
    for person in expected_people:
        assert f"-XMP-dc:Subject-={person}" in args
        assert f"-XMP-dc:Subject+={person}" in args
        assert f"-IPTC:Keywords-={person}" in args
        assert f"-IPTC:Keywords+={person}" in args
    # Vérifier la normalisation et la déduplication pour les albums
    expected_albums = ["Album: Vacances 2024", "Album: Test Album"]
    for album in expected_albums:
        assert f"-XMP-dc:Subject-={album}" in args
        assert f"-XMP-dc:Subject+={album}" in args
        assert f"-IPTC:Keywords-={album}" in args
        assert f"-IPTC:Keywords+={album}" in args
    # Vérifier qu'on n'a PAS -wm cg au début (incompatible avec suppression)
    # mais qu'on l'a réactivé pour les autres champs
    assert "-wm" in args and "cg" in args
def test_deduplication_consistency_between_modes():
    """Tester que la normalisation est cohérente entre mode append-only et écrasement."""
    meta = SidecarData(
        filename="test.jpg",
        description=None,
        people=["anthony VINCENT", "alice dupont"],
        taken_at=None,
        created_at=None,
        latitude=None,
        longitude=None,
        altitude=None,
        favorite=False,
        albums=["vacances 2024"]
    )
    # Mode append-only
    args_append = build_exiftool_args(meta, append_only=True)
    # Mode écrasement
    args_overwrite = build_exiftool_args(meta, append_only=False)
    # Vérifier que les noms normalisés sont identiques dans les deux modes
    expected_people = ["Anthony Vincent", "Alice Dupont"]
    expected_album = "Album: Vacances 2024"
    for person in expected_people:
        # En mode append-only : -=/+=
        assert f"-XMP-iptcExt:PersonInImage-={person}" in args_append
        assert f"-XMP-iptcExt:PersonInImage+={person}" in args_append
        # En mode écrasement : +=
        assert f"-XMP-iptcExt:PersonInImage+={person}" in args_overwrite
    # Album normalisé identique dans les deux modes
    assert f"-XMP-dc:Subject+={expected_album}" in args_append
    assert f"-XMP-dc:Subject+={expected_album}" in args_overwrite
def test_case_normalization_prevents_duplicates():
    """Tester que la normalisation de casse en amont évite les doublons."""
    # Simuler différentes variations de casse du même nom
    meta = SidecarData(
        filename="test.jpg",
        description=None,
        people=["anthony vincent", "ANTHONY VINCENT", "Anthony Vincent"],
        taken_at=None,
        created_at=None,
        latitude=None,
        longitude=None,
        altitude=None,
        favorite=False,
    )
    args = build_exiftool_args(meta, append_only=True)
    # Compter les occurrences du nom normalisé
    normalized_name = "Anthony Vincent"
    remove_count = args.count(f"-XMP-iptcExt:PersonInImage-={normalized_name}")
    add_count = args.count(f"-XMP-iptcExt:PersonInImage+={normalized_name}")
    # Chaque variation devrait générer une paire -=/+= 
    # donc 3 variations = 3 suppressions + 3 ajouts
    assert remove_count == 3, f"Attendu 3 suppressions, trouvé {remove_count}"
    assert add_count == 3, f"Attendu 3 ajouts, trouvé {add_count}"
def test_special_characters_in_names():
    """Tester la gestion des caractères spéciaux dans les noms."""
    meta = SidecarData(
        filename="test.jpg",
        description=None,
        people=["José García", "François Müller", "北京 Beijing"],
        taken_at=None,
        created_at=None,
        latitude=None,
        longitude=None,
        altitude=None,
        favorite=False,
    )
    args = build_exiftool_args(meta, append_only=True)
    # Vérifier que les noms avec caractères spéciaux sont préservés
    expected_names = ["José García", "François Müller", "北京 Beijing"]
    for name in expected_names:
        assert f"-XMP-iptcExt:PersonInImage-={name}" in args
        assert f"-XMP-iptcExt:PersonInImage+={name}" in args
def test_empty_values_handling():
    """Tester la gestion des valeurs vides et None."""
    meta = SidecarData(
        filename="test.jpg",
        description="",  # Vide
        people=[],       # Liste vide
        taken_at=None,
        created_at=None,
        latitude=None,
        longitude=None,
        altitude=None,
        favorite=False,
        albums=None      # None
    )
    args = build_exiftool_args(meta, append_only=True)
    # Ne devrait pas y avoir d'arguments liés aux personnes ou albums
    person_args = [arg for arg in args if "PersonInImage" in arg]
    keyword_args = [arg for arg in args if "Subject" in arg or "Keywords" in arg]
    assert len(person_args) == 0, f"Pas d'arguments PersonInImage attendus, trouvé: {person_args}"
    assert len(keyword_args) == 0, f"Pas d'arguments mots-clés attendus, trouvé: {keyword_args}"
````

## File: tests/test_end_to_end.py
````python
from pathlib import Path
import json
import subprocess
import shutil
import pytest
from PIL import Image
from google_takeout_metadata.processor import process_directory
@pytest.mark.skipif(shutil.which("exiftool") is None, reason="exiftool not installed")
def test_end_to_end(tmp_path: Path) -> None:
    # créer une image factice
    img_path = tmp_path / "sample.jpg"
    Image.new("RGB", (10, 10), color="red").save(img_path)
    # créer le sidecar correspondant
    data = {
        "title": "sample.jpg",
        "description": 'Magicien "en" or',
        "photoTakenTime": {"timestamp": "1736719606"},
        "people": [{"name": "anthony vincent"}],
    }
    (tmp_path / "sample.jpg.json").write_text(json.dumps(data), encoding="utf-8")
    process_directory(tmp_path)
    exe = shutil.which("exiftool") or "exiftool"
    result = subprocess.run(
        [
            exe,
            "-j",
            "-XMP-iptcExt:PersonInImage",
            "-XMP-dc:Subject",
            "-IPTC:Keywords",
            "-EXIF:ImageDescription",
            str(img_path),
        ],
        capture_output=True,
        text=True,
        check=True,
    )
    tags = json.loads(result.stdout)[0]
    # exiftool retourne les valeurs uniques en chaînes, les valeurs multiples en listes
    # Normaliser en listes pour la comparaison
    def normalize_to_list(value):
        if value is None:
            return []
        elif isinstance(value, list):
            return value
        else:
            return [value]
    assert normalize_to_list(tags.get("PersonInImage")) == ["Anthony Vincent"]
    assert normalize_to_list(tags.get("Subject")) == ["Anthony Vincent"]
    assert normalize_to_list(tags.get("Keywords")) == ["Anthony Vincent"]
    assert tags.get("ImageDescription") == 'Magicien "en" or'
````

## File: tests/test_exif_writer.py
````python
from google_takeout_metadata.sidecar import SidecarData
from google_takeout_metadata.exif_writer import write_metadata, build_exiftool_args
import subprocess
import pytest
from pathlib import Path
def test_write_metadata_error(tmp_path, monkeypatch):
    meta = SidecarData(
        filename="a.jpg",
        description="test",  # Add description to ensure args are generated
        people=[],
        taken_at=None,
        created_at=None,
        latitude=None,
        longitude=None,
        altitude=None,
        favorite=False,
    )
    img = tmp_path / "a.jpg"
    img.write_bytes(b"data")
    def fake_run(*args, **kwargs):
        raise subprocess.CalledProcessError(1, "exiftool", stderr="bad")
    monkeypatch.setattr(subprocess, "run", fake_run)
    with pytest.raises(RuntimeError):
        write_metadata(img, meta)
def test_build_args_video():
    """Tester que les balises spécifiques aux vidéos sont ajoutées pour les fichiers MP4/MOV."""
    meta = SidecarData(
        filename="video.mp4",
        description="Video description",
        people=["alice"],
        taken_at=1736719606,
        created_at=None,
        latitude=48.8566,
        longitude=2.3522,
        altitude=None,
        favorite=False,
    )
    video_path = Path("video.mp4")
    args = build_exiftool_args(meta, media_path=video_path)
    # Vérifier les balises spécifiques aux vidéos
    assert "-Keys:Description=Video description" in args
    assert any("-QuickTime:CreateDate=" in arg for arg in args)
    assert any("-QuickTime:ModifyDate=" in arg for arg in args)
    assert "-Keys:Location=48.8566,2.3522" in args
    assert "-QuickTime:GPSCoordinates=48.8566,2.3522" in args
    assert "-api" in args
    assert "QuickTimeUTC=1" in args
def test_build_args_localtime():
    """Tester que le formatage de l'heure locale fonctionne."""
    meta = SidecarData(
        filename="a.jpg",
        description=None,
        people=[],
        taken_at=1736719606,  # 2025-01-12 22:06:46 UTC
        created_at=None,
        latitude=None,
        longitude=None,
        altitude=None,
        favorite=False,
    )
    # Test UTC (default)
    args_utc = build_exiftool_args(meta, media_path=Path("a.jpg"), use_localtime=False)
    # Test local time
    args_local = build_exiftool_args(meta, media_path=Path("a.jpg"), use_localtime=True)
    # Les chaînes de date-heure seront différentes (sauf si exécuté dans le fuseau horaire UTC)
    # mais les deux devraient contenir une forme de DateTimeOriginal
    assert any("-DateTimeOriginal=" in arg for arg in args_utc)
    assert any("-DateTimeOriginal=" in arg for arg in args_local)
def test_build_args_append_only() -> None:
    """Tester que le mode append-only utilise l'approche anti-duplication.
    La nouvelle approche utilise -TAG-=val puis -TAG+=val pour garantir
    zéro doublon avec normalisation des noms.
    """
    meta = SidecarData(
        filename="a.jpg",
        description="desc",
        people=["alice", "bob"],
        taken_at=None,
        created_at=None,
        latitude=None,
        longitude=None,
        altitude=None,
        favorite=False,
    )
    # Normal mode (écrasement)
    args_normal = build_exiftool_args(meta, append_only=False)
    assert "-EXIF:ImageDescription=desc" in args_normal
    # En mode overwrite, on vide d'abord puis on ajoute (normalisé)
    assert "-XMP-iptcExt:PersonInImage=" in args_normal
    assert "-XMP-iptcExt:PersonInImage+=Alice" in args_normal  # Normalisé
    assert "-XMP-iptcExt:PersonInImage+=Bob" in args_normal    # Normalisé
    # Append-only mode avec déduplication
    args_append = build_exiftool_args(meta, append_only=True)
    # Nouvelle approche : supprimer puis ajouter pour déduplication
    assert "-EXIF:ImageDescription=desc" in args_append
    # Vérifier la séquence -=/+= pour PersonInImage
    assert "-XMP-iptcExt:PersonInImage-=Alice" in args_append  # Normalisé
    assert "-XMP-iptcExt:PersonInImage+=Alice" in args_append  # Normalisé
    assert "-XMP-iptcExt:PersonInImage-=Bob" in args_append    # Normalisé
    assert "-XMP-iptcExt:PersonInImage+=Bob" in args_append    # Normalisé
def test_build_args_favorite() -> None:
    """Tester que les photos favorites obtiennent rating=5."""
    meta = SidecarData(
        filename="a.jpg",
        description=None,
        people=[],
        taken_at=None,
        created_at=None,
        latitude=None,
        longitude=None,
        altitude=None,
        favorite=True,
    )
    args = build_exiftool_args(meta, append_only=False)
    assert "-XMP:Rating=5" in args
    # Tester le mode append-only (maintenant le comportement par défaut)
    args_append = build_exiftool_args(meta, append_only=True)
    # Devrait utiliser -wm cg pour l'écriture conditionnelle
    assert "-wm" in args_append
    assert "cg" in args_append
    assert "-XMP:Rating=5" in args_append
def test_build_args_no_favorite() -> None:
    """Tester que les photos non favorites n'obtiennent pas de rating."""
    meta = SidecarData(
        filename="a.jpg",
        description=None,
        people=[],
        taken_at=None,
        created_at=None,
        latitude=None,
        longitude=None,
        altitude=None,
        favorite=False,
    )
    args = build_exiftool_args(meta)
    assert not any("Rating" in arg for arg in args)
def test_build_args_albums() -> None:
    """Tester que les albums sont écrits comme mots-clés avec le préfixe Album: et normalisation."""
    meta = SidecarData(
        filename="a.jpg",
        description=None,
        people=[],
        taken_at=None,
        created_at=None,
        latitude=None,
        longitude=None,
        altitude=None,
        favorite=False,
        albums=["Vacances 2024", "Famille"]
    )
    args = build_exiftool_args(meta, append_only=False)
    # En mode overwrite, on vide d'abord puis on ajoute (avec normalisation)
    assert "-XMP-dc:Subject=" in args
    assert "-IPTC:Keywords=" in args
    # Les mots-clés sont normalisés (chaque mot avec première lettre en majuscule)
    assert "-XMP-dc:Subject+=Album: Vacances 2024" in args
    assert "-IPTC:Keywords+=Album: Vacances 2024" in args
    assert "-XMP-dc:Subject+=Album: Famille" in args
    assert "-IPTC:Keywords+=Album: Famille" in args
def test_build_args_video_append_only() -> None:
    """Tester que les balises spécifiques aux vidéos sont incluses en mode append-only."""
    meta = SidecarData(
        filename="video.mp4",
        description="Video description",
        people=["alice"],
        taken_at=1736719606,
        created_at=None,
        latitude=48.8566,
        longitude=2.3522,
        altitude=35.0,
        favorite=False,
    )
    video_path = Path("video.mp4")
    args = build_exiftool_args(meta, media_path=video_path, append_only=True)
    # Vérifier que l'approche append-only utilise -wm cg
    assert "-wm" in args
    assert "cg" in args
    assert "-Keys:Description=Video description" in args
    # Vérifier que les dates QuickTime sont présentes
    assert any("QuickTime:CreateDate=" in arg for arg in args)
    assert any("QuickTime:ModifyDate=" in arg for arg in args)
    # Vérifier que les champs GPS spécifiques à la vidéo sont présents
    assert "-QuickTime:GPSCoordinates=48.8566,2.3522" in args
    assert "-Keys:Location=48.8566,2.3522" in args
    # Vérifier que l'altitude est présente
    assert "-GPSAltitude=35.0" in args
    # Vérifier la configuration vidéo
    assert "-api" in args
    assert "QuickTimeUTC=1" in args
def test_build_args_albums_append_only() -> None:
    """Tester les albums en mode append-only avec déduplication."""
    meta = SidecarData(
        filename="a.jpg",
        description=None,
        people=[],
        taken_at=None,
        created_at=None,
        latitude=None,
        longitude=None,
        altitude=None,
        favorite=False,
        albums=["Test Album"]
    )
    args = build_exiftool_args(meta, append_only=True)
    # Nouvelle approche : supprimer puis ajouter pour déduplication
    # Les albums sont normalisés (chaque mot avec première lettre en majuscule)
    assert "-XMP-dc:Subject-=Album: Test Album" in args
    assert "-XMP-dc:Subject+=Album: Test Album" in args
    assert "-IPTC:Keywords-=Album: Test Album" in args
    assert "-IPTC:Keywords+=Album: Test Album" in args
def test_build_args_no_albums() -> None:
    """Tester que la liste d'albums vide n'ajoute aucune balise d'album."""
    meta = SidecarData(
        filename="a.jpg",
        description=None,
        people=[],
        taken_at=None,
        created_at=None,
        latitude=None,
        longitude=None,
        altitude=None,
        favorite=False,
        albums=[]
    )
    args = build_exiftool_args(meta)
    assert not any("Album:" in arg for arg in args)
def test_build_args_default_behavior() -> None:
    """Tester que le comportement par défaut est append-only (mode sécurisé)."""
    meta = SidecarData(
        filename="a.jpg",
        description="Safe description",
        people=["Safe Person"],
        taken_at=1736719606,
        created_at=None,
        latitude=48.8566,
        longitude=2.3522,
        altitude=None,
        favorite=True,
    )
    # Le comportement par défaut devrait être append-only avec déduplication robuste
    args = build_exiftool_args(meta)
    # Devrait utiliser -wm cg pour l'écriture conditionnelle de la description
    assert "-wm" in args
    assert "cg" in args
    assert "-EXIF:ImageDescription=Safe description" in args
    # Devrait utiliser l'approche robuste pour les personnes (déduplication)
    assert "-XMP-iptcExt:PersonInImage-=Safe Person" in args
    assert "-XMP-iptcExt:PersonInImage+=Safe Person" in args
    # Le rating devrait être présent
    assert "-XMP:Rating=5" in args
    # GPS devrait être présent  
    assert "-GPS:GPSLatitude=48.8566" in args
def test_build_args_overwrite_mode() -> None:
    """Mode de réécriture explicite (destructif)."""
    meta = SidecarData(
        filename="a.jpg",
        description="Overwrite description",
        people=["Overwrite Person"],
        taken_at=None,
        created_at=None,
        latitude=None,
        longitude=None,
        altitude=None,
        favorite=True,
    )
    # Mode de réécriture explicite
    args = build_exiftool_args(meta, append_only=False)
    # Devrait utiliser l'assignation directe pour les descriptions et les ratings
    assert "-EXIF:ImageDescription=Overwrite description" in args
    # En mode overwrite, on vide d'abord puis on ajoute
    assert "-XMP-iptcExt:PersonInImage=" in args
    assert "-XMP-iptcExt:PersonInImage+=Overwrite Person" in args
    assert "-XMP:Rating=5" in args
    # Ne devrait PAS avoir de conditions -if
    assert "-if" not in args
    assert "not $EXIF:ImageDescription" not in args
    assert "not $XMP-iptcExt:PersonInImage" not in args
    assert "not $XMP:Rating" not in args
def test_build_args_people_default() -> None:
    """Tester que les personnes sont gérées avec déduplication par défaut."""
    meta = SidecarData(
        filename="a.jpg",
        description=None,
        people=["Alice Dupont", "Bob Martin", "Charlie Bernard"],
        taken_at=None,
        created_at=None,
        latitude=None,
        longitude=None,
        altitude=None,
        favorite=False,
    )
    # Comportement par défaut (append-only avec déduplication)
    args = build_exiftool_args(meta)
    # Nouvelle approche : supprimer puis ajouter pour déduplication
    # Les personnes sont dans PersonInImage, mais aussi dans les mots-clés
    for person in ["Alice Dupont", "Bob Martin", "Charlie Bernard"]:
        # PersonInImage : déduplication directe
        assert f"-XMP-iptcExt:PersonInImage-={person}" in args
        assert f"-XMP-iptcExt:PersonInImage+={person}" in args
        # Mots-clés : déduplication des personnes aussi
        assert f"-XMP-dc:Subject-={person}" in args
        assert f"-XMP-dc:Subject+={person}" in args
        assert f"-IPTC:Keywords-={person}" in args
        assert f"-IPTC:Keywords+={person}" in args
    # Ne devrait PAS avoir de conditions -if (remplacé par approche -=/+=)
    assert "not $XMP-iptcExt:PersonInImage" not in args
    assert "not $XMP-dc:Subject" not in args
    assert "not $IPTC:Keywords" not in args
def test_build_args_albums_default() -> None:
    """Tester que les albums sont gérés avec déduplication par défaut."""
    meta = SidecarData(
        filename="a.jpg",
        description=None,
        people=[],
        taken_at=None,
        created_at=None,
        latitude=None,
        longitude=None,
        altitude=None,
        favorite=False,
        albums=["Vacances Été 2024", "Photos de Famille", "Événements Spéciaux"]
    )
    # Comportement par défaut (append-only avec déduplication)
    args = build_exiftool_args(meta)
    # Nouvelle approche : supprimer puis ajouter pour déduplication
    # Les albums sont normalisés avec chaque mot commençant par une majuscule
    expected_albums = ["Album: Vacances Été 2024", "Album: Photos De Famille", "Album: Événements Spéciaux"]
    for album_keyword in expected_albums:
        assert f"-XMP-dc:Subject-={album_keyword}" in args
        assert f"-XMP-dc:Subject+={album_keyword}" in args
        assert f"-IPTC:Keywords-={album_keyword}" in args
        assert f"-IPTC:Keywords+={album_keyword}" in args
    # Ne devrait PAS avoir de conditions -if pour les albums (ils sont des listes, utiliser +=)
    assert "not $XMP-dc:Subject" not in args
    assert "not $IPTC:Keywords" not in args
````

## File: tests/test_file_organization.py
````python
#!/usr/bin/env python3
"""Test de la fonctionnalité d'organisation des fichiers."""
import tempfile
import json
from pathlib import Path
from PIL import Image
from src.google_takeout_metadata.sidecar import parse_sidecar
from src.google_takeout_metadata.file_organizer import FileOrganizer, should_organize_file, get_organization_status
from src.google_takeout_metadata.processor import process_sidecar_file
def test_sidecar_parsing_with_status():
    """Test que le parsing des sidecars extrait bien les statuts archived, locked et trashed."""
    with tempfile.TemporaryDirectory() as tmp_dir:
        tmp_path = Path(tmp_dir)
        # Test fichier normal
        normal_data = {
            "title": "normal.jpg",
            "description": "Fichier normal"
        }
        normal_sidecar = tmp_path / "normal.jpg.json"
        normal_sidecar.write_text(json.dumps(normal_data), encoding="utf-8")
        meta = parse_sidecar(normal_sidecar)
        assert not meta.archived
        assert not meta.trashed
        assert not meta.locked
        # Test fichier archivé
        archived_data = {
            "title": "archived.jpg",
            "description": "Fichier archivé",
            "archived": True
        }
        archived_sidecar = tmp_path / "archived.jpg.json"
        archived_sidecar.write_text(json.dumps(archived_data), encoding="utf-8")
        meta = parse_sidecar(archived_sidecar)
        assert meta.archived
        assert not meta.trashed
        assert not meta.locked
        # Test fichier supprimé
        trashed_data = {
            "title": "trashed.jpg",
            "description": "Fichier supprimé",
            "trashed": True
        }
        trashed_sidecar = tmp_path / "trashed.jpg.json"
        trashed_sidecar.write_text(json.dumps(trashed_data), encoding="utf-8")
        meta = parse_sidecar(trashed_sidecar)
        assert not meta.archived
        assert meta.trashed
        assert not meta.locked
        # Test fichier verrouillé
        locked_data = {
            "title": "locked.jpg",
            "description": "Fichier verrouillé",
            "inLockedFolder": True
        }
        locked_sidecar = tmp_path / "locked.jpg.json"
        locked_sidecar.write_text(json.dumps(locked_data), encoding="utf-8")
        meta = parse_sidecar(locked_sidecar)
        assert not meta.archived
        assert not meta.trashed
        assert meta.locked
        # Test fichier avec les trois statuts (trashed doit l'emporter)
        both_data = {
            "title": "both.jpg",
            "description": "Fichier archivé ET supprimé",
            "archived": True,
            "trashed": True,
            "inLockedFolder": True
        }
        both_sidecar = tmp_path / "both.jpg.json"
        both_sidecar.write_text(json.dumps(both_data), encoding="utf-8")
        meta = parse_sidecar(both_sidecar)
        assert meta.archived
        assert meta.trashed
        assert meta.locked
        # Vérifier la priorité
        assert get_organization_status(meta) == "trashed"
        # Test fichier avec tous les statuts (trashed doit l'emporter)
        all_data = {
            "title": "all.jpg",
            "description": "Fichier avec tous les statuts",
            "archived": True,
            "trashed": True,
            "inLockedFolder": True
        }
        all_sidecar = tmp_path / "all.jpg.json"
        all_sidecar.write_text(json.dumps(all_data), encoding="utf-8")
        meta = parse_sidecar(all_sidecar)
        assert meta.archived
        assert meta.trashed
        assert meta.locked
        # Vérifier la priorité (trashed > locked > archived)
        assert get_organization_status(meta) == "trashed"
        print("✅ Test parsing des statuts réussi !")
def test_file_organization_logic():
    """Test de la logique d'organisation des fichiers."""
    with tempfile.TemporaryDirectory() as tmp_dir:
        tmp_path = Path(tmp_dir)
        organizer = FileOrganizer(tmp_path)
        # Test fichier normal - pas de déplacement
        from src.google_takeout_metadata.sidecar import SidecarData
        normal_meta = SidecarData(
            filename="normal.jpg",
            description=None,
            people=[],
            taken_at=None,
            created_at=None,
            latitude=None,
            longitude=None,
            altitude=None
        )
        assert organizer.get_target_directory(normal_meta) is None
        assert not should_organize_file(normal_meta)
        # Test fichier archivé
        archived_meta = SidecarData(
            filename="archived.jpg",
            description=None,
            people=[],
            taken_at=None,
            created_at=None,
            latitude=None,
            longitude=None,
            altitude=None,
            archived=True
        )
        assert organizer.get_target_directory(archived_meta) == organizer.archive_dir
        assert should_organize_file(archived_meta)
        # Test fichier supprimé
        trashed_meta = SidecarData(
            filename="trashed.jpg",
            description=None,
            people=[],
            taken_at=None,
            created_at=None,
            latitude=None,
            longitude=None,
            altitude=None,
            trashed=True
        )
        assert organizer.get_target_directory(trashed_meta) == organizer.trash_dir
        assert should_organize_file(trashed_meta)
        # Test fichier verrouillé
        locked_meta = SidecarData(
            filename="locked.jpg",
            description=None,
            people=[],
            taken_at=None,
            created_at=None,
            latitude=None,
            longitude=None,
            altitude=None,
            locked=True
        )
        assert organizer.get_target_directory(locked_meta) == organizer.locked_dir
        assert should_organize_file(locked_meta)
        # Test priorité: trashed l'emporte sur locked qui l'emporte sur archived
        both_meta = SidecarData(
            filename="both.jpg",
            description=None,
            people=[],
            taken_at=None,
            created_at=None,
            latitude=None,
            longitude=None,
            altitude=None,
            archived=True,
            locked=True,
            trashed=True
        )
        assert organizer.get_target_directory(both_meta) == organizer.trash_dir
        assert should_organize_file(both_meta)
        # Test priorité: trashed > locked > archived
        all_meta = SidecarData(
            filename="all.jpg",
            description=None,
            people=[],
            taken_at=None,
            created_at=None,
            latitude=None,
            longitude=None,
            altitude=None,
            archived=True,
            trashed=True,
            locked=True
        )
        assert organizer.get_target_directory(all_meta) == organizer.trash_dir
        assert should_organize_file(all_meta)
        # Test priorité: locked > archived
        locked_archived_meta = SidecarData(
            filename="locked_archived.jpg",
            description=None,
            people=[],
            taken_at=None,
            created_at=None,
            latitude=None,
            longitude=None,
            altitude=None,
            archived=True,
            locked=True
        )
        assert organizer.get_target_directory(locked_archived_meta) == organizer.locked_dir
        assert should_organize_file(locked_archived_meta)
        print("✅ Test logique d'organisation réussi !")
def test_file_organization_end_to_end():
    """Test end-to-end de l'organisation des fichiers."""
    with tempfile.TemporaryDirectory() as tmp_dir:
        tmp_path = Path(tmp_dir)
        # Créer une image de test
        img_path = tmp_path / "archived_photo.jpg"
        img = Image.new('RGB', (100, 100), color='blue')
        img.save(img_path)
        # Créer un sidecar pour fichier archivé
        sidecar_data = {
            "title": "archived_photo.jpg",
            "description": "Photo archivée",
            "archived": True
        }
        sidecar_path = tmp_path / "archived_photo.jpg.json"
        sidecar_path.write_text(json.dumps(sidecar_data), encoding="utf-8")
        # Vérifier que les fichiers existent initialement
        assert img_path.exists()
        assert sidecar_path.exists()
        # Traiter avec organisation
        process_sidecar_file(sidecar_path, organize_files=True)
        # Vérifier que les répertoires ont été créés
        archive_dir = tmp_path / "_Archive"
        assert archive_dir.exists()
        # Vérifier que les fichiers ont été déplacés
        moved_img = archive_dir / "archived_photo.jpg"
        moved_sidecar = archive_dir / "OK_archived_photo.jpg.json"
        assert moved_img.exists()
        assert moved_sidecar.exists()
        assert not img_path.exists()  # Fichier original déplacé
        print("✅ Test end-to-end d'organisation réussi !")
if __name__ == "__main__":
    test_sidecar_parsing_with_status()
    test_file_organization_logic() 
    test_file_organization_end_to_end()
    print("\n🎉 Tous les tests d'organisation réussis !")
````

## File: tests/test_improvements.py
````python
"""Tests unitaires pour les améliorations des statistiques et de la recherche d'albums."""
import json
import pytest
import subprocess
import tempfile
from pathlib import Path
from unittest.mock import patch
from PIL import Image
from google_takeout_metadata.processor_batch import process_batch
from google_takeout_metadata.sidecar import find_albums_for_directory
from google_takeout_metadata.statistics import ProcessingStats
class TestProcessingStats:
    """Tests pour la classe ProcessingStats."""
    def test_init(self):
        """Test de l'initialisation des statistiques."""
        stats = ProcessingStats()
        assert stats.total_sidecars_found == 0
        assert stats.total_processed == 0
        assert stats.total_failed == 0
        assert stats.total_skipped == 0
        assert stats.images_processed == 0
        assert stats.videos_processed == 0
        assert stats.files_fixed_extension == 0
        assert stats.sidecars_cleaned == 0
        assert stats.failed_files == []
        assert stats.skipped_files == []
        assert stats.fixed_extensions == []
        assert stats.errors_by_type == {}
        assert stats.start_time is None
        assert stats.end_time is None
    def test_add_processed_file(self):
        """Test de l'ajout de fichiers traités."""
        stats = ProcessingStats()
        # Test image
        stats.add_processed_file(is_image=True)
        assert stats.total_processed == 1
        assert stats.images_processed == 1
        assert stats.videos_processed == 0
        # Test vidéo
        stats.add_processed_file(is_image=False)
        assert stats.total_processed == 2
        assert stats.images_processed == 1
        assert stats.videos_processed == 1
    def test_add_failed_file(self):
        """Test de l'ajout de fichiers en échec."""
        stats = ProcessingStats()
        test_path = Path("test_file.jpg")
        stats.add_failed_file(test_path, "parse_error", "JSON invalide")
        assert stats.total_failed == 1
        assert len(stats.failed_files) == 1
        assert stats.failed_files[0] == "test_file.jpg: JSON invalide"
        assert stats.errors_by_type["parse_error"] == 1
        # Test comptage des erreurs par type
        stats.add_failed_file(test_path, "parse_error", "Autre erreur JSON")
        assert stats.errors_by_type["parse_error"] == 2
    def test_add_skipped_file(self):
        """Test de l'ajout de fichiers ignorés."""
        stats = ProcessingStats()
        test_path = Path("test_file.jpg")
        stats.add_skipped_file(test_path, "Fichier déjà traité")
        assert stats.total_skipped == 1
        assert len(stats.skipped_files) == 1
        assert stats.skipped_files[0] == "test_file.jpg: Fichier déjà traité"
    def test_add_fixed_extension(self):
        """Test de l'ajout de corrections d'extension."""
        stats = ProcessingStats()
        stats.add_fixed_extension("image.png", "image.jpg")
        assert stats.files_fixed_extension == 1
        assert len(stats.fixed_extensions) == 1
        assert stats.fixed_extensions[0] == "image.png → image.jpg"
    def test_success_rate(self):
        """Test du calcul du taux de réussite."""
        stats = ProcessingStats()
        # Aucun fichier
        assert stats.success_rate == 0.0
        # Quelques fichiers
        stats.total_sidecars_found = 10
        stats.total_processed = 8
        assert stats.success_rate == 80.0
        # Tous réussis
        stats.total_processed = 10
        assert stats.success_rate == 100.0
    def test_timing(self):
        """Test du système de timing."""
        stats = ProcessingStats()
        assert stats.duration is None
        stats.start_processing()
        assert stats.start_time is not None
        assert stats.duration is None
        stats.end_processing()
        assert stats.end_time is not None
        assert stats.duration is not None
        assert stats.duration >= 0
class TestFindAlbumsForDirectory:
    """Tests pour la fonction find_albums_for_directory améliorée."""
    def test_empty_directory(self):
        """Test avec un répertoire vide."""
        with tempfile.TemporaryDirectory() as temp_dir:
            result = find_albums_for_directory(Path(temp_dir))
            assert result == []
    def test_case_insensitive_metadata_files(self):
        """Test de la gestion insensible à la casse."""
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)
            # Créer des fichiers avec différentes casses
            (temp_path / "METADATA.JSON").write_text('{"title": "Album1"}', encoding='utf-8')
            (temp_path / "métadonnées.json").write_text('{"title": "Album2"}', encoding='utf-8')
            (temp_path / "Album_Metadata.JSON").write_text('{"title": "Album3"}', encoding='utf-8')
            result = find_albums_for_directory(temp_path)
            # Doit trouver tous les albums
            assert len(result) == 3
            assert "Album1" in result
            assert "Album2" in result
            assert "Album3" in result
    def test_numbered_variations_case_insensitive(self):
        """Test des variations numérotées insensibles à la casse."""
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)
            # Créer des fichiers avec variations numérotées et casses différentes
            (temp_path / "Métadonnées(1).JSON").write_text('{"title": "Album1"}', encoding='utf-8')
            (temp_path / "MÉTADONNÉES(2).json").write_text('{"title": "Album2"}', encoding='utf-8')
            result = find_albums_for_directory(temp_path)
            assert len(result) == 2
            assert "Album1" in result
            assert "Album2" in result
    def test_max_depth_limit(self):
        """Test de la limite de profondeur."""
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)
            # Créer une hiérarchie simple : temp_dir/parent/current
            parent_dir = temp_path / "parent"
            parent_dir.mkdir()
            current_dir = parent_dir / "current"
            current_dir.mkdir()
            # Ajouter un album au niveau parent
            (parent_dir / "metadata.json").write_text('{"title": "ParentAlbum"}', encoding='utf-8')
            # Ajouter un album au niveau racine (temp_dir)
            (temp_path / "metadata.json").write_text('{"title": "RootAlbum"}', encoding='utf-8')
            # Test avec max_depth=2 (permet de vérifier current_dir et parent_dir)
            result = find_albums_for_directory(current_dir, max_depth=2)
            assert "ParentAlbum" in result
            assert "RootAlbum" not in result  # temp_dir est à depth=2, donc exclu
            # Test avec max_depth=3 (permet de vérifier current_dir, parent_dir et temp_dir)
            result_full = find_albums_for_directory(current_dir, max_depth=3)
            assert "ParentAlbum" in result_full
            assert "RootAlbum" in result_full
            # Test avec max_depth=1 (ne vérifie que current_dir)
            result_limited = find_albums_for_directory(current_dir, max_depth=1)
            assert len(result_limited) == 0  # pas d'album dans current_dir
    def test_takeout_marker_detection(self):
        """Test de la détection des répertoires marqueurs."""
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)
            # Créer une hiérarchie avec marqueur
            root_dir = temp_path / "root"
            root_dir.mkdir()
            takeout_dir = root_dir / "mon-takeout" 
            takeout_dir.mkdir()
            photos_dir = takeout_dir / "photos"
            photos_dir.mkdir()
            # Ajouter un album au niveau root (plus haut que le marqueur)
            (root_dir / "metadata.json").write_text('{"title": "RootAlbum"}', encoding='utf-8')
            result = find_albums_for_directory(photos_dir)
            # Doit s'arrêter au marqueur et ne pas remonter jusqu'au root
            assert "RootAlbum" not in result
    def test_order_preservation(self):
        """Test de la préservation de l'ordre de priorité."""
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)
            # Créer une hiérarchie avec albums à différents niveaux
            level1 = temp_path / "level1"
            level1.mkdir()
            # Album au niveau courant (priorité haute)
            (temp_path / "metadata.json").write_text('{"title": "CurrentLevel"}', encoding='utf-8')
            # Album au niveau parent (priorité basse)
            (level1 / "metadata.json").write_text('{"title": "ParentLevel"}', encoding='utf-8')
            result = find_albums_for_directory(temp_path)
            # L'album du niveau courant doit être en premier
            assert result[0] == "CurrentLevel"
    def test_error_handling(self):
        """Test de la gestion d'erreurs."""
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)
            # Créer un fichier JSON invalide
            (temp_path / "metadata.json").write_text('{"invalid": json}', encoding='utf-8')
            # Créer un fichier JSON valide
            (temp_path / "album_metadata.json").write_text('{"title": "ValidAlbum"}', encoding='utf-8')
            # La fonction doit continuer malgré l'erreur
            result = find_albums_for_directory(temp_path)
            # Doit trouver l'album valide
            assert "ValidAlbum" in result
    @patch('google_takeout_metadata.sidecar.logger')
    def test_debug_logging(self, mock_logger):
        """Test des logs debug."""
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)
            # Créer une hiérarchie avec marqueur et album au-dessus
            root_dir = temp_path / "root"
            root_dir.mkdir()
            takeout_dir = root_dir / "Google Photos"  # Un marqueur sûr
            takeout_dir.mkdir()
            photos_dir = takeout_dir / "photos"
            photos_dir.mkdir()
            # Ajouter un album au niveau root pour forcer la remontée
            (root_dir / "metadata.json").write_text('{"title": "RootAlbum"}', encoding='utf-8')
            find_albums_for_directory(photos_dir)
            # Vérifier que le debug a été appelé (pour n'importe quel message debug)
            assert mock_logger.debug.called, "Aucun appel au logger.debug détecté"
            # Vérifier les appels debug pour trouver celui du marqueur
            debug_calls = [str(call) for call in mock_logger.debug.call_args_list]
            # Chercher un message contenant "marqueur"
            marker_calls = [call for call in debug_calls if "marqueur" in call.lower()]
            assert len(marker_calls) > 0, f"Pas de log marqueur trouvé dans: {debug_calls}"
            calls = [call for call in mock_logger.debug.call_args_list 
                    if "répertoire marqueur" in str(call)]
            assert len(calls) > 0
@pytest.mark.integration 
def test_batch_sidecar_cleanup_with_real_failure(tmp_path: Path) -> None:
    """Tester que les sidecars NE SONT PAS supprimés quand exiftool échoue vraiment (erreur grave).
    LOGIQUE MÉTIER: On ne supprime le sidecar QUE si le traitement exiftool a réussi.
    Un échec exiftool signifie que les métadonnées n'ont pas été appliquées -> garder le sidecar pour retry ultérieur.
    """
    # Créer une image de test
    media_path = tmp_path / "test.jpg"
    img = Image.new('RGB', (100, 100), color='blue')
    img.save(media_path)
    # Créer le sidecar JSON avec des arguments invalides qui vont causer une vraie erreur exiftool
    sidecar_data = {
        "title": "test.jpg",
        "description": "Test description"
    }
    json_path = tmp_path / "test.jpg.supplemental-metadata.json"
    json_path.write_text(json.dumps(sidecar_data), encoding="utf-8")
    # Vérifier que le sidecar existe avant traitement
    assert json_path.exists()
    # Créer un lot avec des arguments invalides qui causeront un échec exiftool
    # Utilisons un fichier inexistant pour garantir un échec
    non_existent_file = tmp_path / "non_existent.jpg"
    invalid_args = ["-Comment=Test"]  # Arguments valides mais fichier inexistant
    batch = [(non_existent_file, json_path, invalid_args)]
    # Traiter le lot avec suppression immédiate activée (immediate_delete=True)
    # Ceci devrait échouer à cause des arguments invalides
    result = process_batch(batch, immediate_delete=True)
    # Vérifier que le traitement a échoué
    assert result == 0, "Le traitement aurait dû échouer avec des arguments invalides"
    # CORRECTION: Le sidecar ne doit PAS être supprimé car le traitement a échoué
    assert json_path.exists(), "Le sidecar ne doit PAS être supprimé si exiftool échoue - il faut le garder pour retry"
@pytest.mark.integration
def test_batch_sidecar_cleanup_with_condition_success(tmp_path: Path) -> None:
    """Tester que les sidecars SONT supprimés quand 'files failed condition' en mode append-only.
    CLARIFICATION: 'files failed condition' en mode append-only n'est PAS un échec exiftool,
    c'est le comportement normal quand les métadonnées existent déjà. Dans ce cas, on peut supprimer le sidecar.
    """
    # Créer une image de test
    media_path = tmp_path / "test.jpg"
    img = Image.new('RGB', (100, 100), color='blue')
    img.save(media_path)
    # Ajouter des métadonnées existantes (description EXIF)
    try:
        subprocess.run([
            "exiftool", "-overwrite_original",
            "-EXIF:ImageDescription=Existing description",
            str(media_path)
        ], capture_output=True, text=True, check=True, timeout=30)
    except FileNotFoundError:
        pytest.skip("exiftool introuvable - skipping integration test")
    # Créer le sidecar JSON avec une description (qui causera "files failed condition" en mode append-only)
    sidecar_data = {
        "title": "test.jpg", 
        "description": "New description that should not overwrite existing"
    }
    json_path = tmp_path / "test.jpg.supplemental-metadata.json"
    json_path.write_text(json.dumps(sidecar_data), encoding="utf-8")
    # Vérifier que le sidecar existe avant traitement
    assert json_path.exists()
    # Traiter avec process_sidecar_file en mode append-only (comportement normal)
    from google_takeout_metadata.processor import process_sidecar_file
    process_sidecar_file(json_path, append_only=True, immediate_delete=True)
    # Vérifier que le sidecar a été supprimé car le traitement a "réussi" 
    # (même si condition failed, c'est le comportement normal en append-only)
    assert not json_path.exists(), "Le sidecar doit être supprimé après traitement append-only, même avec 'condition failed'"
def test_batch_cleanup_logic_unit() -> None:
    """Test unitaire pour vérifier la logique de nettoyage en cas de 'files failed condition'."""
    # Ce test vérifie que notre modification de code est cohérente
    # Il ne teste pas exiftool mais la logique interne
    from google_takeout_metadata.processor_batch import process_batch
    import tempfile
    from pathlib import Path
    import json
    from unittest.mock import patch
    with tempfile.TemporaryDirectory() as tmp_dir:
        tmp_path = Path(tmp_dir)
        # Créer des fichiers factices
        media_path = tmp_path / "test.jpg"
        media_path.write_text("fake image content")
        json_path = tmp_path / "test.jpg.supplemental-metadata.json"
        sidecar_data = {"title": "test.jpg", "description": "Test description"}
        json_path.write_text(json.dumps(sidecar_data))
        batch = [(media_path, json_path, ["-description=test"])]
        # Mock subprocess.run pour simuler "files failed condition"
        mock_error = subprocess.CalledProcessError(2, "exiftool")
        mock_error.stderr = "2 files failed condition"
        mock_error.stdout = ""
        with patch('google_takeout_metadata.processor_batch.subprocess.run', side_effect=mock_error):
            # Vérifier que le fichier existe avant
            assert json_path.exists()
            # Appeler process_batch avec immediate_delete=True
            result = process_batch(batch, immediate_delete=True)
            # Vérifier le succès et la suppression
            assert result == 1, "Le batch devrait être considéré comme réussi"
            assert not json_path.exists(), "Le sidecar aurait dû être supprimé même avec 'files failed condition'"
if __name__ == "__main__":
    pytest.main([__file__, "-v"])
````

## File: tests/test_integration.py
````python
"""Tests d'intégration qui exécutent réellement exiftool et vérifient que les métadonnées sont écrites correctement."""
from pathlib import Path
import json
import subprocess
import pytest
import shutil
from PIL import Image
from google_takeout_metadata.processor import process_sidecar_file
from google_takeout_metadata.exif_writer import write_metadata
from google_takeout_metadata.sidecar import SidecarData
def _get_test_assets_dir() -> Path:
    """Retourne le chemin vers le dossier des assets de test."""
    return Path(__file__).parent.parent / "test_assets"
def _copy_test_asset(asset_name: str, dest_path: Path) -> None:
    """Copie un asset de test vers le chemin de destination."""
    assets_dir = _get_test_assets_dir()
    asset_path = assets_dir / asset_name
    if not asset_path.exists():
        pytest.skip(f"Asset de test {asset_name} introuvable dans {assets_dir}")
    shutil.copy2(asset_path, dest_path)
def _run_exiftool_read(media_path: Path) -> dict:
    """Exécuter exiftool pour lire les métadonnées depuis un fichier image."""
    cmd = [
        "exiftool", 
        "-json",
        "-charset", "filename=UTF8",
        "-charset", "iptc=UTF8", 
        "-charset", "exif=UTF8",
        "-charset", "XMP=UTF8",
        str(media_path)
    ]
    try:
        result = subprocess.run(cmd, capture_output=True, text=True, check=True, timeout=30)
        data = json.loads(result.stdout)
        return data[0] if data else {}
    except FileNotFoundError:
        pytest.skip("exiftool introuvable - skipping integration tests")
    except subprocess.CalledProcessError as e:
        pytest.fail(f"exiftool failed: {e.stderr}")
@pytest.mark.integration
def test_write_and_read_description(tmp_path: Path) -> None:
    """Tester que la description est écrite et peut être relue."""
    # Utiliser un asset de test propre
    media_path = tmp_path / "test.jpg"
    _copy_test_asset("test_clean.jpg", media_path)
    # Créer le JSON sidecar
    sidecar_data = {
        "title": "test.jpg",
        "description": "Test photo with ñ and émojis 🎉"
    }
    json_path = tmp_path / "test.jpg.json"
    json_path.write_text(json.dumps(sidecar_data), encoding="utf-8")
    # Traiter le sidecar
    process_sidecar_file(json_path)
    # Relire les métadonnées
    metadata = _run_exiftool_read(media_path)
    # Vérifier que la description a été écrite
    assert metadata.get("Description") == "Test photo with ñ and émojis 🎉"
    assert metadata.get("ImageDescription") == "Test photo with ñ and émojis 🎉"
@pytest.mark.integration
def test_write_and_read_people(tmp_path: Path) -> None:
    """Tester que les noms de personnes sont écrits et peuvent être relus."""
    # Utiliser un asset de test propre
    media_path = tmp_path / "test.jpg"
    _copy_test_asset("test_clean.jpg", media_path)
    # Créer le JSON sidecar avec des personnes
    sidecar_data = {
        "title": "test.jpg",
        "people": [
            {"name": "Alice Dupont"},
            {"name": "Bob Martin"}
        ]
    }
    json_path = tmp_path / "test.jpg.json"
    json_path.write_text(json.dumps(sidecar_data), encoding="utf-8")
    # Traiter le sidecar
    process_sidecar_file(json_path)
    # Relire les métadonnées
    metadata = _run_exiftool_read(media_path)
    # Vérifier que les personnes ont été écrites
    keywords = metadata.get("Keywords", [])
    if isinstance(keywords, str):
        keywords = [keywords]
    assert "Alice Dupont" in keywords
    assert "Bob Martin" in keywords
@pytest.mark.integration 
def test_write_and_read_gps(tmp_path: Path) -> None:
    """Tester que les coordonnées GPS sont écrites et peuvent être relues."""
    # Utiliser un asset de test propre
    media_path = tmp_path / "test.jpg"
    _copy_test_asset("test_clean.jpg", media_path)
    # Créer le JSON sidecar avec des données GPS
    sidecar_data = {
        "title": "test.jpg",
        "geoData": {
            "latitude": 48.8566,
            "longitude": 2.3522,
            "altitude": 35.0
        }
    }
    json_path = tmp_path / "test.jpg.json"
    json_path.write_text(json.dumps(sidecar_data), encoding="utf-8")
    # Traiter le sidecar
    process_sidecar_file(json_path)
    # Relire les métadonnées
    metadata = _run_exiftool_read(media_path)
    # Vérifier que les données GPS ont été écrites
    # exiftool retourne les coordonnées GPS dans un format lisible, donc on doit vérifier différemment
    gps_lat = metadata.get("GPSLatitude")
    gps_lon = metadata.get("GPSLongitude")
    # Vérifier que les champs GPS existent et contiennent les valeurs de degrés attendues
    assert gps_lat is not None, "GPSLatitude devrait être définie"
    assert gps_lon is not None, "GPSLongitude devrait être définie"
    assert "48 deg" in str(gps_lat), f"Expected 48 degrees in latitude, got: {gps_lat}"
    assert "2 deg" in str(gps_lon), f"Expected 2 degrees in longitude, got: {gps_lon}"
    # Les références GPS peuvent être "N"/"North" et "E"/"East" selon la version d'exiftool
    lat_ref = metadata.get("GPSLatitudeRef")
    lon_ref = metadata.get("GPSLongitudeRef")
    assert lat_ref in ["N", "North"], f"Expected N or North for latitude ref, got: {lat_ref}"
    assert lon_ref in ["E", "East"], f"Expected E or East for longitude ref, got: {lon_ref}"
@pytest.mark.integration
def test_write_and_read_favorite(tmp_path: Path) -> None:
    """Tester que le statut favori est écrit comme notation."""
    # Créer une image de test simple
    media_path = tmp_path / "test.jpg"
    img = Image.new('RGB', (100, 100), color='yellow')
    img.save(media_path)
    # Créer le fichier JSON annexe avec favori
    sidecar_data = {
        "title": "test.jpg",
        "favorited": True
    }
    json_path = tmp_path / "test.jpg.json"
    json_path.write_text(json.dumps(sidecar_data), encoding="utf-8")
    # Traiter le sidecar
    process_sidecar_file(json_path)
    # Relire les métadonnées
    metadata = _run_exiftool_read(media_path)
    # Vérifier que la notation a été écrite
    assert int(metadata.get("Rating", 0)) == 5
@pytest.mark.integration
def test_append_only_mode(tmp_path: Path) -> None:
    """Tester que le mode append-only n'écrase pas la description existante."""
    # Utiliser un asset de test avec métadonnées existantes
    media_path = tmp_path / "test.jpg"
    _copy_test_asset("test_with_metadata.jpg", media_path)
    # Créer le fichier JSON annexe avec une description différente
    sidecar_data = {
        "title": "test.jpg", 
        "description": "New description from sidecar"
    }
    json_path = tmp_path / "test.jpg.json"
    json_path.write_text(json.dumps(sidecar_data), encoding="utf-8")
    # Traiter le sidecar en mode append-only
    process_sidecar_file(json_path, append_only=True)
    # Relire les métadonnées
    metadata = _run_exiftool_read(media_path)
    # En mode append-only, la description originale devrait être préservée
    # Note: exiftool's -= operator doesn't overwrite if field exists
    assert metadata.get("ImageDescription") == "Existing description"
@pytest.mark.integration
def test_datetime_formats(tmp_path: Path) -> None:
    """Tester que la date-heure est écrite dans le bon format."""
    # Créer une image de test simple
    media_path = tmp_path / "test.jpg"
    img = Image.new('RGB', (100, 100), color='orange')
    img.save(media_path)
    # Créer le fichier JSON annexe avec horodatage
    sidecar_data = {
        "title": "test.jpg",
        "photoTakenTime": {"timestamp": "1736719606"}  # Horodatage Unix
    }
    json_path = tmp_path / "test.jpg.json"
    json_path.write_text(json.dumps(sidecar_data), encoding="utf-8")
    # Traiter le sidecar
    process_sidecar_file(json_path)
    # Relire les métadonnées
    metadata = _run_exiftool_read(media_path)
    # Vérifier le format de la date-heure (devrait être YYYY:MM:DD HH:MM:SS)
    date_original = metadata.get("DateTimeOriginal")
    assert date_original is not None
    assert ":" in date_original
    # Devrait correspondre au format EXIF datetime
    import re
    assert re.match(r'\d{4}:\d{2}:\d{2} \d{2}:\d{2}:\d{2}', date_original)
@pytest.mark.integration
def test_write_and_read_albums(tmp_path: Path) -> None:
    """Tester que les albums sont écrits et peuvent être relus."""
    # Créer une image de test simple
    media_path = tmp_path / "test.jpg"
    img = Image.new('RGB', (100, 100), color='cyan')
    img.save(media_path)
    # Créer le fichier metadata.json d'album
    album_data = {"title": "Vacances Été 2024"}
    metadata_path = tmp_path / "metadata.json"
    metadata_path.write_text(json.dumps(album_data), encoding="utf-8")
    # Créer le fichier JSON annexe
    sidecar_data = {
        "title": "test.jpg",
        "description": "Photo de vacances"
    }
    json_path = tmp_path / "test.jpg.json"
    json_path.write_text(json.dumps(sidecar_data), encoding="utf-8")
    # Traiter le sidecar
    process_sidecar_file(json_path)
    # Relire les métadonnées
    metadata = _run_exiftool_read(media_path)
    # Vérifier que l'album a été écrit comme mot-clé
    keywords = metadata.get("Keywords", [])
    if isinstance(keywords, str):
        keywords = [keywords]
    assert "Album: Vacances Été 2024" in keywords
    # Vérifier aussi le champ Subject
    subjects = metadata.get("Subject", [])
    if isinstance(subjects, str):
        subjects = [subjects]
    assert "Album: Vacances Été 2024" in subjects
@pytest.mark.integration  
def test_albums_and_people_combined(tmp_path: Path) -> None:
    """Tester que les albums et les personnes peuvent coexister dans les mots-clés."""
    # Créer une image de test simple
    media_path = tmp_path / "test.jpg"
    img = Image.new('RGB', (100, 100), color='magenta')
    img.save(media_path)
    # Créer le fichier metadata.json d'album
    album_data = {"title": "Album Famille"}
    metadata_path = tmp_path / "metadata.json"
    metadata_path.write_text(json.dumps(album_data), encoding="utf-8")
    # Créer le fichier JSON annexe avec des personnes
    sidecar_data = {
        "title": "test.jpg",
        "people": [{"name": "Alice"}, {"name": "Bob"}]
    }
    json_path = tmp_path / "test.jpg.json"
    json_path.write_text(json.dumps(sidecar_data), encoding="utf-8")
    # Traiter le sidecar
    process_sidecar_file(json_path)
    # Relire les métadonnées
    metadata = _run_exiftool_read(media_path)
    # Vérifier que les mots-clés contiennent à la fois les personnes et l'album
    keywords = metadata.get("Keywords", [])
    if isinstance(keywords, str):
        keywords = [keywords]
    # Vérifier que nous avons à la fois des personnes et un album
    assert "Alice" in keywords
    assert "Bob" in keywords
    assert "Album: Album Famille" in keywords
@pytest.mark.integration
def test_default_safe_behavior(tmp_path: Path) -> None:
    """Tester que le comportement par défaut est sûr (append-only) et préserve les métadonnées existantes."""
    # Créer une simple image de test
    media_path = tmp_path / "test.jpg"
    img = Image.new('RGB', (100, 100), color='red')
    img.save(media_path)
    # Tout d'abord, ajouter manuellement des métadonnées en utilisant le mode écrasement
    first_meta = SidecarData(
        filename="test.jpg",
        description="Original description",
        people=["Original Person"],
        taken_at=None,
        created_at=None,
        latitude=None,
        longitude=None,
        altitude=None,
        favorite=False,
        albums=["Original Album"]
    )
    # Écrire les métadonnées initiales avec le mode écrasement
    write_metadata(media_path, first_meta, append_only=False)
    # Vérifier que les métadonnées initiales ont été écrites
    initial_metadata = _run_exiftool_read(media_path)
    assert initial_metadata.get("ImageDescription") == "Original description"
    initial_keywords = initial_metadata.get("Keywords", [])
    if isinstance(initial_keywords, str):
        initial_keywords = [initial_keywords]
    assert "Original Person" in initial_keywords
    assert "Album: Original Album" in initial_keywords
    # Créer le fichier JSON annexe avec une nouvelle description et une nouvelle personne
    sidecar_data = {
        "title": "test.jpg",
        "description": "New description", 
        "people": [{"name": "New Person"}]
    }
    json_path = tmp_path / "test.jpg.json"
    json_path.write_text(json.dumps(sidecar_data), encoding="utf-8")
    # Traiter le sidecar en mode par défaut (append-only)
    process_sidecar_file(json_path)
    # Relire les métadonnées
    final_metadata = _run_exiftool_read(media_path)
    # En mode append-only, la description d'origine doit être préservée
    # car nous utilisons -if "not $TAG" qui n'écrit que si le tag n'existe pas
    assert final_metadata.get("ImageDescription") == "Original description"
    # Les mots-clés devraient toujours contenir les données d'origine, et les nouvelles personnes devraient être AJOUTÉES (pas remplacées)
    # car nous utilisons = qui accumule pour les balises de type liste
    final_keywords = final_metadata.get("Keywords", [])
    if isinstance(final_keywords, str):
        final_keywords = [final_keywords]
    assert "Original Person" in final_keywords
    assert "Album: Original Album" in final_keywords
    # La nouvelle personne devrait également être présente
    assert "New Person" in final_keywords
@pytest.mark.integration  
def test_explicit_overwrite_behavior(tmp_path: Path) -> None:
    """Tester que le mode écrasement explicite remplace les métadonnées existantes."""
    # Créer une simple image de test
    media_path = tmp_path / "test.jpg"
    img = Image.new('RGB', (100, 100), color='blue') 
    img.save(media_path)
    # Tout d'abord, ajouter des métadonnées initiales en utilisant le mode écrasement
    first_meta = SidecarData(
        filename="test.jpg",
        description="Original description",
        people=["Original Person"],
        taken_at=None,
        created_at=None,
        latitude=None,
        longitude=None,
        altitude=None,
        favorite=False,
        albums=[]
    )
    write_metadata(media_path, first_meta, append_only=False)
    # Vérifier que les métadonnées initiales ont été écrites
    sidecar_data = {
        "title": "test.jpg",
        "description": "New description",
        "people": [{"name": "New Person"}]
    }
    json_path = tmp_path / "test.jpg.json"
    json_path.write_text(json.dumps(sidecar_data), encoding="utf-8")
    # Traiter le sidecar en mode écrasement explicite
    process_sidecar_file(json_path, append_only=False)
    # Relire les métadonnées
    final_metadata = _run_exiftool_read(media_path)
    # En mode écrasement, la nouvelle description doit remplacer l'ancienne
    # Note: Nous utilisons l'opérateur = donc les personnes sont ajoutées et accumulent
    final_keywords = final_metadata.get("Keywords", [])
    if isinstance(final_keywords, str):
        final_keywords = [final_keywords]
    # Les deux personnes, originale et nouvelle, devraient être présentes (car = accumule pour les listes)
    assert "Original Person" in final_keywords
    assert "New Person" in final_keywords
@pytest.mark.integration
def test_append_only_vs_overwrite_video_equivalence(tmp_path: Path) -> None:
    """Tester que le mode append-only produit des résultats similaires au mode écrasement pour les vidéos quand aucune métadonnée n'existe."""
    # Copier les fichiers vidéo de test (vierges)
    video_path_append = tmp_path / "test_append.mp4"
    video_path_overwrite = tmp_path / "test_overwrite.mp4"
    _copy_test_asset("test_video_clean.mp4", video_path_append)
    _copy_test_asset("test_video_clean.mp4", video_path_overwrite)
    # Créer les métadonnées à écrire
    meta = SidecarData(
        filename="test.mp4",
        description="Test video description",
        people=["Video Person"],
        taken_at=1736719606,
        created_at=None,
        latitude=48.8566,
        longitude=2.3522,
        altitude=35.0,
        favorite=True,
        albums=["Test Album"]
    )
    # Écrire avec le mode append-only
    write_metadata(video_path_append, meta, append_only=True)
    # Écrire avec le mode écrasement
    write_metadata(video_path_overwrite, meta, append_only=False)
    # Relire les métadonnées des deux fichiers
    metadata_append = _run_exiftool_read(video_path_append)
    metadata_overwrite = _run_exiftool_read(video_path_overwrite)
    # Comparer les champs clés
    # En mode append-only, les nouvelles métadonnées peuvent ne pas être écrites si des tags similaires existent
    # En mode overwrite, les métadonnées sont toujours écrites
    # Le test vérifie que les nouvelles métadonnées importantes sont présentes
    # Les mots-clés devraient contenir la personne et l'album dans les deux modes
    keywords_append = metadata_append.get("Keywords", [])
    keywords_overwrite = metadata_overwrite.get("Keywords", [])
    if isinstance(keywords_append, str):
        keywords_append = [keywords_append]
    if isinstance(keywords_overwrite, str):
        keywords_overwrite = [keywords_overwrite]
    # Vérifier que les nouvelles métadonnées importantes sont présentes
    # En mode overwrite, les nouveaux mots-clés doivent être présents
    # Pour les vidéos MP4, les mots-clés sont stockés dans Subject, pas Keywords
    subjects_append = metadata_append.get("Subject", [])
    subjects_overwrite = metadata_overwrite.get("Subject", [])
    if isinstance(subjects_append, str):
        subjects_append = [subjects_append]
    if isinstance(subjects_overwrite, str):
        subjects_overwrite = [subjects_overwrite]
    # Combiner Keywords et Subject pour une vérification complète
    all_keywords_append = keywords_append + subjects_append
    all_keywords_overwrite = keywords_overwrite + subjects_overwrite
    assert "Video Person" in all_keywords_overwrite
    assert "Album: Test Album" in all_keywords_overwrite
    # En mode append-only, les mots-clés sont ajoutés même si d'autres existent
    assert "Video Person" in all_keywords_append
    assert "Album: Test Album" in all_keywords_append
@pytest.mark.integration
def test_batch_vs_normal_mode_equivalence(tmp_path: Path) -> None:
    """Tester que le mode batch produit les mêmes résultats que le mode normal."""
    # Importer la fonction de traitement par lot
    from google_takeout_metadata.processor_batch import process_directory_batch
    from google_takeout_metadata.processor import process_directory
    # Créer des données de test
    test_files = [
        ("photo1.jpg", "First test photo", "Alice"),
        ("photo2.jpg", "Second test photo", "Bob"),
        ("photo3.jpg", "Third test photo", "Charlie")
    ]
    # Créer deux structures de répertoires identiques
    normal_dir = tmp_path / "normal_mode"
    batch_dir = tmp_path / "batch_mode"
    normal_dir.mkdir()
    batch_dir.mkdir()
    for filename, description, person in test_files:
        # Créer les deux fichiers dans les deux répertoires
        for test_dir in [normal_dir, batch_dir]:
            # Créer l'image
            media_path = test_dir / filename
            img = Image.new('RGB', (100, 100), color='blue')
            img.save(media_path)
            # Créer le sidecar
            sidecar_data = {
                "title": filename,
                "description": description,
                "people": [{"name": person}]
            }
            json_path = test_dir / f"{filename}.json"
            json_path.write_text(json.dumps(sidecar_data), encoding="utf-8")
    try:
        # Proceder avec le mode normal
        process_directory(normal_dir, use_localtime=False, append_only=True, immediate_delete=False)
        # Traiter avec le mode par lot
        process_directory_batch(batch_dir, use_localtime=False, append_only=True, immediate_delete=False)
        # Comparer les métadonnées des fichiers dans les deux répertoires
        for filename, expected_description, expected_person in test_files:
            normal_metadata = _run_exiftool_read(normal_dir / filename)
            batch_metadata = _run_exiftool_read(batch_dir / filename)
            # Vérifier que les descriptions correspondent
            assert normal_metadata.get("ImageDescription") == batch_metadata.get("ImageDescription")
            assert normal_metadata.get("ImageDescription") == expected_description
            # Vérifier que les personnes correspondent
            normal_people = normal_metadata.get("PersonInImage", [])
            batch_people = batch_metadata.get("PersonInImage", [])
            if isinstance(normal_people, str):
                normal_people = [normal_people]
            if isinstance(batch_people, str):
                batch_people = [batch_people]
            assert set(normal_people) == set(batch_people)
            assert expected_person in normal_people
    except FileNotFoundError:
        pytest.skip("exiftool introuvable - skipping batch vs normal mode test")
@pytest.mark.integration
def test_batch_mode_performance_benefit(tmp_path: Path) -> None:
    """Tester que le mode batch peut gérer de nombreux fichiers (test de performance)."""
    from google_takeout_metadata.processor_batch import process_directory_batch
    import time
    # Créer de nombreux fichiers de test
    num_files = 20  # Réduit pour CI, mais démontre toujours la capacité par lot
    for i in range(num_files):
        filename = f"perf_test_{i:03d}.jpg"
        # Créer l'image
        media_path = tmp_path / filename
        img = Image.new('RGB', (50, 50), color='red')
        img.save(media_path)
        # Créer le sidecar
        sidecar_data = {
            "title": filename,
            "description": f"Performance test image {i}"
        }
        json_path = tmp_path / f"{filename}.json"
        json_path.write_text(json.dumps(sidecar_data), encoding="utf-8")
    try:
        # Mesurer le temps de traitement par lot
        start_time = time.time()
        process_directory_batch(tmp_path, use_localtime=False, append_only=True, immediate_delete=False)
        end_time = time.time()
        batch_time = end_time - start_time
        # Vérifier que tous les fichiers ont été traités
        for i in range(num_files):
            filename = f"perf_test_{i:03d}.jpg"
            media_path = tmp_path / filename
            metadata = _run_exiftool_read(media_path)
            expected_description = f"Performance test image {i}"
            assert metadata.get("ImageDescription") == expected_description
        # Imprimer le temps pris pour le traitement par lot
        print(f"Batch mode processed {num_files} files in {batch_time:.2f} seconds")
    except FileNotFoundError:
        pytest.skip("exiftool introuvable - skipping batch performance test")
@pytest.mark.integration  
def test_batch_mode_with_mixed_file_types(tmp_path: Path) -> None:
    """Tester le mode batch avec différents types de fichiers et métadonnées complexes."""
    from google_takeout_metadata.processor_batch import process_directory_batch
    # Créer des fichiers de test avec différents types et métadonnées
    test_files = [
        ("mixed1.jpg", "JPEG test"),
        ("mixed2.png", "PNG test")  # PNG if supported by PIL
    ]
    for filename, description in test_files:
        # Créer l'image
        media_path = tmp_path / filename
        if filename.endswith('.jpg'):
            img = Image.new('RGB', (100, 100), color='green')
            img.save(media_path, format='JPEG')
        elif filename.endswith('.png'):
            img = Image.new('RGBA', (100, 100), color=(0, 255, 0, 128))
            img.save(media_path, format='PNG')
        # Créer le sidecar complexe
        sidecar_data = {
            "title": filename,
            "description": description,
            "people": [{"name": "Mixed Test Person"}],
            "favorited": True,
            "geoData": {
                "latitude": 45.5017,
                "longitude": -73.5673,
                "altitude": 20.0
            }
        }
        json_path = tmp_path / f"{filename}.json"
        json_path.write_text(json.dumps(sidecar_data), encoding="utf-8")
    try:
        # Traiter avec le mode par lot
        process_directory_batch(tmp_path, use_localtime=False, append_only=True, immediate_delete=False)
        # Vérifier que tous les fichiers ont été traités
        for filename, expected_description in test_files:
            media_path = tmp_path / filename
            metadata = _run_exiftool_read(media_path)
            # Vérifier la description
            assert metadata.get("ImageDescription") == expected_description
            # Vérifier les personnes
            people = metadata.get("PersonInImage", [])
            if isinstance(people, str):
                people = [people]
            assert "Mixed Test Person" in people
            # Vérifier la note (favori)
            rating = metadata.get("Rating")
            assert rating == 5 or rating == "5"
            # Vérifier les données GPS (peut ne pas fonctionner pour tous les types de fichiers)
            gps_lat = metadata.get("GPSLatitude")
            if gps_lat is not None:
                # Si GPSLatitude est présent, vérifier qu'il est correct
                assert "45 deg" in str(gps_lat)
                assert gps_lat is not None
    except FileNotFoundError:
        pytest.skip("exiftool introuvable - skipping mixed file types batch test")
````

## File: tests/test_local_folder.py
````python
#!/usr/bin/env python3
"""Test rapide de l'extraction du localFolderName."""
import json
import sys
import tempfile
from pathlib import Path
sys.path.insert(0, "src")
from google_takeout_metadata.sidecar import parse_sidecar
from google_takeout_metadata.exif_writer import build_exiftool_args
def test_local_folder_name_integration():
    """Test complet d'extraction et génération d'arguments pour localFolderName."""
    with tempfile.TemporaryDirectory() as temp_dir:
        temp_path = Path(temp_dir)
        # 1. Créer un sidecar avec localFolderName
        sidecar_data = {
            "title": "test_photo.jpg",
            "description": "Photo test",
            "people": [{"name": "Alice"}],
            "googlePhotosOrigin": {
                "mobileUpload": {
                    "deviceFolder": {
                        "localFolderName": "Instagram"
                    },
                    "deviceType": "ANDROID_PHONE"
                }
            }
        }
        json_path = temp_path / "test_photo.jpg.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(sidecar_data, f)
        # 2. Parser le sidecar
        meta = parse_sidecar(json_path)
        print("🔍 Parsing résultats:")
        print(f"   local_folder_name: {meta.local_folder_name}")
        print(f"   albums: {meta.albums}")
        print(f"   people: {meta.people}")
        # 3. Générer les arguments ExifTool
        media_path = temp_path / "test_photo.jpg"
        args = build_exiftool_args(meta, media_path=media_path, use_localtime=False, append_only=True)
        print("🔧 Arguments ExifTool générés:")
        for arg in args:
            if "Album:" in str(arg) or "Alice" in str(arg):
                print(f"   {arg}")
        # 4. Vérifications
        assert meta.local_folder_name == "Instagram", f"Attendu 'Instagram', obtenu {meta.local_folder_name}"
        # Chercher l'argument pour Alice (personnes)
        alice_found = False
        instagram_as_album_found = False
        for arg in args:
            if isinstance(arg, str):
                if "Alice" in arg:
                    alice_found = True
                # local_folder_name ne devrait PAS être traité comme un album
                if "Album: Instagram" in arg:
                    instagram_as_album_found = True
        # Alice devrait être présente (personne)
        assert alice_found, "L'argument 'Alice' devrait être présent"
        # Instagram ne devrait PAS être traité comme un album
        assert not instagram_as_album_found, "local_folder_name ne devrait PAS être traité comme un album avec préfixe 'Album:'"
        # Pour le moment, acceptons que local_folder_name ne soit pas utilisé dans les métadonnées
        # (selon la logique métier expliquée par l'utilisateur)
        print(f"✅ local_folder_name extrait correctement: {meta.local_folder_name}")
        print("✅ local_folder_name correctement non traité comme album")
if __name__ == "__main__":
    print("🧪 Test d'intégration localFolderName")
    print("=" * 50)
    try:
        test_local_folder_name_integration()
        print("🎉 Tous les tests réussis!")
    except Exception as e:
        print(f"💥 Erreur: {e}")
        import traceback
        traceback.print_exc()
````

## File: tests/test_p1_specific.py
````python
#!/usr/bin/env python3
"""
Test script pour vérifier le P1 dans write_metadata directement.
"""
import sys
sys.path.append('src')
from google_takeout_metadata.sidecar import SidecarData
from google_takeout_metadata.exif_writer import build_description_args, build_datetime_args
def test_p1_write_metadata_conditional_args():
    """
    Teste spécifiquement le P1 : dans write_metadata, quand build_description_args
    retourne une liste vide mais qu'il y a des datetime_args, -wm cg doit être ajouté.
    """
    print("=== Test P1: Cas problématique original ===")
    # Scénario P1 : pas de description, mais des dates
    meta = SidecarData(
        filename="test.jpg",
        description=None,  # ❌ Pas de description
        people=None,
        taken_at=1640995200,  # ✅ Mais il y a des dates
        created_at=1640995200,
        latitude=None,
        longitude=None,
        altitude=None,
        favorite=False,
    )
    # Reproduire la logique de write_metadata (avant correction)
    conditional_args_before = []
    # build_description_args avec description=None retourne []
    desc_args = build_description_args(meta, conditional_mode=True)
    conditional_args_before.extend(desc_args)
    print(f"Description args: {desc_args}")
    # build_datetime_args retourne les timestamps mais sans -wm cg
    datetime_args = build_datetime_args(meta, use_localtime=False, is_video=False)
    conditional_args_before.extend(datetime_args)
    print(f"Datetime args: {datetime_args}")
    print(f"Conditional args AVANT correction: {conditional_args_before}")
    # PROBLÈME P1 : Pas de -wm cg dans conditional_args_before !
    # => exiftool va écraser les timestamps existants
    has_wm_before = "-wm" in conditional_args_before
    print(f"❌ AVANT correction - a -wm cg: {has_wm_before}")
    # Maintenant testons APRÈS correction
    conditional_args_after = []
    conditional_args_after.extend(desc_args)
    # CORRECTION P1: Ajouter -wm cg si on a des datetime_args
    if datetime_args:
        conditional_args_after.extend(["-wm", "cg"])
        conditional_args_after.extend(datetime_args)
    print(f"Conditional args APRÈS correction: {conditional_args_after}")
    has_wm_after = "-wm" in conditional_args_after
    print(f"✅ APRÈS correction - a -wm cg: {has_wm_after}")
    assert has_wm_after, "La correction doit ajouter -wm cg pour les timestamps"
    # Vérifier l'ordre
    if "-wm" in conditional_args_after:
        wm_idx = conditional_args_after.index("-wm")
        cg_idx = conditional_args_after.index("cg")
        assert cg_idx == wm_idx + 1, "-wm et cg doivent être consécutifs"
        # Vérifier qu'au moins un timestamp suit
        has_timestamp_after_wm = False
        for i, arg in enumerate(conditional_args_after):
            if i > cg_idx and ("DateTimeOriginal=" in arg or "CreateDate=" in arg or "ModifyDate=" in arg):
                has_timestamp_after_wm = True
                break
        assert has_timestamp_after_wm, "Il doit y avoir au moins un timestamp après -wm cg"
    print("✅ P1 correctement corrigé : -wm cg ajouté pour préserver les timestamps existants")
if __name__ == "__main__":
    test_p1_write_metadata_conditional_args()
    print("\n🎉 Correction P1 validée !")
````

## File: tests/test_processor_batch.py
````python
"""Tests pour la fonctionnalité de traitement par lots."""
import json
import subprocess
from pathlib import Path
from unittest.mock import Mock, patch
import pytest
from PIL import Image
from google_takeout_metadata.processor_batch import process_batch, process_directory_batch
from google_takeout_metadata.sidecar import SidecarData
def test_process_batch_empty_batch():
    """Tester que process_batch retourne 0 pour un lot vide."""
    result = process_batch([], immediate_delete=False)
    assert result == 0
@patch('google_takeout_metadata.processor_batch.subprocess.run')
def test_process_batch_success(mock_subprocess_run, tmp_path):
    """Tester le traitement par lots réussi."""
    # Configuration
    mock_subprocess_run.return_value = Mock(returncode=0, stdout="    1 image files updated")
    media_path = tmp_path / "test.jpg"
    json_path = tmp_path / "test.jpg.json"
    args = ["-EXIF:ImageDescription=Test Description"]
    batch = [(media_path, json_path, args)]
    # Exécution
    result = process_batch(batch, immediate_delete=False)
    # Vérification
    assert result == 1
    mock_subprocess_run.assert_called_once()
    # Vérifier que la commande a été construite correctement
    call_args = mock_subprocess_run.call_args
    cmd = call_args[0][0]
    assert cmd[0] == "exiftool"
    assert "-overwrite_original" in cmd
    assert "-charset" in cmd
    assert "-@" in cmd
@patch('google_takeout_metadata.processor_batch.subprocess.run')
def test_process_batch_with_argfile_content(mock_subprocess_run, tmp_path):
    """Vérifier que le fichier d'arguments est créé avec le contenu correct."""
    # Setup
    mock_subprocess_run.return_value = Mock(returncode=0, stdout="    2 image files updated")
    media_path1 = tmp_path / "test1.jpg"
    media_path2 = tmp_path / "test2.jpg"
    json_path1 = tmp_path / "test1.jpg.json"
    json_path2 = tmp_path / "test2.jpg.json"
    args1 = ["-EXIF:ImageDescription=Description 1", "-XMP:Rating=5"]
    args2 = ["-EXIF:ImageDescription=Description 2"]
    batch = [
        (media_path1, json_path1, args1),
        (media_path2, json_path2, args2)
    ]
    # Execute
    result = process_batch(batch, immediate_delete=False)
    # Assert
    assert result == 2
    mock_subprocess_run.assert_called_once()
    # Vérifier que le chemin du fichier d'arguments a été passé au sous-processus
    call_args = mock_subprocess_run.call_args
    cmd = call_args[0][0]
    assert "-@" in cmd
    # Le chemin du fichier d'arguments devrait être l'argument juste après "-@"
    argfile_index = cmd.index("-@")
    assert argfile_index + 1 < len(cmd)  # S'assurer qu'il y a un argument après "-@"
@patch('google_takeout_metadata.processor_batch.subprocess.run')
def test_process_batch_immediate_delete_sidecars(mock_subprocess_run, tmp_path):
    """Vérifier que les fichiers de sidecar sont supprimés immédiatement lorsqu'on le demande."""
    # Setup
    mock_subprocess_run.return_value = Mock(returncode=0, stdout="    1 image files updated")
    media_path = tmp_path / "test.jpg"
    json_path = tmp_path / "test.jpg.json"
    json_path.write_text('{"title": "test.jpg"}')
    args = ["-EXIF:ImageDescription=Test Description"]
    batch = [(media_path, json_path, args)]
    # Execute
    result = process_batch(batch, immediate_delete=True)
    # Assert
    assert result == 1
    assert not json_path.exists()
@patch('google_takeout_metadata.processor_batch.subprocess.run')
def test_process_batch_exiftool_not_found(mock_subprocess_run):
    """Vérifier la gestion d'erreurs lorsque exiftool n'est pas trouvé."""
    # Setup
    mock_subprocess_run.side_effect = FileNotFoundError("exiftool introuvable")
    media_path = Path("test.jpg")
    json_path = Path("test.jpg.json")
    args = ["-EXIF:ImageDescription=Test Description"]
    batch = [(media_path, json_path, args)]
    # Execute & Assert
    with pytest.raises(RuntimeError, match="exiftool introuvable"):
        process_batch(batch, immediate_delete=False)
@patch('google_takeout_metadata.processor_batch.subprocess.run')
def test_process_batch_exiftool_error(mock_subprocess_run, caplog):
    """Vérifier la gestion d'erreurs lorsque exiftool retourne une erreur."""
    # Setup
    mock_subprocess_run.side_effect = subprocess.CalledProcessError(
        1, ["exiftool"], stderr="Some error"
    )
    media_path = Path("test.jpg")
    json_path = Path("test.jpg.json")
    args = ["-EXIF:ImageDescription=Test Description"]
    batch = [(media_path, json_path, args)]
    # Execute
    result = process_batch(batch, immediate_delete=False)
    # Assert
    assert result == 0
    assert "Échec du traitement par lot" in caplog.text
def test_process_directory_batch_no_sidecars(tmp_path, caplog):
    """Vérifier le traitement par lot lorsque aucun fichier de sidecar n'est trouvé."""
    # Execute
    process_directory_batch(tmp_path, use_localtime=False, append_only=True, immediate_delete=False)
    # Assert
    assert "Aucun fichier de métadonnées (.json) trouvé" in caplog.text
@pytest.mark.integration
def test_process_directory_batch_single_file(tmp_path):
    """Vérifier le traitement par lot d'un seul fichier."""
    try:
        # Créer une image de test
        media_path = tmp_path / "test.jpg"
        img = Image.new('RGB', (100, 100), color='blue')
        img.save(media_path)
        # Créer le fichier JSON annexe
        sidecar_data = {
            "title": "test.jpg",
            "description": "Batch test description",
            "people": [{"name": "Batch Test Person"}]
        }
        json_path = tmp_path / "test.jpg.json"
        json_path.write_text(json.dumps(sidecar_data), encoding="utf-8")
        # Traiter en mode batch
        process_directory_batch(tmp_path, use_localtime=False, append_only=True, immediate_delete=False)
        # Vérifier que les métadonnées ont été écrites en les relisant
        cmd = [
            "exiftool",
            "-j",
            "-EXIF:ImageDescription",
            "-XMP-iptcExt:PersonInImage",
            str(media_path)
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, check=True, timeout=30)
        metadata = json.loads(result.stdout)[0]
        assert metadata.get("ImageDescription") == "Batch test description"
        people = metadata.get("PersonInImage", [])
        if isinstance(people, str):
            people = [people]
        assert "Batch Test Person" in people
    except FileNotFoundError:
        pytest.skip("Exiftool non trouvé - ignore les tests d'intégration")
@pytest.mark.integration  
def test_process_directory_batch_multiple_files(tmp_path):
    """Vérifier le traitement par lot de plusieurs fichiers."""
    try:
        # Créer plusieurs images de test avec leurs fichiers annexes
        files_data = [
            ("test1.jpg", "First batch test", "Person One"),
            ("test2.jpg", "Second batch test", "Person Two"),
            ("test3.jpg", "Third batch test", "Person Three")
        ]
        for filename, description, person in files_data:
            # Créer l'image
            media_path = tmp_path / filename
            img = Image.new('RGB', (100, 100), color='red')
            img.save(media_path)
            # Créer le fichier annexe
            sidecar_data = {
                "title": filename,
                "description": description,
                "people": [{"name": person}]
            }
            json_path = tmp_path / f"{filename}.json"
            json_path.write_text(json.dumps(sidecar_data), encoding="utf-8")
        # Traiter en mode batch
        process_directory_batch(tmp_path, use_localtime=False, append_only=True, immediate_delete=False)
        # Vérifier que tous les fichiers ont été traités correctement
        for filename, expected_description, expected_person in files_data:
            media_path = tmp_path / filename
            cmd = [
                "exiftool",
                "-j",
                "-EXIF:ImageDescription",
                "-XMP-iptcExt:PersonInImage",
                str(media_path)
            ]
            result = subprocess.run(cmd, capture_output=True, text=True, check=True, timeout=30)
            metadata = json.loads(result.stdout)[0]
            assert metadata.get("ImageDescription") == expected_description
            people = metadata.get("PersonInImage", [])
            if isinstance(people, str):
                people = [people]
            assert expected_person in people
    except FileNotFoundError:
        pytest.skip("Exiftool non trouvé - ignore les tests d'intégration")
@pytest.mark.integration
def test_process_directory_batch_with_albums(tmp_path):
    """Vérifier le traitement par lot avec des métadonnées d'album."""
    try:
        # Créer la structure de répertoires
        album_dir = tmp_path / "Album Test"
        album_dir.mkdir()
        # Créer les métadonnées d'album
        album_metadata = {
            "title": "Test Album",
            "description": "Album for batch testing"
        }
        metadata_path = album_dir / "metadata.json"
        metadata_path.write_text(json.dumps(album_metadata), encoding="utf-8")
        # Créer l'image de test dans le répertoire d'album
        media_path = album_dir / "album_photo.jpg"
        img = Image.new('RGB', (100, 100), color='green')
        img.save(media_path)
        # Créer le fichier annexe
        sidecar_data = {
            "title": "album_photo.jpg",
            "description": "Photo in album batch test"
        }
        json_path = album_dir / "album_photo.jpg.json"
        json_path.write_text(json.dumps(sidecar_data), encoding="utf-8")
        # Traiter en mode batch
        process_directory_batch(tmp_path, use_localtime=False, append_only=True, immediate_delete=False)
        # Vérifier que l'album a été ajouté aux mots-clés
        cmd = [
            "exiftool",
            "-j",
            "-IPTC:Keywords",
            "-XMP-dc:Subject",
            str(media_path)
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, check=True, timeout=30)
        metadata = json.loads(result.stdout)[0]
        keywords = metadata.get("Keywords", [])
        if isinstance(keywords, str):
            keywords = [keywords]
        assert "Album: Test Album" in keywords
    except FileNotFoundError:
        pytest.skip("Exiftool non trouvé - ignore les tests d'intégration")
@pytest.mark.integration
def test_process_directory_batch_immediate_delete(tmp_path):
    """Test d'intégration pour le traitement par lot avec suppression immédiate des sidecars.
    LOGIQUE MÉTIER: Le sidecar est supprimé immédiatement après traitement réussi
    quand immediate_delete=True (mode destructeur).
    """
    try:
        # Créer une image de test
        media_path = tmp_path / "cleanup_test.jpg"
        img = Image.new('RGB', (100, 100), color='yellow')
        img.save(media_path)
        # Créer le fichier JSON annexe
        sidecar_data = {
            "title": "cleanup_test.jpg",
            "description": "Test cleanup functionality"
        }
        json_path = tmp_path / "cleanup_test.jpg.json"
        json_path.write_text(json.dumps(sidecar_data), encoding="utf-8")
        # Vérifier que le fichier annexe existe avant le traitement
        assert json_path.exists()
        # Traiter avec la suppression immédiate activée
        process_directory_batch(tmp_path, use_localtime=False, append_only=True, immediate_delete=True)
        # Comportement attendu avec immediate_delete=True :
        # - Si exiftool réussit → sidecar supprimé immédiatement
        # - Si exiftool échoue → sidecar conservé pour retry (mode sécurisé)
        if json_path.exists():
            # Le sidecar existe encore car le traitement a échoué - c'est correct
            print("INFO: Sidecar conservé après échec exiftool - comportement correct")
        else:
            # Le sidecar a été supprimé car le traitement a réussi - aussi correct
            print("INFO: Sidecar supprimé après traitement réussi avec immediate_delete=True")
        # Vérifier que les métadonnées ont quand même été écrites
        cmd = [
            "exiftool",
            "-j",
            "-EXIF:ImageDescription",
            str(media_path)
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, check=True, timeout=30)
        metadata = json.loads(result.stdout)[0]
        assert metadata.get("ImageDescription") == "Test cleanup functionality"
    except FileNotFoundError:
        pytest.skip("Exiftool non trouvé - ignore les tests d'intégration")
@patch('google_takeout_metadata.processor_batch.parse_sidecar')
def test_process_directory_batch_invalid_sidecar(mock_parse_sidecar, tmp_path, caplog):
    """Tester le traitement par lot avec un fichier sidecar invalide."""
    # Configuration
    mock_parse_sidecar.side_effect = ValueError("Invalid JSON")
    # Créer des fichiers factices
    media_path = tmp_path / "invalid.jpg"
    media_path.write_text("dummy")
    json_path = tmp_path / "invalid.jpg.json"
    json_path.write_text("invalid json")
    # Exécuter
    process_directory_batch(tmp_path, use_localtime=False, append_only=True, immediate_delete=False)
    # Vérifier
    assert "Échec de la préparation de" in caplog.text
@patch('google_takeout_metadata.processor_batch.build_exiftool_args')
def test_process_directory_batch_no_args_generated(mock_build_args, tmp_path):
    """Tester le traitement par lot quand aucun argument exiftool n'est généré."""
    # Configuration - build_exiftool_args retourne une liste vide
    mock_build_args.return_value = []
    # Créer l'image de test
    media_path = tmp_path / "no_args.jpg"
    img = Image.new('RGB', (100, 100), color='white')
    img.save(media_path)
    # Créer le fichier JSON annexe
    sidecar_data = {"title": "no_args.jpg"}
    json_path = tmp_path / "no_args.jpg.json"
    json_path.write_text(json.dumps(sidecar_data), encoding="utf-8")
    # Exécuter (ne devrait pas planter même sans arguments)
    process_directory_batch(tmp_path, use_localtime=False, append_only=True, immediate_delete=False)
    # Aucune assertion spécifique nécessaire - juste s'assurer que ça ne plante pas
def test_process_directory_batch_missing_media_file(tmp_path, caplog):
    """Tester le traitement par lot quand le fichier média est manquant."""
    # Créer un fichier annexe sans fichier média correspondant
    sidecar_data = {
        "title": "missing.jpg",
        "description": "Media file does not exist"
    }
    json_path = tmp_path / "missing.jpg.json"
    json_path.write_text(json.dumps(sidecar_data), encoding="utf-8")
    # Exécuter
    process_directory_batch(tmp_path, use_localtime=False, append_only=True, immediate_delete=False)
    # Vérifier
    assert "Fichier image introuvable" in caplog.text
@patch('google_takeout_metadata.processor_batch.fix_file_extension_mismatch')
@patch('google_takeout_metadata.processor_batch.parse_sidecar')
def test_process_directory_batch_file_extension_fix(mock_parse_sidecar, mock_fix_extension, tmp_path):
    """Tester que la correction de l'extension de fichier est gérée dans le traitement par lot."""
    # Configuration
    media_path = tmp_path / "test.jpg"
    json_path = tmp_path / "test.jpg.json"
    fixed_media_path = tmp_path / "test.jpeg"
    fixed_json_path = tmp_path / "test.jpeg.json"
    # Créer les fichiers
    img = Image.new('RGB', (100, 100), color='black')
    img.save(media_path)
    json_path.write_text('{"title": "test.jpg"}')
    # Simuler la correction d'extension pour retourner des chemins différents
    mock_fix_extension.return_value = (fixed_media_path, fixed_json_path)
    # Simuler parse_sidecar pour retourner des données différentes pour chaque appel
    mock_parse_sidecar.side_effect = [
        SidecarData(filename="test.jpg", description="Original", people=[], taken_at=None, created_at=None, 
                   latitude=None, longitude=None, altitude=None, favorite=False, albums=[]),
        SidecarData(filename="test.jpeg", description="Fixed", people=[], taken_at=None, created_at=None,
                   latitude=None, longitude=None, altitude=None, favorite=False, albums=[])
    ]
    # Exécuter
    process_directory_batch(tmp_path, use_localtime=False, append_only=True, immediate_delete=False)
    # Vérifier que fix_file_extension_mismatch a été appelé
    mock_fix_extension.assert_called()
    # Vérifier que parse_sidecar a été appelé deux fois (une fois pour l'original, une fois pour le corrigé)
    assert mock_parse_sidecar.call_count == 2
````

## File: tests/test_processor.py
````python
from pathlib import Path
import json
import unittest.mock
import os
from google_takeout_metadata.processor import (
    process_directory, 
    _is_sidecar_file, 
    fix_file_extension_mismatch
)
def test_ignore_non_sidecar(tmp_path: Path) -> None:
    (tmp_path / "data.json").write_text("{}", encoding="utf-8")
    process_directory(tmp_path)
def test_is_sidecar_file_standard_pattern() -> None:
    """Test standard pattern: photo.jpg.json"""
    assert _is_sidecar_file(Path("photo.jpg.json"))
    assert _is_sidecar_file(Path("video.mp4.json"))
    assert _is_sidecar_file(Path("image.PNG.JSON"))  # insensible à la casse
def test_is_sidecar_file_supplemental_metadata_pattern() -> None:
    """Vérifier le format Google Takeout: photo.jpg.supplemental-metadata.json"""
    assert _is_sidecar_file(Path("IMG_001.jpg.supplemental-metadata.json"))
    assert _is_sidecar_file(Path("video.mp4.supplemental-metadata.json"))
    assert _is_sidecar_file(Path("image.PNG.SUPPLEMENTAL-METADATA.JSON"))  # insensible à la casse
    assert _is_sidecar_file(Path("photo.heic.supplemental-metadata.json"))
def test_is_sidecar_file_older_pattern() -> None:
    """Vérifier l'ancien format: photo.json"""
    assert _is_sidecar_file(Path("IMG_1234.jpg.json"))  # devrait fonctionner avec la nouvelle logique
    # Note: photo.json sans extension dans le nom ne serait pas détecté
    # car c'est ambigu, mais c'est acceptable puisque parse_sidecar() valide
def test_is_sidecar_file_negative() -> None:
    """vérifier les fichiers qui ne devraient pas être détectés comme sidecars"""
    assert not _is_sidecar_file(Path("data.json"))  # pas d'extension d'image
    assert not _is_sidecar_file(Path("photo.txt"))  # pas un json
    assert not _is_sidecar_file(Path("photo.jpg"))  # pas un json
    assert not _is_sidecar_file(Path("metadata.json"))  # album metadata, pas un sidecar
    assert not _is_sidecar_file(Path("métadonnées.json"))  # album metadata, pas un sidecar
def test_fix_file_extension_mismatch_rollback_on_failure(tmp_path: Path) -> None:
    """Vérifier que fix_file_extension_mismatch annule correctement le renommage de l'image en cas d'échec"""
    # Créer un faux fichier JPEG avec une mauvaise extension
    media_path = tmp_path / "photo.png"
    media_path.write_bytes(b'\xff\xd8\xff\xe0')  # JPEG magic bytes
    # Créer le fichier JSON correspondant
    json_path = tmp_path / "photo.png.supplemental-metadata.json"
    json_data = {"title": "photo.png"}
    json_path.write_text(json.dumps(json_data), encoding='utf-8')
    # Simuler un échec de unlink pour le fichier JSON (fichier en lecture seule)
    original_unlink = Path.unlink
    def mock_unlink(self):
        if self.name.endswith('.supplemental-metadata.json') and 'photo.png' in str(self):
            raise OSError("Permission denied")
        return original_unlink(self)
    with unittest.mock.patch.object(Path, 'unlink', mock_unlink):
        result_image, result_json = fix_file_extension_mismatch(media_path, json_path)
        # Devrait retourner les chemins d'origine car le rollback a réussi
        assert result_image == media_path
        assert result_json == json_path
        assert media_path.exists()  # L'image originale devrait exister à nouveau
        assert not (tmp_path / "photo.jpg").exists()  # L'image renommée ne devrait pas exister
        assert not (tmp_path / "photo.jpg.supplemental-metadata.json").exists()  # Pas de JSON orphelin attendu
def test_fix_file_extension_mismatch_failed_rollback(tmp_path: Path) -> None:
    """Tester fix_file_extension_mismatch lorsque l'opération et le rollback échouent tous les deux"""
    # Créer un faux fichier JPEG avec une mauvaise extension
    media_path = tmp_path / "photo.png"
    media_path.write_bytes(b'\xff\xd8\xff\xe0')  # JPEG magic bytes
    # Créer le fichier JSON correspondant
    json_path = tmp_path / "photo.png.supplemental-metadata.json"
    json_data = {"title": "photo.png"}
    json_path.write_text(json.dumps(json_data), encoding='utf-8')
    # Simuler un échec à la fois pour le renommage de l'image et pour le rollback du JSON
    original_unlink = Path.unlink
    def mock_unlink(self):
        if self.name.endswith('.supplemental-metadata.json'):
            raise OSError("Permission denied")
        return original_unlink(self)
    def mock_rename(self, target):
        # Simuler un échec lors du rollback du renommage
        if str(target).endswith('.png') and str(self).endswith('.jpg'):
            raise OSError("Rollback failed")
        # Sinon, faire le renommage réel
        os.rename(str(self), str(target))
    with unittest.mock.patch.object(Path, 'unlink', mock_unlink), \
         unittest.mock.patch.object(Path, 'rename', mock_rename):
        result_image, result_json = fix_file_extension_mismatch(media_path, json_path)
        # Devrait retourner le nouveau chemin de l'image mais l'ancien chemin du JSON en raison du rollback échoué
        assert result_image == tmp_path / "photo.jpg"
        assert result_json == json_path  # Chemin JSON d'origine
        assert (tmp_path / "photo.jpg").exists()  # La nouvelle image devrait exister
        assert not media_path.exists()  # L'image originale ne devrait pas exister
````

## File: tests/test_resume_handler.py
````python
# Fichier : tests/test_resume_handler.py
"""Tests pour le module de gestion de reprise des traitements."""
from pathlib import Path
from google_takeout_metadata.resume_handler import (
    should_resume, parse_efile_logs, build_resume_batch, 
    cleanup_efile_logs, _read_file_list
)
def test_should_resume_no_logs(tmp_path):
    """Tester qu'aucune reprise n'est détectée sans logs -efile."""
    assert should_resume(tmp_path) is False
def test_should_resume_with_logs(tmp_path):
    """Tester que la reprise est détectée avec des logs -efile."""
    # Créer un fichier de log factice
    error_log = tmp_path / "error_files.txt"
    error_log.write_text("test.jpg\n")
    assert should_resume(tmp_path) is True
def test_read_file_list_empty(tmp_path):
    """Tester la lecture d'un fichier de log inexistant."""
    non_existent = tmp_path / "non_existent.txt"
    result = _read_file_list(non_existent)
    assert result == []
def test_read_file_list_with_content(tmp_path):
    """Tester la lecture d'un fichier de log avec contenu."""
    log_file = tmp_path / "test_log.txt"
    log_file.write_text("image1.jpg\nimage2.jpg\n# Commentaire\n  \nimage3.jpg\n")
    result = _read_file_list(log_file)
    expected = [Path("image1.jpg"), Path("image2.jpg"), Path("image3.jpg")]
    assert result == expected
def test_parse_efile_logs_no_files(tmp_path):
    """Tester le parsing des logs -efile sans fichiers."""
    error_files, updated_files, unchanged_files, failed_condition_files = parse_efile_logs(tmp_path)
    assert error_files == []
    assert updated_files == []
    assert unchanged_files == []
    assert failed_condition_files == []
def test_parse_efile_logs_with_files(tmp_path):
    """Tester le parsing des logs -efile avec des fichiers."""
    # Créer les logs -efile
    (tmp_path / "error_files.txt").write_text("error1.jpg\nerror2.jpg\n")
    (tmp_path / "updated_files.txt").write_text("updated1.jpg\n")
    (tmp_path / "unchanged_files.txt").write_text("unchanged1.jpg\nunchanged2.jpg\n")
    (tmp_path / "failed_condition_files.txt").write_text("failed1.jpg\n")
    error_files, updated_files, unchanged_files, failed_condition_files = parse_efile_logs(tmp_path)
    assert len(error_files) == 2
    assert len(updated_files) == 1
    assert len(unchanged_files) == 2
    assert len(failed_condition_files) == 1
    assert Path("error1.jpg") in error_files
    assert Path("updated1.jpg") in updated_files
    assert Path("unchanged1.jpg") in unchanged_files
    assert Path("failed1.jpg") in failed_condition_files
def test_build_resume_batch_errors_only():
    """Tester la construction d'un lot de reprise en mode erreurs uniquement."""
    error_files = [Path("error1.jpg"), Path("error2.jpg")]
    unchanged_files = [Path("unchanged1.jpg"), Path("unchanged2.jpg")]
    result = build_resume_batch(error_files, unchanged_files, resume_mode="errors")
    assert result == error_files
    assert Path("unchanged1.jpg") not in result
def test_build_resume_batch_all_mode():
    """Tester la construction d'un lot de reprise en mode complet."""
    error_files = [Path("error1.jpg"), Path("error2.jpg")]
    unchanged_files = [Path("unchanged1.jpg"), Path("unchanged2.jpg")]
    result = build_resume_batch(error_files, unchanged_files, resume_mode="all")
    expected = error_files + unchanged_files
    assert result == expected
def test_cleanup_efile_logs(tmp_path):
    """Tester le nettoyage des logs -efile."""
    # Créer des logs factices
    log_files = ["error_files.txt", "updated_files.txt", "unchanged_files.txt", "failed_condition_files.txt"]
    for log_file in log_files:
        (tmp_path / log_file).write_text("test content\n")
    # Créer un fichier qui ne devrait pas être supprimé
    other_file = tmp_path / "other_file.txt"
    other_file.write_text("keep this\n")
    # Nettoyer
    cleanup_efile_logs(tmp_path)
    # Vérifier que les logs ont été supprimés
    for log_file in log_files:
        assert not (tmp_path / log_file).exists()
    # Vérifier que l'autre fichier existe toujours
    assert other_file.exists()
def test_edge_cases_empty_lists():
    """Tester les cas limites avec des listes vides."""
    result = build_resume_batch([], [], resume_mode="errors")
    assert result == []
    result = build_resume_batch([], [], resume_mode="all")
    assert result == []
def test_edge_cases_none_unchanged():
    """Tester les cas limites avec unchanged_files = None."""
    error_files = [Path("error1.jpg")]
    result = build_resume_batch(error_files, None, resume_mode="all")
    assert result == error_files
    result = build_resume_batch(error_files, None, resume_mode="errors")
    assert result == error_files
def test_log_file_with_unicode_content(tmp_path):
    """Tester la lecture de logs avec contenu Unicode."""
    log_file = tmp_path / "unicode_log.txt"
    log_file.write_text("image_été.jpg\nphoto_naïve.jpg\n北京.jpg\n", encoding='utf-8')
    result = _read_file_list(log_file)
    expected = [Path("image_été.jpg"), Path("photo_naïve.jpg"), Path("北京.jpg")]
    assert result == expected
````

## File: tests/test_robust_approach.py
````python
import shutil
import tempfile
import subprocess
import os
from pathlib import Path
from google_takeout_metadata.sidecar import SidecarData
from google_takeout_metadata.exif_writer import write_metadata
def read_exif_people(image_path: Path) -> list[str]:
    """Lit les personnes depuis un fichier image en utilisant exiftool."""
    try:
        cmd = ["exiftool", "-s", "-s", "-s", "-XMP-iptcExt:PersonInImage", str(image_path)]
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=30, encoding='utf-8')
        if result.returncode == 0 and result.stdout.strip():
            # ExifTool retourne les valeurs séparées par des virgules
            people = [p.strip() for p in result.stdout.strip().split(',')]
            return [p for p in people if p]  # Filtrer les valeurs vides
    except (subprocess.SubprocessError, OSError):
        pass
    return []
def test_robust_approach_no_duplicates():
    """Test de l'approche robuste (remove-then-add) : pas de doublons quand on ajoute des personnes existantes."""
    with tempfile.TemporaryDirectory() as temp_dir:
        # Copier l'image test dans le répertoire temporaire
        test_dir = Path(os.path.dirname(__file__)).parent  # Remonter d'un niveau depuis tests/
        test_image_src = test_dir / "test_assets" / "test_clean.jpg"
        test_image = Path(temp_dir) / "test_image.jpg"
        shutil.copy2(test_image_src, test_image)
        test_image = Path(temp_dir) / "test_image.jpg"
        shutil.copy2(test_image_src, test_image)
        # Étape 1 : Ajouter les premières personnes (ancien takeout)
        meta1 = SidecarData(
            filename="test_image.jpg",
            description=None,
            people=["Anthony", "Bernard"],
            taken_at=None,
            created_at=None,
            latitude=None,
            longitude=None,
            altitude=None,
            favorite=False,
            albums=["Vacances"]
        )
        write_metadata(test_image, meta1, append_only=True)
        # Vérifier l'état initial
        people_initial = read_exif_people(test_image)
        assert "Anthony" in people_initial
        assert "Bernard" in people_initial
        assert len([p for p in people_initial if p == "Anthony"]) == 1
        assert len([p for p in people_initial if p == "Bernard"]) == 1
        # Étape 2 : Ajouter nouveaux + existants (nouveau takeout avec tous les gens)
        # Test de la stratégie robuste (remove-then-add) : -TAG-=val puis -TAG+=val 
        # qui garantit zéro doublon même avec redondance dans les inputs
        meta2 = SidecarData(
            filename="test_image.jpg",
            description=None,
            people=["Anthony", "Bernard", "Cindy"],  # Contient TOUS les gens, pas juste les nouveaux
            taken_at=None,
            created_at=None,
            latitude=None,
            longitude=None,
            altitude=None,
            favorite=False,
            albums=["Vacances", "Famille"]
        )
        write_metadata(test_image, meta2, append_only=True)
        # Vérifier le résultat final : approche robuste garantit pas de doublons malgré la redondance
        people_final = read_exif_people(test_image)
        print(f"Personnes finales: {people_final}")
        # Assertions critiques : aucun doublon grâce à la stratégie remove-then-add
        assert "Anthony" in people_final
        assert "Bernard" in people_final 
        assert "Cindy" in people_final
        assert len([p for p in people_final if p == "Anthony"]) == 1, f"Anthony apparaît plusieurs fois: {people_final}"
        assert len([p for p in people_final if p == "Bernard"]) == 1, f"Bernard apparaît plusieurs fois: {people_final}"
        assert len([p for p in people_final if p == "Cindy"]) == 1, f"Cindy apparaît plusieurs fois: {people_final}"
        # Vérifier que toutes les personnes attendues sont présentes
        expected_people = {"Anthony", "Bernard", "Cindy"}
        actual_people = set(people_final)
        assert expected_people.issubset(actual_people), f"Personnes manquantes. Attendu: {expected_people}, Réel: {actual_people}"
def test_robust_approach_only_new_people():
    """Test de l'approche robuste (remove-then-add) : ajouter seulement les nouvelles personnes."""
    with tempfile.TemporaryDirectory() as temp_dir:
        # Copier l'image test
        test_dir = Path(os.path.dirname(__file__)).parent  # Remonter d'un niveau depuis tests/
        test_image_src = test_dir / "test_assets" / "test_clean.jpg"
        test_image = Path(temp_dir) / "test_image.jpg"
        shutil.copy2(test_image_src, test_image)
        # Étape 1 : Ajouter les premières personnes
        meta1 = SidecarData(
            filename="test_image.jpg",
            description=None,
            people=["Alice", "Bob"],
            taken_at=None,
            created_at=None,
            latitude=None,
            longitude=None,
            altitude=None,
            favorite=False
        )
        write_metadata(test_image, meta1, append_only=True)
        # Étape 2 : Ajouter seulement les nouvelles personnes 
        meta2 = SidecarData(
            filename="test_image.jpg",
            description=None,
            people=["Charlie"],  # Seulement la nouvelle personne
            taken_at=None,
            created_at=None,
            latitude=None,
            longitude=None,
            altitude=None,
            favorite=False
        )
        write_metadata(test_image, meta2, append_only=True)
        # Vérifier le résultat : toutes les personnes présentes, pas de doublons
        people_final = read_exif_people(test_image)
        expected_people = {"Alice", "Bob", "Charlie"}
        actual_people = set(people_final)
        assert expected_people == actual_people, f"Attendu: {expected_people}, Réel: {actual_people}"
        assert len(people_final) == 3, f"Doublons détectés: {people_final}"
if __name__ == "__main__":
    test_robust_approach_no_duplicates()
    test_robust_approach_only_new_people()
    print("✅ Tests de l'approche robuste (remove-then-add) : SUCCÈS")
````

## File: tests/test_sidecar_integration.py
````python
#!/usr/bin/env python3
"""
Test d'intégration pour vérifier que parse_sidecar + write_metadata 
utilisent bien la normalisation et la terminologie à jour.
"""
import json
import tempfile
from pathlib import Path
import sys
sys.path.append('src')
from google_takeout_metadata.sidecar import parse_sidecar
from google_takeout_metadata.exif_writer import build_exiftool_args, normalize_person_name, normalize_keyword
def test_sidecar_to_exiftool_integration():
    """Test d'intégration : vérifier que les noms de personnes du sidecar sont normalisés dans build_exiftool_args."""
    with tempfile.TemporaryDirectory() as temp_dir:
        temp_path = Path(temp_dir)
        # Créer un sidecar avec des noms non normalisés
        sidecar_data = {
            "title": "test.jpg",
            "description": "Photo de test", 
            "people": [
                {"name": "anthony vincent"},  # minuscules
                {"name": "ALICE DUPONT"},     # majuscules
                {"name": "jean de la fontaine"},  # particules
                {"name": "patrick o'connor"},     # O'
                {"name": "john mcdonald"},         # Mc
            ]
        }
        json_path = temp_path / "test.jpg.json"
        json_path.write_text(json.dumps(sidecar_data), encoding="utf-8")
        # Parser le sidecar
        meta = parse_sidecar(json_path)
        print(f"Noms depuis parse_sidecar: {meta.people}")
        # Les noms depuis parse_sidecar ne sont PAS encore normalisés (comportement attendu)
        assert meta.people == ["ALICE DUPONT", "anthony vincent", "jean de la fontaine", "john mcdonald", "patrick o'connor"]
        # Construire les arguments exiftool (qui DOIT normaliser)
        args = build_exiftool_args(meta, append_only=True)
        print(f"Arguments exiftool: {args}")
        # Vérifier que les arguments contiennent les noms normalisés
        args_str = " ".join(args)
        # Vérifier la normalisation dans les arguments
        assert "Anthony Vincent" in args_str, "anthony vincent devrait être normalisé en Anthony Vincent"
        assert "Alice Dupont" in args_str, "ALICE DUPONT devrait être normalisé en Alice Dupont"
        assert "Jean de la Fontaine" in args_str, "jean de la fontaine devrait préserver 'de la'"
        assert "Patrick O'Connor" in args_str, "patrick o'connor devrait être normalisé en Patrick O'Connor"
        assert "John McDonald" in args_str, "john mcdonald devrait être normalisé en John McDonald"
        # Vérifier que nous utilisons bien l'approche robuste (remove-then-add)
        # Chaque personne devrait avoir une paire -PersonInImage-=X et -PersonInImage+=X
        for person in ["Anthony Vincent", "Alice Dupont", "Jean de la Fontaine", "Patrick O'Connor", "John McDonald"]:
            assert f"-XMP-iptcExt:PersonInImage-={person}" in args, f"Devrait avoir -PersonInImage-={person}"
            assert f"-XMP-iptcExt:PersonInImage+={person}" in args, f"Devrait avoir -PersonInImage+={person}"
def test_sidecar_album_normalization():
    """Test que les albums des sidecars sont normalisés avec normalize_keyword."""
    with tempfile.TemporaryDirectory() as temp_dir:
        temp_path = Path(temp_dir)
        # Créer un sidecar
        sidecar_data = {
            "title": "test.jpg",
            "description": "Photo avec albums"
        }
        json_path = temp_path / "test.jpg.json"
        json_path.write_text(json.dumps(sidecar_data), encoding="utf-8")
        # Parser le sidecar
        meta = parse_sidecar(json_path)
        # Simuler des albums trouvés par find_albums_for_directory 
        # (ces albums ne sont pas normalisés à ce stade)
        meta.albums = ["vacances été", "photos de famille", "ÉVÉNEMENTS SPÉCIAUX"]
        # Construire les arguments exiftool
        args = build_exiftool_args(meta, append_only=True)
        args_str = " ".join(args)
        print(f"Arguments avec albums: {args_str}")
        # Vérifier que les albums sont normalisés avec le préfixe "Album: "
        assert "Album: Vacances Été" in args_str, "Album devrait être normalisé"
        assert "Album: Photos De Famille" in args_str, "Album devrait être normalisé"
        assert "Album: Événements Spéciaux" in args_str, "Album devrait être normalisé"
def test_manual_normalization_vs_integrated():
    """Test que la normalisation manuelle donne le même résultat que l'intégration."""
    # Test avec des noms divers
    test_names = [
        "anthony vincent",
        "ALICE DUPONT", 
        "jean de la fontaine",
        "patrick o'connor",
        "john mcdonald"
    ]
    # Normalisation manuelle
    manually_normalized = [normalize_person_name(name) for name in test_names]
    expected = ["Anthony Vincent", "Alice Dupont", "Jean de la Fontaine", "Patrick O'Connor", "John McDonald"]
    assert manually_normalized == expected, f"Normalisation manuelle incorrecte: {manually_normalized}"
    # Test albums  
    test_albums = ["vacances été", "photos de famille", "ÉVÉNEMENTS SPÉCIAUX"]
    album_normalized = [normalize_keyword(album) for album in test_albums]
    expected_albums = ["Vacances Été", "Photos De Famille", "Événements Spéciaux"]
    assert album_normalized == expected_albums, f"Normalisation albums incorrecte: {album_normalized}"
    print("✅ Normalisation manuelle cohérente avec l'intégration")
if __name__ == "__main__":
    test_sidecar_to_exiftool_integration()
    print()
    test_sidecar_album_normalization()
    print()
    test_manual_normalization_vs_integrated()
    print()
    print("🎉 Tests d'intégration sidecar + normalisation : SUCCÈS !")
````

## File: tests/test_sidecar.py
````python
from pathlib import Path
import json
import pytest
from google_takeout_metadata.sidecar import parse_sidecar
def test_parse_sidecar(tmp_path: Path) -> None:
    sample = {
        "title": "1729436788572.jpg",
        "description": "Magicien en or",
        "creationTime": {"timestamp": "1736719606"},
        "photoTakenTime": {"timestamp": "1736719606"},
        "geoData": {"latitude": 0.0, "longitude": 0.0, "altitude": 0.0},
        "people": [{"name": "anthony vincent"}],
    }
    json_path = tmp_path / "1729436788572.jpg.json"
    json_path.write_text(json.dumps(sample), encoding="utf-8")
    meta = parse_sidecar(json_path)
    assert meta.filename == "1729436788572.jpg"
    assert meta.description == "Magicien en or"
    assert meta.people == ["anthony vincent"]
    assert meta.taken_at == 1736719606
    assert meta.created_at == 1736719606
def test_title_mismatch(tmp_path: Path) -> None:
    data = {"title": "other.jpg"}
    json_path = tmp_path / "sample.jpg.json"
    json_path.write_text(json.dumps(data), encoding="utf-8")
    with pytest.raises(ValueError):
        parse_sidecar(json_path)
def test_parse_sidecar_supplemental_metadata_format(tmp_path: Path) -> None:
    """Tester l'analyse du nouveau format Google Takeout : IMG_001.jpg.supplemental-metadata.json"""
    sample = {
        "title": "IMG_001.jpg",
        "description": "Test photo with new format",
        "creationTime": {"timestamp": "1736719606"},
        "photoTakenTime": {"timestamp": "1736719606"},
        "people": [{"name": "test user"}],
    }
    json_path = tmp_path / "IMG_001.jpg.supplemental-metadata.json"
    json_path.write_text(json.dumps(sample), encoding="utf-8")
    meta = parse_sidecar(json_path)
    assert meta.filename == "IMG_001.jpg"
    assert meta.description == "Test photo with new format"
    assert meta.people == ["test user"]
    assert meta.taken_at == 1736719606
    assert meta.created_at == 1736719606
def test_title_mismatch_supplemental_metadata(tmp_path: Path) -> None:
    """Tester la validation du titre avec le format supplemental-metadata."""
    data = {"title": "wrong_name.jpg"}
    json_path = tmp_path / "IMG_001.jpg.supplemental-metadata.json"
    json_path.write_text(json.dumps(data), encoding="utf-8")
    with pytest.raises(ValueError, match="Le titre du sidecar.*ne correspond pas au nom de fichier attendu"):
        parse_sidecar(json_path)
def test_invalid_json(tmp_path: Path) -> None:
    json_path = tmp_path / "bad.jpg.json"
    json_path.write_text("not json", encoding="utf-8")
    with pytest.raises(ValueError):
        parse_sidecar(json_path)
def test_zero_coordinates(tmp_path: Path) -> None:
    sample = {
        "title": "a.jpg",
        "geoData": {"latitude": 0.0, "longitude": 0.0, "altitude": 10.0, "latitudeSpan": 1, "longitudeSpan": 1},
    }
    json_path = tmp_path / "a.jpg.json"
    json_path.write_text(json.dumps(sample), encoding="utf-8")
    meta = parse_sidecar(json_path)
    # Les coordonnées 0/0 doivent être filtrées car peu fiables
    assert meta.latitude is None
    assert meta.longitude is None
    assert meta.altitude is None
def test_people_deduplication(tmp_path: Path) -> None:
    """Tester que les noms de personnes sont dédupliqués et nettoyés."""
    sample = {
        "title": "a.jpg",
        "people": [
            {"name": "alice"},
            {"name": " alice "},  # avec espaces
            {"name": "alice"},   # doublon
            {"name": "bob"},
            {"name": "  "},      # vide après nettoyage
            {"name": "charlie"},
            {"name": " bob "},   # autre doublon avec espaces
        ]
    }
    json_path = tmp_path / "a.jpg.json"
    json_path.write_text(json.dumps(sample), encoding="utf-8")
    meta = parse_sidecar(json_path)
    # Devrait avoir dédupliqué et nettoyé : ["alice", "bob", "charlie"]
    assert meta.people == ["alice", "bob", "charlie"]
def test_parse_favorite_true(tmp_path: Path) -> None:
    """Tester l'analyse d'une photo favorite avec le format Google Takeout réel."""
    sample = {
        "title": "favorite.jpg",
        "favorited": True
    }
    json_path = tmp_path / "favorite.jpg.json"
    json_path.write_text(json.dumps(sample), encoding="utf-8")
    meta = parse_sidecar(json_path)
    assert meta.favorite is True
def test_parse_favorite_false(tmp_path: Path) -> None:
    """Tester l'analyse d'une photo non favorite avec le format Google Takeout réel."""
    sample = {
        "title": "not_favorite.jpg",
        "favorited": False
    }
    json_path = tmp_path / "not_favorite.jpg.json"
    json_path.write_text(json.dumps(sample), encoding="utf-8")
    meta = parse_sidecar(json_path)
    assert meta.favorite is False
def test_parse_no_favorite_field(tmp_path: Path) -> None:
    """Tester l'analyse d'une photo sans champ favori."""
    sample = {
        "title": "no_fav.jpg",
        "description": "Test photo"
    }
    json_path = tmp_path / "no_fav.jpg.json"
    json_path.write_text(json.dumps(sample), encoding="utf-8")
    meta = parse_sidecar(json_path)
    assert meta.favorite is False
def test_parse_zero_geo_coordinates(tmp_path: Path) -> None:
    """Tester que les coordonnées 0/0 sont filtrées car peu fiables."""
    sample = {
        "title": "geo_zero.jpg",
        "geoData": {"latitude": 0.0, "longitude": 0.0, "altitude": 100.0}
    }
    json_path = tmp_path / "geo_zero.jpg.json"
    json_path.write_text(json.dumps(sample), encoding="utf-8")
    meta = parse_sidecar(json_path)
    # Les coordonnées 0/0 doivent être filtrées
    assert meta.latitude is None
    assert meta.longitude is None
    assert meta.altitude is None
def test_parse_valid_geo_coordinates(tmp_path: Path) -> None:
    """Tester que les coordonnées valides sont préservées."""
    sample = {
        "title": "geo_valid.jpg",
        "geoData": {"latitude": 48.8566, "longitude": 2.3522, "altitude": 35.0}
    }
    json_path = tmp_path / "geo_valid.jpg.json"
    json_path.write_text(json.dumps(sample), encoding="utf-8")
    meta = parse_sidecar(json_path)
    assert meta.latitude == 48.8566
    assert meta.longitude == 2.3522
    assert meta.altitude == 35.0
def test_parse_missing_timestamps(tmp_path: Path) -> None:
    """Tester l'analyse quand les horodatages sont manquants."""
    sample = {
        "title": "no_dates.jpg",
        "description": "Photo without dates"
    }
    json_path = tmp_path / "no_dates.jpg.json"
    json_path.write_text(json.dumps(sample), encoding="utf-8")
    meta = parse_sidecar(json_path)
    assert meta.taken_at is None
    assert meta.created_at is None
def test_parse_local_folder_name(tmp_path: Path) -> None:
    """Tester l'extraction du nom du dossier local de l'appareil."""
    sample = {
        "title": "messenger_photo.jpg",
        "description": "Photo from Messenger",
        "googlePhotosOrigin": {
            "mobileUpload": {
                "deviceFolder": {
                    "localFolderName": "Messenger"
                },
                "deviceType": "ANDROID_PHONE"
            }
        }
    }
    json_path = tmp_path / "messenger_photo.jpg.json"
    json_path.write_text(json.dumps(sample), encoding="utf-8")
    meta = parse_sidecar(json_path)
    assert meta.local_folder_name == "Messenger"
def test_parse_no_local_folder_name(tmp_path: Path) -> None:
    """Tester quand il n'y a pas de dossier local."""
    sample = {
        "title": "normal_photo.jpg",
        "description": "Photo normale"
    }
    json_path = tmp_path / "normal_photo.jpg.json"
    json_path.write_text(json.dumps(sample), encoding="utf-8")
    meta = parse_sidecar(json_path)
    assert meta.local_folder_name is None
def test_parse_album_metadata(tmp_path: Path) -> None:
    """Tester l'analyse des métadonnées d'album depuis les fichiers metadata.json."""
    from google_takeout_metadata.sidecar import parse_album_metadata
    # Tester le format réel Google Takeout
    album_data = {
        "title": "halloween",
        "description": "",
        "access": "protected",
        "date": {
            "timestamp": "1730287676",
            "formatted": "30 oct. 2024, 11:27:56 UTC"
        }
    }
    metadata_path = tmp_path / "metadata.json"
    metadata_path.write_text(json.dumps(album_data), encoding="utf-8")
    albums = parse_album_metadata(metadata_path)
    assert albums == ["halloween"]
def test_parse_album_metadata_no_title(tmp_path: Path) -> None:
    """Tester l'analyse quand le titre est manquant."""
    from google_takeout_metadata.sidecar import parse_album_metadata
    album_data = {
        "description": "Album sans titre",
        "access": "protected"
    }
    metadata_path = tmp_path / "metadata.json"
    metadata_path.write_text(json.dumps(album_data), encoding="utf-8")
    albums = parse_album_metadata(metadata_path)
    assert albums == []
def test_find_albums_for_directory(tmp_path: Path) -> None:
    """Tester la recherche d'albums pour un répertoire."""
    from google_takeout_metadata.sidecar import find_albums_for_directory
    # Créer les métadonnées d'album
    album_data = {"title": "Mon Album"}
    metadata_path = tmp_path / "metadata.json"
    metadata_path.write_text(json.dumps(album_data), encoding="utf-8")
    albums = find_albums_for_directory(tmp_path)
    assert albums == ["Mon Album"]
def test_find_albums_for_directory_no_metadata(tmp_path: Path) -> None:
    """Tester la recherche d'albums quand aucune métadonnée n'existe."""
    from google_takeout_metadata.sidecar import find_albums_for_directory
    albums = find_albums_for_directory(tmp_path)
    assert albums == []
def test_find_albums_french_metadata_format(tmp_path: Path) -> None:
    """Tester la recherche d'albums avec le format de fichier de métadonnées français."""
    from google_takeout_metadata.sidecar import find_albums_for_directory
    # Créer les métadonnées d'album français
    album_data = {"title": "Mon Album Français"}
    metadata_path = tmp_path / "métadonnées.json"
    metadata_path.write_text(json.dumps(album_data), encoding="utf-8")
    albums = find_albums_for_directory(tmp_path)
    assert albums == ["Mon Album Français"]
def test_find_albums_french_numbered_metadata(tmp_path: Path) -> None:
    """Tester la recherche d'albums avec des fichiers de métadonnées français numérotés."""
    from google_takeout_metadata.sidecar import find_albums_for_directory
    # Créer plusieurs fichiers de métadonnées français
    album_data1 = {"title": "Album 1"}
    metadata_path1 = tmp_path / "métadonnées.json"
    metadata_path1.write_text(json.dumps(album_data1), encoding="utf-8")
    album_data2 = {"title": "Album 2"}
    metadata_path2 = tmp_path / "métadonnées(1).json"
    metadata_path2.write_text(json.dumps(album_data2), encoding="utf-8")
    album_data3 = {"title": "Album 3"}
    metadata_path3 = tmp_path / "métadonnées(2).json"
    metadata_path3.write_text(json.dumps(album_data3), encoding="utf-8")
    albums = find_albums_for_directory(tmp_path)
    assert set(albums) == {"Album 1", "Album 2", "Album 3"}
def test_find_albums_mixed_formats(tmp_path: Path) -> None:
    """Tester la recherche d'albums avec des fichiers de métadonnées mixtes anglais et français."""
    from google_takeout_metadata.sidecar import find_albums_for_directory
    # Créer les métadonnées anglais
    album_data_en = {"title": "English Album"}
    metadata_path_en = tmp_path / "metadata.json"
    metadata_path_en.write_text(json.dumps(album_data_en), encoding="utf-8")
    # Créer les métadonnées français
    album_data_fr = {"title": "Album Français"}
    metadata_path_fr = tmp_path / "métadonnées.json"
    metadata_path_fr.write_text(json.dumps(album_data_fr), encoding="utf-8")
    albums = find_albums_for_directory(tmp_path)
    assert set(albums) == {"Album Français", "English Album"}
def test_sidecar_with_albums_from_directory(tmp_path: Path) -> None:
    """Tester que les albums sont ajoutés depuis les métadonnées de répertoire lors du traitement des sidecars."""
    from google_takeout_metadata.sidecar import parse_sidecar
    # Créer les métadonnées d'album
    album_data = {"title": "Album Test"}
    metadata_path = tmp_path / "metadata.json"
    metadata_path.write_text(json.dumps(album_data), encoding="utf-8")
    # Créer un fichier image factice
    media_path = tmp_path / "test.jpg"
    with open(media_path, 'wb') as f:
        f.write(b'\xFF\xD8\xFF\xE0')  # En-tête JPEG minimal
    # Créer le sidecar
    sidecar_data = {
        "title": "test.jpg",
        "description": "Test photo"
    }
    json_path = tmp_path / "test.jpg.json"
    json_path.write_text(json.dumps(sidecar_data), encoding="utf-8")
    # Analyser le sidecar - les albums devraient être vides initialement
    meta = parse_sidecar(json_path)
    assert meta.albums == []
    # Note: Nous ne pouvons pas tester process_sidecar_file sans exiftool
    # mais nous pouvons tester la logique de recherche d'albums séparément
````

## File: tests/test_stats_validation.py
````python
#!/usr/bin/env python3
"""Test rapide pour vérifier que les statistiques sont bien connectées."""
import tempfile
from pathlib import Path
import json
from PIL import Image
from src.google_takeout_metadata.processor import process_directory
from src.google_takeout_metadata import statistics
def test_stats_connected():
    """Test rapide pour vérifier les connexions des statistiques."""
    with tempfile.TemporaryDirectory() as tmp_dir:
        tmp_path = Path(tmp_dir)
        # Réinitialiser les statistiques
        statistics.stats = statistics.ProcessingStats()
        # Créer une image de test
        img_path = tmp_path / "test.jpg"
        img = Image.new('RGB', (100, 100), color='red')
        img.save(img_path)
        # Créer un sidecar JSON
        sidecar_data = {"title": "test.jpg", "description": "Test image"}
        json_path = tmp_path / "test.jpg.json"
        json_path.write_text(json.dumps(sidecar_data), encoding="utf-8")
        # Créer un sidecar déjà traité (préfixe OK_)
        processed_sidecar = tmp_path / "OK_test2.jpg.json"
        processed_sidecar.write_text(json.dumps({"title": "test2.jpg"}), encoding="utf-8")
        # Traiter le répertoire
        process_directory(tmp_path, use_localtime=False, append_only=True, immediate_delete=False)
        # Vérifier les statistiques
        print(f"Total sidecars trouvés: {statistics.stats.total_sidecars_found}")
        print(f"Total traités: {statistics.stats.total_processed}")
        print(f"Total ignorés: {statistics.stats.total_skipped}")
        print(f"Fichiers ignorés: {statistics.stats.skipped_files}")
        # Le sidecar déjà traité devrait être dans les ignorés
        assert statistics.stats.total_skipped == 1
        assert len(statistics.stats.skipped_files) == 1
        assert "OK_test2.jpg.json" in statistics.stats.skipped_files[0]
        print("✅ Toutes les statistiques sont bien connectées !")
if __name__ == "__main__":
    test_stats_connected()
````

## File: tests/test_wm_cg_fix.py
````python
#!/usr/bin/env python3
"""
Test script pour vérifier les corrections de la logique -wm cg.
"""
import sys
sys.path.append('src')
from google_takeout_metadata.sidecar import SidecarData
from google_takeout_metadata.exif_writer import build_exiftool_args
def test_append_only_timestamps_without_description():
    """
    Teste le scénario P1 : mode append-only avec timestamps mais sans description.
    Doit ajouter -wm cg pour éviter d'écraser les timestamps existants.
    """
    # Métadonnées avec seulement des dates (pas de description)
    meta = SidecarData(
        filename="test.jpg",
        description=None,  # Pas de description -> build_description_args retourne []
        people=None,
        taken_at=1640995200,  # 2022-01-01 00:00:00 UTC
        created_at=1640995200,
        latitude=None,
        longitude=None,
        altitude=None,
        favorite=False,
    )
    # Mode append-only
    args = build_exiftool_args(meta, append_only=True)
    print("=== Test P1: Timestamps sans description en mode append-only ===")
    print(f"Arguments générés: {args}")
    # Vérifications
    assert "-wm" in args, "L'option -wm devrait être présente"
    assert "cg" in args, "L'option cg devrait être présente"
    # Vérifier que -wm cg apparaît avant les timestamps
    wm_index = args.index("-wm")
    cg_index = args.index("cg")
    assert cg_index == wm_index + 1, "-wm et cg doivent être consécutifs"
    # Vérifier qu'il y a des timestamps après -wm cg
    datetime_found = False
    for i, arg in enumerate(args):
        if "-DateTimeOriginal=" in arg or "-CreateDate=" in arg or "-ModifyDate=" in arg:
            assert i > cg_index, f"Timestamp {arg} doit apparaître après -wm cg"
            datetime_found = True
    assert datetime_found, "Au moins un timestamp doit être présent"
    print("✅ Test P1 réussi : -wm cg correctement ajouté pour les timestamps")
def test_fragile_wm_logic_eliminated():
    """
    Teste que la logique fragile any("-wm" in str(arg) for arg in args) n'est plus utilisée.
    """
    # Métadonnées avec dates et GPS
    meta = SidecarData(
        filename="test.jpg",
        description=None,
        people=None,
        taken_at=1640995200,
        created_at=1640995200,
        latitude=48.8566,
        longitude=2.3522,
        altitude=35.0,
        favorite=True,  # Rating=5
    )
    args = build_exiftool_args(meta, append_only=True)
    print("=== Test: Logique -wm cg structurée ===")
    print(f"Arguments générés: {args}")
    # Compter le nombre d'occurrences de -wm
    wm_count = args.count("-wm")
    # Avec la nouvelle logique, il ne devrait y avoir qu'un seul -wm cg 
    # (+ éventuellement un dans build_description_args si description présente)
    assert wm_count <= 2, f"Trop d'occurrences de -wm: {wm_count}"
    # Vérifier que -wm cg apparaît dans l'ordre correct
    if "-wm" in args:
        wm_indices = [i for i, arg in enumerate(args) if arg == "-wm"]
        for wm_idx in wm_indices:
            assert wm_idx + 1 < len(args), "Il doit y avoir un argument après -wm"
            assert args[wm_idx + 1] == "cg", f"Après -wm doit venir 'cg', trouvé: {args[wm_idx + 1]}"
    print("✅ Test logique structurée réussi : -wm cg utilisé de manière cohérente")
def test_no_wm_in_overwrite_mode():
    """
    Teste qu'en mode overwrite, pas de -wm cg inutile.
    """
    meta = SidecarData(
        filename="test.jpg", 
        description="Test description",
        people=None,
        taken_at=1640995200,
        created_at=1640995200,
        latitude=None,
        longitude=None,
        altitude=None,
        favorite=False,
    )
    args = build_exiftool_args(meta, append_only=False)
    print("=== Test: Mode overwrite sans -wm cg inutile ===")
    print(f"Arguments générés: {args}")
    # En mode overwrite, la description ne devrait pas avoir -wm cg
    # (sauf si explicitement nécessaire pour certaines opérations)
    wm_count = args.count("-wm")
    # Le mode overwrite ne devrait pas ajouter de -wm cg sauf cas spéciaux
    print(f"Nombre d'occurrences -wm en mode overwrite: {wm_count}")
    print("✅ Test mode overwrite réussi")
if __name__ == "__main__":
    test_append_only_timestamps_without_description()
    print()
    test_fragile_wm_logic_eliminated() 
    print()
    test_no_wm_in_overwrite_mode()
    print()
    print("🎉 Tous les tests des corrections -wm cg ont réussi !")
````

## File: updated_files.txt
````
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-237/test_main_integration_batch_mo0/batch1.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-237/test_main_integration_batch_mo0/batch2.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-237/test_batch_sidecar_cleanup_wit0/test.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-237/test_batch_vs_normal_mode_equi0/batch_mode/photo1.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-237/test_batch_vs_normal_mode_equi0/batch_mode/photo2.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-237/test_batch_vs_normal_mode_equi0/batch_mode/photo3.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-237/test_batch_mode_performance_be0/perf_test_000.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-237/test_batch_mode_performance_be0/perf_test_001.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-237/test_batch_mode_performance_be0/perf_test_002.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-237/test_batch_mode_performance_be0/perf_test_003.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-237/test_batch_mode_performance_be0/perf_test_004.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-237/test_batch_mode_performance_be0/perf_test_005.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-237/test_batch_mode_performance_be0/perf_test_006.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-237/test_batch_mode_performance_be0/perf_test_007.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-237/test_batch_mode_performance_be0/perf_test_008.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-237/test_batch_mode_performance_be0/perf_test_009.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-237/test_batch_mode_performance_be0/perf_test_010.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-237/test_batch_mode_performance_be0/perf_test_011.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-237/test_batch_mode_performance_be0/perf_test_012.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-237/test_batch_mode_performance_be0/perf_test_013.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-237/test_batch_mode_performance_be0/perf_test_014.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-237/test_batch_mode_performance_be0/perf_test_015.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-237/test_batch_mode_performance_be0/perf_test_016.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-237/test_batch_mode_performance_be0/perf_test_017.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-237/test_batch_mode_performance_be0/perf_test_018.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-237/test_batch_mode_performance_be0/perf_test_019.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-237/test_batch_mode_with_mixed_fil0/mixed1.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-237/test_batch_mode_with_mixed_fil0/mixed2.png
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-237/test_process_directory_batch_s0/test.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-237/test_process_directory_batch_m0/test1.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-237/test_process_directory_batch_m0/test2.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-237/test_process_directory_batch_m0/test3.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-237/test_process_directory_batch_w0/Album Test/album_photo.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-237/test_process_directory_batch_i0/cleanup_test.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-240/test_main_integration_batch_mo0/batch1.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-240/test_main_integration_batch_mo0/batch2.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-241/test_main_integration_batch_mo0/batch1.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-241/test_main_integration_batch_mo0/batch2.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-242/test_main_integration_batch_mo0/batch1.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-242/test_main_integration_batch_mo0/batch2.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-243/test_main_integration_batch_mo0/batch1.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-243/test_main_integration_batch_mo0/batch2.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-245/test_main_integration_batch_mo0/batch1.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-245/test_main_integration_batch_mo0/batch2.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-245/test_batch_vs_normal_mode_equi0/batch_mode/photo1.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-245/test_batch_vs_normal_mode_equi0/batch_mode/photo2.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-245/test_batch_vs_normal_mode_equi0/batch_mode/photo3.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-245/test_batch_mode_performance_be0/perf_test_000.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-245/test_batch_mode_performance_be0/perf_test_001.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-245/test_batch_mode_performance_be0/perf_test_002.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-245/test_batch_mode_performance_be0/perf_test_003.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-245/test_batch_mode_performance_be0/perf_test_004.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-245/test_batch_mode_performance_be0/perf_test_005.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-245/test_batch_mode_performance_be0/perf_test_006.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-245/test_batch_mode_performance_be0/perf_test_007.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-245/test_batch_mode_performance_be0/perf_test_008.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-245/test_batch_mode_performance_be0/perf_test_009.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-245/test_batch_mode_performance_be0/perf_test_010.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-245/test_batch_mode_performance_be0/perf_test_011.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-245/test_batch_mode_performance_be0/perf_test_012.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-245/test_batch_mode_performance_be0/perf_test_013.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-245/test_batch_mode_performance_be0/perf_test_014.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-245/test_batch_mode_performance_be0/perf_test_015.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-245/test_batch_mode_performance_be0/perf_test_016.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-245/test_batch_mode_performance_be0/perf_test_017.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-245/test_batch_mode_performance_be0/perf_test_018.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-245/test_batch_mode_performance_be0/perf_test_019.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-245/test_batch_mode_with_mixed_fil0/mixed1.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-245/test_batch_mode_with_mixed_fil0/mixed2.png
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-245/test_process_directory_batch_s0/test.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-245/test_process_directory_batch_m0/test1.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-245/test_process_directory_batch_m0/test2.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-245/test_process_directory_batch_m0/test3.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-245/test_process_directory_batch_w0/Album Test/album_photo.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-245/test_process_directory_batch_i0/cleanup_test.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-246/test_main_integration_batch_mo0/batch1.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-246/test_main_integration_batch_mo0/batch2.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-246/test_batch_vs_normal_mode_equi0/batch_mode/photo1.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-246/test_batch_vs_normal_mode_equi0/batch_mode/photo2.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-246/test_batch_vs_normal_mode_equi0/batch_mode/photo3.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-246/test_batch_mode_performance_be0/perf_test_000.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-246/test_batch_mode_performance_be0/perf_test_001.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-246/test_batch_mode_performance_be0/perf_test_002.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-246/test_batch_mode_performance_be0/perf_test_003.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-246/test_batch_mode_performance_be0/perf_test_004.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-246/test_batch_mode_performance_be0/perf_test_005.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-246/test_batch_mode_performance_be0/perf_test_006.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-246/test_batch_mode_performance_be0/perf_test_007.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-246/test_batch_mode_performance_be0/perf_test_008.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-246/test_batch_mode_performance_be0/perf_test_009.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-246/test_batch_mode_performance_be0/perf_test_010.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-246/test_batch_mode_performance_be0/perf_test_011.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-246/test_batch_mode_performance_be0/perf_test_012.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-246/test_batch_mode_performance_be0/perf_test_013.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-246/test_batch_mode_performance_be0/perf_test_014.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-246/test_batch_mode_performance_be0/perf_test_015.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-246/test_batch_mode_performance_be0/perf_test_016.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-246/test_batch_mode_performance_be0/perf_test_017.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-246/test_batch_mode_performance_be0/perf_test_018.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-246/test_batch_mode_performance_be0/perf_test_019.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-246/test_batch_mode_with_mixed_fil0/mixed1.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-246/test_batch_mode_with_mixed_fil0/mixed2.png
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-246/test_process_directory_batch_s0/test.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-246/test_process_directory_batch_m0/test1.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-246/test_process_directory_batch_m0/test2.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-246/test_process_directory_batch_m0/test3.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-246/test_process_directory_batch_w0/Album Test/album_photo.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-246/test_process_directory_batch_i0/cleanup_test.jpg
C:/Users/anthony/AppData/Local/Temp/tmps3gog9jm/_Corbeille/test_image.jpg
C:/Users/anthony/AppData/Local/Temp/tmpihaozgmv/_Corbeille/test_image.jpg
C:/Users/anthony/AppData/Local/Temp/tmp50u_n5rx/_Corbeille/test_image.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-247/test_main_integration_batch_mo0/batch1.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-247/test_main_integration_batch_mo0/batch2.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-247/test_batch_vs_normal_mode_equi0/batch_mode/photo1.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-247/test_batch_vs_normal_mode_equi0/batch_mode/photo2.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-247/test_batch_vs_normal_mode_equi0/batch_mode/photo3.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-247/test_batch_mode_performance_be0/perf_test_000.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-247/test_batch_mode_performance_be0/perf_test_001.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-247/test_batch_mode_performance_be0/perf_test_002.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-247/test_batch_mode_performance_be0/perf_test_003.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-247/test_batch_mode_performance_be0/perf_test_004.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-247/test_batch_mode_performance_be0/perf_test_005.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-247/test_batch_mode_performance_be0/perf_test_006.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-247/test_batch_mode_performance_be0/perf_test_007.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-247/test_batch_mode_performance_be0/perf_test_008.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-247/test_batch_mode_performance_be0/perf_test_009.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-247/test_batch_mode_performance_be0/perf_test_010.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-247/test_batch_mode_performance_be0/perf_test_011.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-247/test_batch_mode_performance_be0/perf_test_012.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-247/test_batch_mode_performance_be0/perf_test_013.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-247/test_batch_mode_performance_be0/perf_test_014.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-247/test_batch_mode_performance_be0/perf_test_015.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-247/test_batch_mode_performance_be0/perf_test_016.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-247/test_batch_mode_performance_be0/perf_test_017.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-247/test_batch_mode_performance_be0/perf_test_018.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-247/test_batch_mode_performance_be0/perf_test_019.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-247/test_batch_mode_with_mixed_fil0/mixed1.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-247/test_batch_mode_with_mixed_fil0/mixed2.png
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-247/test_process_directory_batch_s0/test.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-247/test_process_directory_batch_m0/test1.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-247/test_process_directory_batch_m0/test2.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-247/test_process_directory_batch_m0/test3.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-247/test_process_directory_batch_w0/Album Test/album_photo.jpg
C:/Users/anthony/AppData/Local/Temp/pytest-of-anthony/pytest-247/test_process_directory_batch_i0/cleanup_test.jpg
````
